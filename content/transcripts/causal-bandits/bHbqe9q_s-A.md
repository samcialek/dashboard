root cause analysis explanations and causal Discovery this week we travel to S California to hear from researchers who presented their work at this year's edition of the clear conference on caal learning and representation enjoy I'm giving the bear I work for the German Aerospace Center in Munich so my work is about applying coel Discovery methods with climate time series and uh for this conference I was presenting a paper in which uh we used bootstrap aggregation to provide confidence measures of the Edge outputed by time series Co Discovery methods and also we found uh empirically that the aggregated graph resulting from the bootstrap aggregation and also like higher precision and also recall compared to the Baseline method that we tested for the empirical experiments what impact would you like to see of your work in the in the real world so for me I'm really focusing on applications with Cent time series and I would like to to see applications of my methods with climate time series in order to understand better climate processes are linked together so we could understand better how climate change is impacting those processes from climate models and also we would like to understand if climate models are able to represent this um processes correctly in the historical data what are the main insights something that you learned while working on this project good question I think uh for me it was um my first time working with so many people on the paper I would say so I I learned how to to write the paper in like a group and yeah all the review process and yeah that's that's what I love I think what what should people type in Google in order to find your work uh I think if you type uh bootstrap aggregation for time series coel Discovery you will find the archive uh paper yeah what is the best CLE paper you read last quarter yeah so it's actually a review paper which was written by uh Gustav com files from the University of Valencia and it's uh presenting all the current methods and uh I think the paper is called uh discovering caal relationships and equations from data and it's explaining like the current methods to estimate relationships and equations from data and also presenting opportunities and challenges in this domain so it's more like focused on physical sciences so for me it's quite relevant and I really enjoyed the people great thank you Kevin appreciate it hi um my name is utan Drew um I'm a PhD student at UCL what is your work about the work that you're presenting okay so the work I'm presenting today is uh called a meaningful causal aggregation and paradoxical compounding it's um some work I did while interning at um Amazon research chingan uh this is Joint work with kyash Bui yonas Kubler and Dominic yaning um in this work we show an interesting Paradox uh we find when we consider aggregated causal models which is that even the property of confounding which is a structural property of caal models even that is well defined when we um consider ambiguous interventions on aggregated variables um we we make um a simple realization with which we call Natural Intervention which um can help us mitigate uh this problem um and we also try to uh generalize this observation to laric rocks what do that mean to make an ambiguous intervention uh yes so um when the variables that we consider are aggregated variables of some fine grained um micr level variables then when we intervene on an aggregated varable there are many different ways of realizing that intervention on the micro level for which we assume that we do have a a robust C Modo for did you give an example for example Amazon um has millions of products uh Each of which might have different prices um then when they want to ask questions such as uh if I sell more cleaning products how would that impact my Downstream Revenue um number of cleaning products sold is an aggregated variable and you might have diff like different cleaning products with slightly different prices so how exactly do you sell them will have different impacts on your Downstream Revenue what impact of your work would you like to see in the real world because most variables that we care about are aggregated variables uh yet there's only limited academic work um analyzing how we deal with this uh like the consequence of ambiguous interventions I would definitely like to see this this problem being analyzed more um for real world applications and also it would be nice um if there can be work that can learn from data um a set of macro variables for which like which is complete in some sense in summarizing this micro model um I think that that will be uh really useful for for real real world applications what should people type in Google in order to find your work the title Works a meaningful call agregation and related paradoxes or you can search my name uh Google and is on my Google schar what is the best C paper you read last quarter um so there paper that I always go back to called um multi-level cause effect systems uh it's written by Kristoff kupka I think in 2016 or 17 basically in this case it it learns these like sufficient macro variables uh for a for a specific model um and uh yeah I I always go back to it even and I think uh is is even given me some Inspirations for understanding uh how to um mitigate reward hacking for example for large models uh because in in that case we also want to think about transfer from some kind of lower dimensional models um yeah I think it's a really nice paper great thank you so much I'm Constantine gobler I'm from Germany I'm uh a fourth year PhD student at the Technical University of Munich I'm with Matia st's group there and since two years I'm also affiliated with the Robert BOS be and uh yeah we do a bunch of stuff them with them together I guess the work you presented here what is it about so the work that I presented is uh I I call this causal assembly or like we call this causal assembly and it's basically aimed at facilitating uh benchmarking causal Discovery algorithms so it's more or less like a service for the community but also I think um it's filling a gap of uh in the field there's some issues of uh attaining um reasonably complex ground truth data for causal Discovery so we U managed to um convince the people at Bush to uh make Public Access not really public but we tried to manage to find out a tool that makes propriety data publicly accessible via some semi synthetic some semi synthetic data steps we do so in a somewhat principled manner uh with a bunch of like Steps in the middle so so that people can sure people are assured to when they Benchmark um their cyth this is with this library that is implemented in Python that um the data really follows the ground truth cograph that is also implemented in there what what is the advantage of your approach uh compared to other approaches that are available in Python today I think the advantage is that we almost should do this basically for any implementation I think that is uh where people are what uncertain about the ground truth causal structure that is given to somewhat complex real data I think because as soon as there's some uncertainty and you run your favorite cause of Discovery algorithm on on this data like the worst case scenario is that you um your algorithm is correct but you think it's wrong because your ground truth is wrong so what I what we basically do is we make sure that the data that you run your Cal Discovery algorithm on really follows the ground truth that is uh at hand what impact of your work would you would you like to see in the real world that's a hard one I think so the impact of my work ideally is that it like I said it facilitates progress in the field such that um call the discovery is more reliable um and is able to scale better such that reward problems can be solved like degree what what should people type in Google in order to find your work caal assembly what's the best CLE paper you read last quter so it's not necessarily I think a strict CA of paper but I really like I dived a little bit into like a and uh and there was a paper on nonlinear IA that I very much enjoyed the paper itself is very readable but the proof is very hot so um I very much enjoyed the nonlinear IA byav and a couple of coauthors I think yeah and do you remember the author of the title so I know that the second author isavia who was also awarded the best paper here thank you so much thank you hi everyone I'm oja B I am from moner Technological University cork in Ireland and uh my PhD is founded by Science Foundation Arland and mcken private limited I am presenting the impact of neighborhood on explainable AI Frameworks such that I want to know how much uh they are able to to convey the sufficiency and necessity of features so sufficiency and necessity are the fundamental you know blocks of any explanation we do want to know which feature is sufficient in maintaining the classification as it is and which feature is very very necessary to the necessary that if if the feature valers get change then the cation will get changed so there are these sufficiency necessary Concepts now we do have many many Frameworks inexplainable AI uh especially State of-the-art Frameworks like sharp line dice dice is a counteract library and we extracted feature importance scores using that that libraries and we wanted to see how much these feature importance scores are able to convey the sufficiency and necessity of features the reason why I was doing that is because if you are provided with a feature importance ranking you can interpret it very very different ways I can say that oh a is very very important so if I change the value of a the the classification might change if somebody else is reading that feature importance ranking he or she let's say is reading it you know and it it he looks at the feature ranking and it's like H this test is not g given that much importance by a machine learning model so it might not be very important as for the model so go TR your model again because this test is very important so there can be different interpretation and we don't know what to interpret from that ranking right so that's why we develop this concept called explanandum we Define it properly and we try to see what exactly to interpret from that ranking that we are getting provided so I focus on the basic fundamental blocks Exum which is sufficiency and necessity uh I wanted to know if I'm looking at the top most ranked feature by Shar am I going to get conveyed that this feature is the most sufficient feature or the most necessary feature and so on now the problem is these Frameworks are very very sensitive to the neighborhoods that they use for explaining and different neighborhoods can produce different explanations sometimes people uh you know you can always innocently use certain samples in the neighborhood and can produce very very false explanations we tried a range of neighborhoods to see how much each of the neighborhoods can help these Frameworks to convey the sufficiency and necessity and we wanted to identify the best neighborhood that can help let's say sharp to convey the sufficiency of features the outside based neighborhoods basically perform well which means that if I'm focusing on samples that are outside the division boundary Shar can help me in producing a ranking that can tell me oh look this is the most sufficient less sufficient less sufficient and so on same with necessity uh of features but the higher level takeaway I will say for my paper is that people should draft a specific explananda and then try to see whether these Frameworks are able to convey that explanandum or not and if not then experiment with different neighborhood and try to find your answers which neighborhood is giving you the most most uh relatable or relevant answer to answer your own explan and so yeah that was pretty much my research right does this conclusion mean that it's it's very difficult just find one framework that was universally work and reliable at the same time yeah so uh we have years of papers that talk about there is no freelance theorem in explainable AI as well the main thing is that you need to be clear of your explanatory requirements here if I am a clinician I am a you know some stakeholder in in any Finance Company where loads of machine learning model are getting used without defining specifically what to interpret from the explanation that I'm provided anything is very very like ambiguous and it's very useless because now it becomes a checkbox exercise that oh okay you providing mation good I trust your model and that's it what is that explanation doing is it helping you is it is it representing the model truly in all ways so I think multiple explainable AI Frameworks using different neighborhood context is important to understand the whole actual truer picture of a model basically but what the impact of this work would you like to see there you go I actually had a chat with nephologist in G University Hospital back in Ireland and I wanted to talk to them about like uh I developed a more complex explanandum in medical domain which basically meant if I'm looking at the feature importance ranking can I say okay I don't need to do further tests as per machine learning model I don't need to do further test or can I also answer another question which is uh as per the machine learning model which is the next most important diagnostic test that I would like to do so these are the questions that we wanted to answer uh using the same methodology that we adopted in this paper and we discussed this with the CL um and they really liked our work so I really want to see more and more uh tour forms of Explorations with clearly well defined explanandum so that people don't follow all this as a checkbox exercise for ethical permissions and all and actually present the true picture of the model to the to the stakeholders basically what's the best caal paper you read last quarter I have not read a causal I don't remember if I read a POS because my domain I really focus on explorability I don't think of course my domain should be very very overlapping with causality because without causality it f so B it's kind of ambiguous to have explainability and we did work on Cal relationship in a way that we constructed medical workflows like which test comes after what test and everything I think in the last part the most my favorite fav and I can share is dear XI Community um it's a people that you can just just write Dear XII community and that people talks about how much here and there the research is going on in explain people are not standardizing the concept people are not focusing on one single definitions of things defining and also the the importance of explanandum is highlighted in that paper that you need to be very clear of who is your audience what are you exactly trying to explain and what action someone can take looking at your explanation so I think these are the question that are the whole point of our domain and people should work more and more on that rather than just developing novel xci Frameworks to create just another ranking without defining what to get from that ranking So yeah thank you so much thank you so much hi I'm well Orchard I'm at the University of Cambridge uh but the work I did here um I did Amazon as an intern in Tuan my work is about root cause analysis uh uh from a number of directions one is how root cause analysis should be formalized as a causal problem and two is the real world application of root CA analysis to real world problems such as in microservice based applications an can you say a little bit about your up the approach to formalizing recot calls analysis or so um essentially a lot of existing there's a lot of existing works on root cause analysis and each of them have have typically approached it nor from a causal perspective despite the fact that the cause is in the name one thing I've done is I've just gone through a lot of works and tried to figure out whether there is a unifying csal description you can give to each of these methods and at the moment there um there is very much literature on how root cause analysis methods should be classified but sort of unsurprisingly you can classify them according to the causal hierarchy about the way which they think of what a root cause is um whether or not it's an associational question an Interventional question or a counterfactual question and so my Approach has one been to just try to classify what already exists and then in particular because I've worked with Dominic yaning he's very interested in the counter factual approach so um so yeah so counter contribution approach recal analysis would be what are the main challenges in this work yes that's a good question so I think there's a number of things so one is a question which comes up when you're trying to formalize any problem right which is uh what is the best way to ask a question which sort of captures your intuition about how a problem should be formalized right uh whether or not it truly captures the thing that you're trying for it to uh capture right and I think causality can give very convincing answers to uh to whether or not you giving a good explanations for something like a root cause and so just trying to get my head around about whether or not we were asking the right question and how other uh approaches were asking this question and what the relative merits were of each of those things that was challenging just on a conceptual level and then sort of relatedly the question was whether or not this formalization actually works in real life for real problems yes and that involves obviously talking to engineers and people like this who who work with this data and have sort of developed their own fistic and things like this for solving this problem and whether or not this this formalization captures their experience as well yeah what are the main learnings main insights that you got from this work personal I think the first thing I love was I think the question of what is a root cause is actually a very deep question it's I think it's interrelated to lots of questions in causality about um explainability it's toally related to questions of sufficiency and necessity it's also closely related to the relationship between anomalous values or rare values and interventions and things like this so I really think I learned a lot about um uh yeah causality from this perspective and and root cause analysis I think really is connected to lot of these things I also learned that uh Engineers typically aren't very interested and and it really requires some convincing to tell them that their staff is important and that it can it can help them out so that was very interesting what the fact of your work would you like to see in the in the real work I think the first thing particularly with this work is there really has been a total almost a total lack of standardized data sets available for evaluating root course analysis methods and I think one of the impacts of this has been very many methods being developed not uh from a course of perspective which are being uh benchmarked against many other methods so like each each new paper has its own way of evaluating the approach typically with simulated data and then they don't release the data publicly and it becomes very unclear as to the way in which you formalize the problem um is seen in benchmarking results right so having publicly accessible data sets I think is very important actually for trying to convince people that Cal approaches are important and also to actually understand which ways are understanding problem working work in practice I really hope that people are going to use this data set learn more about root analysis and um yeah we can come to some kind of consensus about the best way to approach it so where can people find out more about you and your world I think mainly my Twitter um U Twitter is where I usually post uh information about my work in this case this paper is available on archive the data set is available on a on a git repo and there are QR codes in cor here um uh and then I of course also have a Google Scholar but yeah that those are the places to go what should we type in Google to find the data set yeah Pet Shop data set Amazon that kind of thing yeah what is the best gole paper you read last board um yes this is a very good question so I think one paper I found quite inspiring recently these caal Discovery methods so this is somewhat unrelated to to R call analysis but these uh score based causal discovering methods which are using the score in terms of the uh the derivative of the log of the probability right um of of the of the data and um so there's this score algorithm there's this no uh no Gan method and I think this sort of the theoretical work which has gone into the identifiability results for this sort of thing and and the way of using score matching to do causal Discovery I found um yeah really exciting it's it's just I think some of the best Cal Discovery work I've seen in a long time so yeah that's been a that's been great um and then also this this work from NFP to on using heavy tale distributions for Cal Discovery and identifiability there that also com from line I think this is related to uh to through course analysis so yeah