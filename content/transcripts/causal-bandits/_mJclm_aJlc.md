at ABB Hitachi we ran together with colleagues from eth zich rigorous field experiment where we showed that this tool can improve or reduce the yield loss in semiconductor fabrication by almost 50 almost 50% 49% we of course worked also together with other companies like booking.com that run these CA machine learning algorithms at Large Scale you're and your team's papers are consistently accepted at the biggest and most important machine learning con refences across the globe what's your recipe for Success hey causal Bandits welcome to the second season of The causal Bandits podcast the best podcast on causality and AI on the internet he wrote his first web page when he was 12 he loves making an impact that's why he transitioned from computer science to Ai and management his team consistently publishes at the top AI conferen researcher hiker and head of the institute for Ai and management at LMU ladies and Gentlemen please welcome Professor Stefan for eagal let me pass it to your host Alex molak welcome to the podcast Stefan great welcome to be here I'm very happy to have you here and I'm I'm really glad you found you found time in your busy schedule to have this conversation in your recent uh nature medicine paper you discussed the notion of clinical translation what is clinical translation and how do you think about causal machine learning in this context many of us are really interested in causal machine learning some of course simply because it's a statistical Challenge and we want to maybe have new estimators new theorems but what really drives me is how can we make a distinctive impact in practice and I think medicine is one of the fields where I think c a machine learning could make a really profound impact on the lives of patients so that's why I'm so interested Ed and also so invested in CA of machine learning for medicine but then immediately the challenge starts how do we get medical people to actually use M course machine learning and one of the things is or one idea could be we simply wait for them to think and realize that CA machine learning is a very great tool that is of help and can solve many problems I mean that's the way how I came to uh cause of machine learning but it's probably won't work for medical professionals the have a very full schedule so I think we need to go to them and tell them how they can use cause machine learning in their day-to-day business and how it helps them to answer new questions or questions more rigorously and better um that they ask in order to um improve um treatment selection what do you think we as a broader causal Community could do in order to facilitate this adoption for people at the front line I think we as a community have of course really developed great methods and great tools and I'm immensely proud of what we have so far achieved but I think now really to get uptake in other disciplines medicine marketing business decision making at large I think we need to move to their field and speak their language we can't expect them to come to us and simply say okay maybe this is a great tool and and maybe it helps me but in particular for medical people we need to sort of like also not only translate our methods into their practice but we also need to translate our language into their language this reminds me of uh thinking of of many successful businesses uh that they do not focus on making people understand them they rather make people feel understood you had this experience in your in your career earlier in your career uh to work for for McKenzie how this experience shapes your perspective as a researcher today for me it personally really is very interesting to really have to be invested in this translational part and to sort of like take my maybe sometimes also complex thoughts and the mathematics that we have behind our algorithms but really translate it into the language that decision makers end users practitioner can understand and that they can uh eventually have it understood and really then be able to use it um just one anecdote we worked with the very interdisciplinary team in machine learning for medicine um specifically in the field of diabetes and I have been explaining what an au is for 2 or 3 years like once every half a year um some people may say like is isn't that boring but I think every time to explain it in very crisp words and simple ones so that others are can make actionable or have can take action until from what they have learned I think it's also a challenge sometimes that is not easy and where we as a community are especially faced substantive challenges because causality is not the thing that you can explain so easily well can explain easily but especially cause a machine learning methods you can't explain that easily any longer if you could solve one problem in caal causal modeling caal machine learning just like this today what would that be I think what have a magic visard um that really helps people to understand the concepts in just one second um because the thing is especially thinking of medicine we have medical professionals I mean I can explain them why they need that tool but really to absorb and make be able to make a decision whether they want to have an S learner a t learner or a double robust learner is almost impossible when you don't have a solid uh technical background in statistics mathematics or computer science but users of our tools like in medicine they are not trained often in statistics to the same extent we are or maybe not even even at all because their study program is centered around actual um medical content and not about statistics so I think helping them or being able to really make this translation I think is doing um would be an important and also very rewarding step as our community and I'm especially very pleased to see that there are so many books uh that appeared over the last uh year um that really help people understand the materials yeah I think we we have a significant progress in the community in ways uh that we popularize the concepts right we started talking more and more using language that is not so hermetic for just like a small group of people you and your team published over the last two three years uh you you published a lot of papers covering a broad a broad scope of different machine learning topics um many of them related to to causality directly two topics that stand out to me in those recent Publications are related to causal machine learning or causal modeling over time so looking at treatment effects over time and the second one is related to broadly speaking uncertainty quantification either using conformal prediction or sensitivity analysis models or partial identification what dictated this choice of topics personally I think that we have three pillars where we need to improve our models and methods more broadly speaking in order to be able to really make reliable inferences in medical practice and other fields one is of course in computer science we often focus on very stylized settings because that's where we can demonstrate our methods in a of course Very rigorous manner that allows us to do benchmarking and a a very solid way however many of the action decision making settings in practice like in medicine are not of this stylized setting so rather what we want to have is we need also treatment effect estimation methods that can move beyond the standard settings that move Beyond binary treatments that move Beyond binary outcomes for example in one of our research papers we focus as you mentioned on time series setting we have another paper um that we published last year at nurbs uh 2020 3 where we focus on uh drug combinations so multiple continuous treatments and we currently working also on one paper um where we really be able where we want to be offer new methods in to analyze complex treatments um second uncertainty con ification is hugely important and I think we sometimes in machine learning forget about that as compared to maybe medicine in medicine it's very standard that every paper not only reports Point estimates in an abstract especially in abstract given that this is a very short and brief summary of the paper but even there they re rigorously report uncertainty intervals for almost all of the estimates I think that's important but it is obviously import very important for medicine and for Reliable decision- making but many of our machine learning methods for cause the inference and treatment effect estimation more broadly are not yet in the place that we can do reliable uncertainty quantification and that's why also this is a hugely important topic to our research group I think this is sort of like the holy graay which we need to improve on in order to be able to bring our methods into Medical Practice because in medicine when it comes to treatment recommendation and treatment selection this will not be they Medical Practice will not use methods that simply rely on point estimates once we have can be able to give a rigorous uncertainty quantification I think we are in the place to really bring also our machine learning methods or cause the machine learning methods more broadly into Medicare applications in many of your answers you you mention this aspect of impact having impact Beyond just the Academia somewhere in the real uh World why is that important to you I mean we as a group want to achieve and I think it's really TOS us that we're not doing something that is um abstract or um a nice think or thought exercise but really to improve the lives of patients or people more broadly let me give you one example we collaborated recently with the large health insurance in the Middle East where we wanted or where the health insurance wanted to improve their diabetes prevention programs and of course this is a nice exercise where you would say okay maybe machine learning can identify people at the risk of developing diabetes in order to allocate preventive measures like uh met for mean treatment or even simply um coachings that that help people um develop a more healthy lifestyle but of course resources in the public sector are constrained so it's clear that not every patient of the health insurance round about several Millions um can receive such a preventive care program but we need to allocate it to those patients that benefit me um the most one way is to use traditional predictive machine learning then we only would Target those that have the highest risk of developing diabetes but we don't consider really what is the impact um of a potential preventive care program and some patients May benefit more from a preventive care program than others maybe for younger patient patients it's better to have like a lifestyle coaching program that might might not be effective any longer when you're 80 or 90 years old whereas maybe metrine treatment might be better suited for certain other groups of patients and may have a larger treat treatment effect um if we apply it there so what did we do we partnered with the health insurance and we developed a two-stage machine learning cause a machine learning model where we first estimate um the potential benefit of preventive care from the electronic health records and then in the second step we made a um allocation model an optimization model that helps to identify those patients that after that would benefit the most so that the health insurance company was able to allocate their limited resources in the most costeffective manner today it doesn't happen as often as it used to happen but we still hear voices uh coming from machine learning community and statistics community that causal machine learning or causal modeling more broadly speaking uh maybe Beyond traditional rcts is impossible to implement in practice and and it's impossible to use those methods in order to drive real world outcomes what would be your comment to those criticisms disagree um and let me give you two um or even three examples of the opposite uh we for example work together with no large Media company uh where we aim to improve or optimized the front page of the newspaper and we framed the presentation of what should be promoted at the top of the website and what should be promoted at the bottom as a caer inference task and we implemented it together with a company we did not do it in a way where we wanted to replace editors we are speaking here of a very reputable newspaper that is where the cated content is part of the business model but rather we helped develop the decision support systems that can help editors improve their choices and um augment them with addition expertise from our machine learning algorithm and as a result we did not replace any uh editor but instead we empowered the editors to make better decisions uh for example they eventually realized um that the articles by the editor of she um are actually very of great interest to the um readers and that they help the company Drive long-term impact and long-term Revenue so however the company always thought like well we should be very more hesitant to promote our own articles our own comments but our machine learning C Machine learning models actually read the opposite and it helped decision makers make better decisions um a second example we worked together with abbb Hitachi where we implemented the CAA machine learning uh toour in the field that helped them improve take better Improvement actions in order to reduce low quality in the semiconductor fabrication again that is a cause of machine learning approach and the question is how would I need to change my manufacturing processes in order to improve the average quality and third we of course worked also together with other companies like booking.com that run these CA machine learning algorithms at Large Scale so I think there's a strong evidence that this that cause of machine learning can be used and can have an impact but I think there are three elements that are important one is we should not always we should not necessarily aim to replace humans but rather augment them because if they are invested I think we have much more trust and much more drives from the top management to implement these projects and to really go this long mile of explaining them why they need to cause a machine learning algorithm and how they can really implement it into practice that needs a lot of like education and teaching people and explaining them why they need it and really understanding that second we need rigorous field experiments to demonstrate the impact at ABB Hitachi we ran together with colleagues from eth CC a rigorous field experiment where we showed that this tool can improve or reduce the yield loss um in semiconductor fabrication by almost 50 almost 50% yeah 49% um I'm not allowed to tell you the the financial gain but I mean you can multiply it with the cost of a wafer and semiconductor fabrication and that was over a 4mth time period and third um we really need to educate people more and I think that will help then to bring cause and machine learning um into practice what's the best way to educate people in order to help them feel more confident using those methods we want to find this we sometimes need also to get out out of our rabbit hole with of course a very RoR way of how we present it how we write our nurs or icml papers where we always State our assumptions very explicitly and in the very former way I don't want to give up the rigor but I think we need to sometimes also explain it in the more simple terms and ways that experts can understand that are domain experts or managers that have been uh VI their last uh statistics courses 30 years ago we come back I feel to this point that you mentioned before that we should learn how to speak the language of our readers rather than trying to uh use our own language yes and uh I let me give you an example I always try to explain managers that they need cause and machine learning by saying well you have correlation and here maybe you want more causation and uh th these are your technical problems and maybe it never really worked um I've been testing that for a couple of years my current way is to Simply explain it with like a crystal ball does a manager really want to have one crystal ball telling how the future is no a manager wants to change the future so they don't want a crystal ball rather they want to have two Crystal boards one for decision a and the second for decision B and then they can look into the future how certain decisions will improve outcomes in the future and then they can pick the decision that works best for their company and I think that makes it very clear in very simple terms also what sometimes C Machine learning is doing and it brings it on point but I think we sometimes need these simple ways of explaining to medical professionals as well as to Industry folks can I and other listeners steal this method from you with the example with yeah you can you can steal it of course but I mean that's that's currently what we are doing for example um together with co-authors we want to write a piece or a small commentary that summarizes the ideas of CA of machine learning for more managerial audience um we tried it with our nature medicine for a more Medicare audience um and I think there are other fields that could benefit from these things but we also need not only explaining papers but we also need like maybe role model papers papers that really in medicine tell us what are the best practice steps um we know know as you know causality or cause inference rests on so many assumptions so we need to tell also educate maybe professionals what are the best practive robustness checks that they should do your and your team's papers are consistently accepted at the biggest and most important machine learning conferences across the globe what's your recipe for Success having a great team that's it I wish Alex I know you want to have like a super good recipe answer that everyone can do but I don't have I I'm very proud of what the the team has achieved since the last 3 years where we have been in Munich uh before we were at eth zich so that has been a very interesting and very productive uh Journey so far maybe our team DNA is our joint lunch that we have maybe this is a very European way of that we that we talk over lunch about our ideas and have a bit of more break not a work break but a discuss break that we have whiteboards that you can also see here in the backgrounds in all of our offices and that we have a good team spirit but I mean I can only be an enabler eventually it really boils down to the PhD students uh doing a fantastic job how do you build a great team like this you may need to ask a sports coach from FC Bayern Munich also about their things of course I mean let's be honest professors are not trained in in management and I'm definitely far from great and luckily you don't interview my PhD these students talking about all of my flaws and where we fighted about it and where they think that I may have changed the tone of the paper to my in in the wrong direction but I think one thing that I really appreciate and that I find is helping to have a great team is diversity and I'm not only talking about diversity in terms of culture or gender I'm also talking about diversity in terms of like backgrounds um I'm really enjoying that I have students with the background more in mathematics data science statistics computer science but also folks economics and they have all natural talents and they look sometimes on problems slightly differently and they also approach problems differently and the with certain like different priorities for example I had once um a large experiment um in the medical field where we unfortunately screwed up the randomization that was not identified by the computer scientist on the team but it was the economic student that actually looked more in the data that did this extra visualizations and went this extra to really see what's going on in the data and only he was able to identify that something was broken in the first place um on the other hand if you have students for example in computer science they for them it's very natural to run our GPU clusters um whereas for example mathematicians um they rather start maybe with a nice idea that is first formalized and approv and then they are very relaxed from that moment on before the paper deadline because they know the mathematics is working so their implementation will also work and I think everyone has sort of reflects the different strengths um and backgrounds and in particular and what I'm very proud of in our team is that many of us pull these IDE ideas together that we have papers that are where we combine the expertise from somebody in computer science about how to fit a generative adversar Network a complex diffusion model but also maybe with somebody who has a bit more theoretical uh focus and who adds a theorem a proper proof to really give a paper a foundation to build on what drives you I think that we had already discussed I think the idea is really to bring algorithms to practice always say the vision of our team of our group is to redevelop implement and evaluate new AI algorithms to improve decision-making and this is not only just developing them on pen and paper but we also have several team members that really bring these algorithms into practice with companies or practitioners in medicine um and you see another term saying new algorithms yes we publish in computer science journals so by definition they should be new um but it's also about decision making and if you really have a paper that tells us hey we can learn something we can improve decisions that will behave immediately an impact um Downstream for the decision makers in the audience who are not familiar with causal machine learning maybe maybe maybe just familiar on like a very surface level what would be your recommendation for them what should they what should they learn or where should they reach out in order to start um start learning about those methods and how those methods can be helpful for them I think we still missing some res sources there I think there are many speaker series there are of course new summary pieces sorry for my Shameless self- advertisement maybe our nature medicine paper on cause a machine learning for predicting treatment outcomes might give a first overview and sorry that I do another very Shameless self- advertisement um one paper that I'm also very proud of um is presented by Milan K manovich this year at the kdd 20124 and there we use very unique data from the oecd in order to make suggestions how to allocate development Aid development Aid We're talking about a sector that is spending 1.5 trillion doar over the past decades not 1.5 billion but really trillion um it's complex we have hundreds of different stakeholders public organizations working in that sphere like the world health organizations we have private organizations like the Bill and Melinda Gates Foundation um we have hundreds almost a hundred of countries that are recipient of development Aid so this is like by definition a complex allocation problem and we often don't know really how effective development Aid is the development economics literature has really added much experience and evidence over the past years but still I think we need tools that help them decision makers navigate this and I hope that our paper that provides in some way like an genter introduction of how CA and machine learning can help in such a decision-making setting and by navigating this with like a very simple but also applied language might be um a good idea to sort of like see what CA machine learning can do can do and see sort of like how to use it what were the main lessons for you personally uh from working on this paper sometimes I say don't use neuron networks um and I think that's true I of course I understand that we do use neuron networks in conference that they are mandat somewhat mandatory nowadays in conferences like neurs or IA but if you go to like actra applications in business or in organizations we often don't have that large data sets meta has a 1 billion customers and they have a large data large data set many small medium Enterprises in particular in Europe don't have and in particular countries like Germany we easily get N More Than 90% of our Ross domestic product from small medium Enterprises and they maybe have like a few hundred customers so we need often methods that are very data that work in data Spar regiments and that's sometimes why I also Advocate um in practice simpler models uh because they are robust and they can make better use of data so going back to our example with the development dat we didn't use the neur network we used the generalized propensity score with a simple polinomial regression and that worked very well and it outperformed way more complex approaches like generative adversar networks neuron networks at large who would you like to thank my team I think that's really great inspiration and when we have a discussion about new ideas and I think uh we're currently of course are in have submitted or some working papers recently we're currently working on some new ideas so I'm looking forward to the next week when we have our team meetings uh this sit here and see what cool ideas we came up with what question would you like to ask me no good on spot sorry I'm not a media staff for that reason earlier in your career you not only worked at McKenzie but you also started your own company startup what did you learn from the experience um as I always say you learn from errors you don't learn from success that's at least also evidence-based um in management research one thing was we wanted to use machine learning to improve corporate communication um that was back in 2015 um way ahead maybe of the current AI hype wave um and one lesson learned is we were way too early we had to do educate our customers not only what are the benefits but also to trust in these AI systems that this was eventually impossible and that was maybe one lesson learned the second one is we had a product that was required customization um so the sales funer was way too complex for actually a simple product that then also needed customization um and third one was test always your ideas early don't be attached to your um ideas too much sometimes academics are really not great in founding startups because we laugh our ideas we laugh our algorithms that we developed but we don't give up if we see a better business opportunity so sometimes you need really an entrepreneurial mindset to be successful in with startup I wasn't I'm attached to my ideas so um I leave that uh part of the world to my students um and some of them have uh founded great startups for example one is ethn AI it's a Zurich based manufacturing startup that uses also cause machine learning in order to Pro improve manufacturing processes do you think that those lessons regarding not being um attached to your ideas testing ideas early and so on are those lessons also applicable in research course I'm sometimes teaching executive courses or students also or courses to management students and then I have to tell them like how much time should they actually invest in machine learning products or ideas and when to maybe give up and there I have my one day rule if you get for a standard and please apologize I'm not talking about cause of machine learning here I'm talking about the standard traditional machine learning approach where you maybe need a linear regression or a random Forest if you can make that work on your data set on the first day this is topically a good example for a good case for machine learning and that can benefit but if you don't get a satisfying performance on the first day maybe your data set maybe your mods are not bad but maybe your sort of data set is bad or maybe your task is simply not solvable by Machine learning and I think sometimes you need to give up on uh early on because otherwise you simply are biased towards like because I invested so much I now invest more and those are first projects that are really successful second those are the projects where students are really happy with because they see that they are running always against that they always receive some tension and that sort of the ideas are not just flowing so smooth and third those are often like also not the inspiring things and maybe not like the big step forward Stefan what's your message to the caal python Community um we need more packages like econ ML and dou ML and maybe more um packages and software tools that also attach other parts of the Cel c pipeline for example uh our group is working heavily on par identification but still there is not yet of like fully fledged comprehensive uh package or library for par identification in Python and I think sometimes I think there are still some white uh empty spots on the chess field where we need some libraries and I think that could help make some of the IDE could really help up in the uptake of ideas before we finish I wanted to ask you one more question that I don't typically ask um I asked you about your message to to the causal python Community people who are doing stuff similar to the stuff we are doing what would you say to people in management roles or to entrepreneurs when it comes to their perspective uh on on machine learning analytics and and and causal machine learning when I have executive meetings especially now in the generative AI era I often ask who of you has used J gbt all hands go up and then I ask the question who of you is using cat gbt on a daily basis and let me spoiler you the answer I see almost no hand there and I think that tells us a lot like of course companies have of course Financial constraints they have a business model that they are invested in and they have limited capabilities of course also and um time pressure but I think we need to test these ideas and uh in order to understand where which methods work in order to identify the you the effective use cases and the same is for cause and machine learning sometimes maybe a simple s learner AK our traditional machine learning method might be suitable for many applications but maybe there others where you need a bit more a riger or you want to go the extra mile and there you may want to have a CA a forest or a nice model from the double ml uh package Suite or um another doubly robust learner so I think it really end depends and that means sometimes in particular with the challenges of observing the counterfactual values the unobserved ones um we need to test and see what works also in practice and which is sufficiently robust there that's a great message thank you so much Stefan for your time it was a great conversation thanks Alex thank you