a very interesting metaphor to me comes from Kad lens was one of the fathers of ethology study of animal behavior and he at some point said that thinking is nothing but acting in an imagined space but then there's another aspect of biological systems which is that our training data is is finite and I think some of the questions around gentic modeling especially when it comes to controllable generation a lot of people are working on this and don't even know that this has something to do with causality I think the general idea is if you have an internal World model you can learn without having to risk your life every time hey caal Bandits welcome to the causal Bandits podcast the best podcast on causality and machine learning on the internet today we're traveling to Los Angeles to meet our guest his curiosity inspired him to study Physics and Mathematics he completed his PhD under the supervision of the legendary Vladimir vapnik he worked with at and t-bell Labs Microsoft research Amazon and mobile recipient of the ACM Allen newal award co-founder of Ellison director at the max plank Institute for intelligent systems Professor burnhard chock let me pass it to your host Alex molak welcome to the podcast Bernhard thank you very much how how uh do you like the conference so far I think it's it's very exciting very interesting talks and it's a it's a it feels like a nice Community is forming around these problems at the intersection or maybe also in the Union of causal insurance and and machine learning so it's uh exciting to see this uh coming together what brought you into causality your background is very is very rich what was the one or two aspects that that brought you that attracted you to this field yeah so it I think it was there were several things coming together maybe the first one was at some point I was and this maybe this already 20 25 years ago I was invited to a conference which was called the interface I don't know if it still exists it was a conference somehow I don't know maybe it was the interface between statistics and computer science and it was held not far from here I think in Orange County so I was invited to give talk I was working on Colonel meths those days and uh but then there was some other very interesting in talks and one of them was by pill and I was quite blown away that there is such a theory of cly entrance and I I had always found this interesting from a philosophical point of view causality and to understand that this is studied using tools of mathematics I thought was fascinating at the same time I was also very excited about the Fe that I was working here at the time so I didn't I didn't change my research Direction H but then some years later old friend of mine Dominique Jansen came and said and he was working in Quantum information Theory at the time he had a student who wanted to work with him on causality and told him look I don't really work on causality but then uh we started talking about it together and we thought well it's not so far from machine learning and maybe we can advis the student together and then we uh basically this student was so persistent she said he he wants to work on this with us and then he convinced us and then we started getting into that field and got more and more sucked into it and at some point I I I almost stopped working C methods or now it's just a small fraction of what I do and I I work mostly on C it and and it's I think it's U maybe to me at some point you know at the beginning we were interested in the standard problems of causality caal Discovery caal graphs and so on but pretty soon it became clear to me that actually many of the interesting open problems with machine learning are connected to causality so I I didn't see it as two separate things anymore but actually as a way to make progress and fundamental problems machine learning and inference what was the story behind behind the book you call for ments of causal inference um well we had worked on causality for some time I don't know when we started writing I don't remember exactly and earlier I had written a book about Colonel methods with Alex H and you know writing a book is very painful and if you finished one and we must have worked on that for I don't know four or five years finish one book you swear to yourself never going to write a book again and but then uh this was maybe 10 years in the past I had forgotten about that and then Dominic and and I we start talking about writing a book and we had a very good student I guess he must have still been a student when when we started thinking about it Yas Peters but then he graduated and then the three of us said why don't we try to do that together and we I think we were thinking similarly we also were all reasonably close mathematics and we we thought it would be nice to have a modern treatment so reasonably compact of the the main ideas of cality and it was actually fun it was maybe it was actually a little bit less painful than the first book because from the start we said let's try to keep it reasonably short and if someone is thinking about writing a book I would always give the recommendation try to aim for something short it's going to get longer anyway um and try to finish it within two years otherwise it becomes if it starts dragging out it's too painful as an offer myself I must say I think this is an excellent piece of advice now we're working on another one yes oh what is it about about caal representation building okay that's great I didn't know about it yeah so it's still still work in progress I hope let's see I hope we can finish sometime this year MH can you share something with the audience already about the book uh maybe about the structure or the content of the main main ideas capture it will cover of course some basics of causality but we also thinking a lot about representation learning so you know nowadays modern machine learning is a lot is about representation learning High dimensional generative models and uh if you yeah if you anal analyze High dimensional data of course or in general machine learning as long as you're in an IID settings or independent identically distributed data it is enough to just look at correlation statistic dependencies and uh exploit these if you are in a setting where things change and change could mean that the distribution changes it could also mean that the variables that you measure change so today you see the set of variables tomorrow you see another set of variables so all these settings that occur a lot in the real world from our point of view have to do with causality and now when it comes to caal representation learning uh there's this idea that you sometimes have high dimensional data uh where they are the entities which should be modeled caely on not given to you so you might see a scene with some objects in it and nobody tells you a prior which pixels belong together and form an object so you have to somehow learn this you have to either learn it by having a data set where things change you know sometimes moves the lighting uh or sometimes moves the camera position or someone moves the camera or or you get to move the object yourself so there are ways to violate the IID assumption that also give you a hint as to how you should represent data in the first place and what what are the the objects or the symbols or or the low dimensional representations that actually should be uh scrutinized or should be learned so so we're trying to move the field a little bit in this direction I need understand understand this better and of course it has to do with the classical problem of causal Discovery but we think it's not identical to that so it's a little bit like if you think of you know one of the major advances of machine learning compared to classical AI is that in classical AI we assume that the symbols are given and then we think of algorithms how the symbols should be processed so if you symbols could be a positions of the pieces on a chess board and the types of Chess figures that you have and if these are given to you you can think about clever algorithms uh to search through the game tree Etc but maybe they're not given to you maybe you just observe chess play and and you get manipul the symbols and you see how people chess and then it's hard problem maybe even harder than the actual chess problem to identify these things in the first place and find the representation of the data on which you then can perform reasoning learning Etc mhm and and how do you see causality entering this picture would you see it as another step going Beyond just learning the representation when I think about intelligence or artificial intelligence but actually I I like to think of it is a more General problem which is not just about artificial intelligence but also about natural intelligence systems so I think the most of course the only real examples of intelligence that we have are in the the Animal Kingdom so animal intelligence because those are really the examples where we have compelling forms of intelligence currently realized in the world and uh if you think about how humans or animals think then a very interesting metaphor to me comes from conard lawence was one of the fathers of ethology a study of animal behavior and he at some point said that thinking is nothing but acting in an imagined space now if you think about the current state of artificial artificial intelligence or machine learning G generative AI um it's a lot about representations we talked about that before but usually there are statistical representations so you have uh there are some statistical dependencies in the data and then you try to transform these dependencies in a in a useful space maybe a lower dimensional space or space that better generalizes to new programs Etc but by and large I think it's fair to say it's it's still about statistical representations what is correlated to what how can we do large scale pattern recognition and in the end I think if we're honest most of the impressive things that we can do with AI still lar sale pattern recognition pattern matching and so if we want to move in this direction to make the representations Interventional so if if we have a representation that allows us to act in the representation so thinking in an imagined space that then the representations have to include a notion of intervention and in action and I think that's moving things towards calicis so we have to find these representations and we have to find representations such that they uh permit actions in the representations we also have to find ways of representing ACS in in the same space we need some kind of working space and I think biology is a good example for that so people believe that there there's I mean we have visual CTIC there are certain representations that are driven by signals from outside not just outside but certainly strongly influenced by that but we have not only that we also have what biology is called efference copies we have copies of of actions that our PR produces with the goal of affecting the world outside or moving the eyes Etc and then if you have both things represented your actions and information coming from the world then then you start moving towards the internal model it allows you to simulate the world simulate your actions in the world and uh that should then be a first step towards uh understanding thinking I recently had a conversation with Andrew lampinen he's a researcher at Google deep M he works with agents reinforcement learning but he's also uh very interesting causality and in our discussion we had this um this threat uh you know where we also talked about biological systems that that you are also inspired by and we had this conversation that at least for humans and some other animals that we we we know of a large part of what we are learning might be correlational right so we we we do not always use causal models that probably from evolutionary perspective would not be the most efficient way also for us to function but causal models are very important tools for us nevertheless we talk today a lot in the community about artificial general general intelligence like agents that can learn on themselves and so on what is your Intuition or what is your hypothesis how those systems should be constructed and where should we find where should we look for the balance between correlational and symbolic or causal yeah I think that's a that's a deep question um I think in the past uh the AI Community sometimes we have been a little bit too fast with just dismissing stupid correlational learning so I think what we're experiencing today is sort of very compelling demonstration how far we can get with correlational learning so maybe that has to be said first and it's quite possible that a lot of what we do is based on correlational learning and there certain things that the brain has to do very fast and maybe sometimes doing explicit Cal reasoning might be more expensive and you might want to be able to have to react fast if a predator comes or something like that so I think correlation learning is great and maybe a lot of what we do should be about that but then there's another aspect of biological systems which is that our training data is is finite so we can't train on the whole internet so the most compelling correlation Learning System Foundation models LGE language models of course they use huge training sets they basically use the sort of collected cultural knowledge produced by billions of humans as so we are not in this situation so we have finite resour in terms of tra data we also have finite resources computational resources we have a finite sized brain we can't we can't grow it Beyond limits it takes a lot of energy I think biological systems have to be a little bit more clever about how they learn and and if you I suppose you have to learn multiple tasks and you have to learn them in a way that they work across multiple environments changing conditions I don't know that the light changes even if you just imagine how the color of the spectrum the light changes from morning through the middle of the day until the evening it doesn't make sense to will build a separate object recogition system let say you you want to eat an apple you want to recognize whether it's R from the physics point of view the apple looks very different in the morning the Spectrum reflected light looks very different in the morning from lunchtime still it looks the same to us so so we have methods that uh process this data we have methods of color consistency we have methods of of gain control control and once we have learned such a method of course this is a module we can apply not just for apples but also for PS and for recognizing people and for recognizing all sorts of things and I think this is just just one example how in biology once you have learned one module or one task if your resources are finite then you really try to reuse this somewhere else you learn in a more probably in a more modular fashion than what we do in modern AI cuz we're not forced to do this we we just make the system bigger and bigger so we're not forced to be clever about modules and but then the interesting thing is if you learn in a modulized fashion and if at the same time if it's true that the world is also composed of mod modules that play together then there's this fascinating thought that maybe they could be a bias that the modules that we learn might have something to do on a structural level with what's going on in the world and on the structural level because so for if we have a method in our T retina we have gain control mechanisms that allow us to to sort of exhibit some degree of invariance across a wide range of of brightness in the world now uh this module of course has in terms of physics nothing to do with how the world generates scenes of very brightnesses it doesn't know about the physics of the Sun and I don't know the atmosphere and so on and but this module could play a role that corresponds to a module in the world so so that's why I think it's interesting to think about C representations in terms of structure structural similarities in terms of so there could be some kind of it could be homomorphic properties sometimes you have certain transformations in the world that form a group and they might be represented also uh by preserving this structure and there's this a second aspect that for was discussed by by the physicist HS and he was saying that uh if we represent an object in our brain and then we think about the evolution of this object in thought then the result of this Evolution should correspond to performing The Evolution in the real world and then representing the evolved object so a special case if you think about interventions so I I take an object I look at the object if I then move the object and look at it again I should get the same result as if I first looked closed my eyes and just imagined performing the intervention in my brain MH so that's a a very different operation right I don't really move the object as just imagine moving it but I get to the same result so there's a commutative diagram going on which captures this kind of consistency so I think it's interesting to think about representations from this point of view MH that's that's very interesting and when we think about our own commission uh for for instance uh for the land of Daniel canman who recently passed way we see that this ability to simulate the world might be very good sometimes in certain cases but in certain other cases it fails there there's a very interesting body of work by a neuroscientist called Donald Hoffman I don't know if you're aware of him so he started by running simulations evolutionary simulations to check how agents in those simulations would learn reality right so he has some concept of reality and then agents uh under evolutionary press pressures in this environments and it turned out that the agents that were perceiving the environment in a way that was unbiased we're getting extinct in those simulations MH and so his conclusion from the study was that perhaps being biased towards whatever is good for our fitness is a better evolutionary strategy than seeing reality as it is do you think that this could be a good EXP explation of what we observe in in human and animal cognition and when we think about the simulations that you mentioned yeah could that be a reason why we are good at those simulations in certain aspects but in certain other aspects not necessarily yeah so I I think so simulations are something that's maybe relatively expensive mhm so I don't think we will do it in all tasks but then but there are some things so but there are so many different things uh interesting things connected to this so maybe a simp a simple case let's say you are you are trying to hunt an animal you have a spear you're trying to throw the spear um then maybe you have some kind of mental model depending so you have some input parameters the angle how you throw it the force that you put in and you have some kind of mental model how fast the sphere is going to get thrown but maybe if you have it if you've done it thousand of times you don't have to run this through this model anymore but maybe if you teach it to someone El you teach your your children how to hunt animals you might first explain and and show them some examples and and tell them about the principles so there's there's an aspect also of communication I think which is interesting especially when it comes to cultural learning it's a feel that I think we haven't studied much but that's extremely important for for human learning and then there might be other tasks that are more complicated than throwing up spars so let's say we want to work out what kind of food we can eat how how we have to prepare the food that we don't get sick afterwards we might have models of of these kind of things or we might eat something that does make us sick and then we want to be able to go back and say oh let me think about what have I eaten before what could it be this thing I've tried before I didn't get sick last time but what I did differently was these things so there are also processes of credit attribution not not just in eating but in many different problems where you can I think the general idea is if you have an internal World model you can learn without having to risk your life every time you learn you know you can you can also learn directly in the real world and maybe I think maybe many aspect of learning have many types of learning have this aspect and maybe can be done much more cheaply by doing them directly in the world but I I think I do think there are some aspects to human learning that do benefit from having internal World models and probably in the again there's a there's not a clearcut separation between the two and it might be something that at the beginning you do explicitly that somewh teaches you to brush your teeth and they say okay you have to touch each side of each tooth and you have to R the toothbrush or whatever and if you've done it a thousand of times it becomes an automatic thing when you brush your teeth you're not thinking anymore about what you're doing where it comes it's an automatic thing and you don't need a a world model to simulate you don't you're not focusing before you start doing it and making a plan for how you brush your teeth yeah on the other hand if I have uh Too Fake and I don't want to touch this one one too I it's pretty easy for me to imagine what how I should modify my action right not to not to touch it when I was reading the the elements of of causal inference I had an impression that this is one of those books that is inspired heavily by physics I don't know how heavily but compared to other books of cality probably it's hard to say heavily if we take this context what is there in the in the is this basic physical perspective that can help us when we think about causality yeah so I think that's interesting question so so first of all so do G and I are are both physicists uh originally so we met while studying physics uh we then later also moved into mathematics Yas SP is a mathematician so I guess the book is u in terms of motivations is quite as physics but it's trying to be also mathematically precise but it's probably I think it's fair to say it's closer to physics than most other texts about about causality and so from my point of view I don't want to speak for everybody you can think of you can describe causal systems on on multiple levels so uh or you could describe system you can model systems on on multiple levels of course and in you know machine learning we model them on the level of statistical dependency or or maybe even just correlations The Other Extreme is we can model differential equations so the gold standards in physics we say you have a couple system of nonlinear partial differential equations and if you manage to fit this to your data or to somehow come up with such a system through experimentation then that's the gold standard because it allows you to simulate the system it also allows you to reason about interventions about different side initial conditions Etc so once you have that you can do everything and that's the best thing you could do from the physics point of view and then the question is what's what's in between and uh one way to think about causality about structural causal models is that these are something in between uh hopefully preserving some of the Simplicity of of machine learning methods that you can still learn things from data without having a full mechanistic understanding of the system uh but at the same time allowing to understand what's going on allowing us to reason about so at least the class of interventions uh uh so so it's somewhere in between but it's still of course in the end it should be something that's consistent with the underlying physical reality as is described more closely by the differential equation system so we're also quite interested in questions like suppose you have such a physical system described by differential equation under which conditions and how can you abstract that into a structural go model for instance or or are levels in between are there ways of um capturing causality directly uh in dynamical system so I think from this point of view the thinking is inspired by physics we trying to be consistent with physics and also a lot of our work at about thinking one way to think of causality would be to say we think about mechanisms rather than uh about statistic dependencies and mechanisms are one level lower they give rise to statistic dependencies but a mechanism is something that from my point of view is a physical mer mechanism physical process I think this is also consistent with how some computer scientists think about cality I think Jud PE also fundamentally in the end thinks about mechanisms and tries to understand causality in terms of mechanisms so I would even view them philosophically as almost as a physicist thinking about about causality and then a lot of our work about independent mechanisms so coming up with additional assumptions that are not just mathematical or structural about goost PA but they try to capture something about how C systems are realized in the world physically realized I think that's also very much inspired by physics you talked about uh differential equations in one of the recent papers that you caller you proposed a a new formalism for talking about causality based on stochastic differential equations what was your motivation for this work yeah so I think you're referring to the work with last laws you yes I think that's a very interesting Direction um I think there were multi motiv motivations one is that often in practice if we look at Cost systems we we do have typ serious data forance if you look at biological problems you often have time serious data and second thing is often impractical cause of problems you can't guarantee that it's systems form a direct ayc graph you might have loops you can unroll the loops by extending things in time and then the question is whether structural cause models unrolled in time are still the optimal formalism for this or not and then so last was thinking about this proam and came up with a nality formulation and uh has a nice mathematical connection to Kernel methods he came up with a notion which called the kernel deviation from stationarity so I think it's an interesting framework to try to see how much of the causal formalism can we retain if we Mo this to this more General uh time dependent setting mhm what are two books that changed your life two books that change my life oh um you know it's hard to say whether these are you you mean science books or oh I live it to you okay let me think so I I I'm quite influenced by the literature of boses the Argentinian writer I've been thinking about boses for well ever since I disc discover actually I think I first read about boses in the book of dlas hofstatter it's this book gach which was old AI Bible and I read this before I even knew that the field of machine learning existed and here I think somewhere in this book or maybe in one of the other books of of sh he also reprints a very short text by boses which is called boses and I and uh it's about boses writing about the author boses and he says okay there's this guy and I read about him in the newspaper and he's written some stories he's written some useful texts but uh he somehow talks about things in a vain way that doesn't I don't I probably don't remember it in detail but it's a very interesting article that sort of works out the difference between him as a as an individual and him as an author and he starts seeing himself from the outside as an author through his published work and then at the end of the text he he says I don't know who of the two of us has written this text so I thought this is very interesting and then I started getting into boss so I think that's um that's one book that influenced me a book that try influenc me when I was a physicist for was interesting book by Hans Bas it's called chemistry quantum phys physics and reductionism MH so that's maybe one science book that I found very interesting and and then of course in machine learning uh I was early on quite influenced by the books of of viic who who was my PhD advisor um I managed to or I I ended up working with him through an exchange program and and I was looking around it was an exchange program with bell Labs where rnck worked and I was somehow I got my hands on a text of that was about different people at Babs that are working on things related to machine learning so there were lots of interesting people there I don't know y patri SAR isabe G and then bunch of people in there in the muray so these were all in home a bunch of people in the muray hill lab and and there was mck in the H lab and I didn't know mik before I saw this text but then I noticed he had written a book which was called estimation of dependencies from empirical data or statistical data I think emiral data and I looked at it and I was blown away because I thought wow this is I was always interested in this program why why and how can we perceive structure or perceive and identify non-random structure in the world and here there was a book of someone studying this mathematically and studying under which condition can we identify dependencies in the world and then I think that's even though the book is very dry and technical in places I think the underly philosophy influenced me a lot and then when I came to ftic maybe that influenced me even more he was just in the process of writing another book about learning theory and called it the nature of statistic learning theory that was uh maybe even a little bit more philosophical and it wasn't in process of writing it so I had to sort of proof read many versions of it and discuss many parts of that book with him so in a way I was lucky that arrived when he was working in this because that led to a lot of discussions and and some understanding of how he's thinking about this problem so this book which I got to know before it was even finished maybe that was the scientific book that influenced me most I don't know what's your message to the k Community and in particular where do you think or do you believe we should focus our efforts today in research in order to move the entire field forward yeah so I think one the simple answer is to say we have to come up with compelling applications so we have to I think in this community we understand and on a philosophical level we understand that it's not enough to just model statistic dependencies if we want to understand the world um but I think to convince the broader Community we need compelling applications so I think that's the one message the other message is I think we we have to really work at the face between causality and and generative modeling generative modeling is now it's a very Hot Topic in machine learning and I think some of the questions around generative modeling especially when it comes to controllable generation a lot of people are working on this and don't even know that this has something to do with causality so I think we as a causality community have get into this also we have to get our hands dirty and and understand how to train high performance generative models so we shouldn't be be afraid of new networks this is how currently these kind of problems are used but use them in a way that connects to causality in interesting ways I think that's what I would encourage people especially young students Ming into the field I think there's a lot of interesting things to do there mhm before we finish I would like to ask you one more question you studied physics and Mathematics and dealt with very very uh challenging Topics in in your career and you did this successful as at least as as it looks like from my perspective what would be your advice to people who are coming to complex Fields like causality or Advanced physics or mathematics what would be your advice what what should they focus on or what skills should they train in order to be successful in this field yeah one thing is to pick a good problem and you when you want to pick a program I think you want to pick one which is not already beaten to death so at some point I was before I moved into machine learning I was working on Quantum field Theory and algebraic quantum theory and it's absolutely beautiful field but um I mean we not going into that field many many smart people had already been thinking about it for 50 years or more than 50 years I mean you can you can do this but then the bar is quite high if you want to contribute something interesting perceptually new from that point of view uh choosing the right area I think is an important aspect but then once you've chosen it I think you should not be afraid of going into depth so if you are in an area which is not yet so much explored then my experience is almost no matter what you look at if you go into sufficient depth you find something intriguing and interesting so you just have to stick long enough with a problem and don't be dis encouraged if it doesn't work immediately because even if you don't solve what you set out to solve you will find something interesting if you dig deep so I would try to encourage people that's also what I tell my students don't not be afraid of that that's a beautiful advice M thank you so much it was a pleasure thank you thank you