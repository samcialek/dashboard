businesses usually want to take actions that have hopefully the effects they want to bring about occur and so in my mind that's all about you you know understanding the problem from a causal point of view at Spotify we've been having a lot of kind of success recently with like the types of projects we're working on and like the areas in which we're applying causal inference Beyond just what was the impact of that product launch or that new feature or whatever to really Drive actions and so forth so a lot of these are kind of at a late stage now so we're you know final testing and so forth and so I'm really hoping that they see the light of day where I can talk about them quite a lot publicly in one of your papers earlier papers you worked at the intersection of quantum physics and causality and your work was related to the ren box principle can you tell us a little bit more about this work hey caal Bandits welcome to the second season of the caal bandits podcast the best podcast on causality and AI on the internet as a child he loved Lego he chose to study quantum physics to keep his Joy of building alive his research has been published in nature journals accepted at top machine learning conferences and called a breakthrough by popular outlets in his free time he writes for new scientists and helps his students apply causal methods in new Fields ladies and gentlemen Dr Kieran Gilligan Lee let me pass it to your host Alex molak welcome to the podcast Kieran it's great to have you here thanks very much Alex it's it's a new new thing for me um a new thing for you I suppose as well it's the first online podcast and the first live podcast so there are two things that are that are very very new today I wanted to start with a very very general question um you came from background in in in quantum physics and then gradually you moved towards working with coal models and today uh you're the head of the advanced coal inference in inference Labb at Spotify what types of problems can caal AI help us with in companies like Spotify coal AI or coal modeling more broadly yeah it's a great question so in my view you know most questions we're interested in from a business point of view right businesses usually want to take actions that have hopefully hopefully the effects they want to bring about occur and so in my mind that's all about you you know understanding the problem from a causal point of view figuring out okay I take this action what effect will it cause usually in most kind of big tech companies we use lots of data to try and you know train models to understand the best things to kind of do that's uh you know suggested by our previous kind of data and so forth but all this data usually is kind of collectives in some sort of observational sense so you know there's selection biases going on there's other biases there's you know reasons why users do certain actions on you know various platforms and in big tech companies and so forth and so if we want to answer these kind of business questions which are you know from my point of VI fundamentally causal questions about cause and effect then we need to use causal inference to really take this observational and bias data remove those biases in the right way and then use it to kind of make these good actionable decisions for you know various business outcomes so you know it's a very vague high level answer we can go into specifics in a while but every time you want to understand what effect an action will have or decision will have on future business outcomes you need to use causal effect causal inference one of the methods that that I I saw in more than one of your papers is is synthetic control is there something special about this method that you find it particularly useful um especially in the context of of your work at Spotify so it's a great kind of methodology for when a treatment has a very precise time at which it's been administered to you know either a user or population or some unit that you want to understand the effect of that intervention on that unit um so when you have this very precise nature happen on this exact time on this exact day and so forth Sy itic control is great because you have a very clearly defined before treatment period and after treatment period um and in you know lots of cases Spotify sometimes is difficult to figure out what confounders would be the right things to do to adjust for various things synthetic control has a kind of nice approach in that once you can find similar looking enough units you can use them to construct a synthetic control as long as they haven't been impacted by the treatment as well um and then this thing can then help us understand what the impact of that treatment or intervention was on the specific unit at that time and it just turns out that a lot of kind of questions we we have in big kind of tech companies are really kind of questions where an intervention happens at a fixed point in time like a new feature is released on this day or you know a user interacts with an artist in a very fixed way on this point in time and we want to figure out what the impact of that is and future time points and so forth so it's a really useful methodology for that both when we have this very fixed kind of time period which the intervention happens and when perhaps it's difficult to figure out what this big set of confounders are that we could control maybe some of them are hidden from us but we do have a set of similar enough looking units that aren't impacted by the treatment and we can use those then to try and infer what the causal effect is synthetic control is also a very intuitive method like every time I talk about causality to someone who is not familiar with this topic and I talk about this method people tend to grasp it very very fast um and I think it's a great advantage of this method but perhaps at the same time it's also a disadvantage because this intuitiveness of of of the the structure of how synthetic control works uh can also make us more susceptible to believing that this method gives us causal identification out of the box which as we know is it's not true unfortunate in one of your papers you describe ways of combining synthetic control quas experimental methods with the framework of thex directed basically graphs and then you use both to Ure that you have causal identification and it also allows you to to put a sensitivity model on top of this later on yeah so synthetic controls are originally developed by economists and so forth uh and you know the kind of viewpoint of the economics background is somehow slightly different than let say the peran SCM computer sciency approach both are you know conceptually very related but there's kind of key differences in these two kind of uh groups of of of uh individuals so for the synthetic controls that were kind of in standardly known in the literature and so forth no one as far as I could have tell as far as I could see by the time I first you know came about to learn about synthetic controls nobody had drawn a dag about you know what the synthetic control model kind of looks like what the underlying graphical assumptions might be and so forth U and I thought this this to me coming from a very you know computer sciency background was strange it was like the first thing I did when I heard about them was draw a dag um it seemed to be a strange thing uh to do for synthetic controls cuz it just wasn't done in the literature up until that point but you know coming from this economics background the assumptions that went into the model were sometimes very semi- parametric so the underlying assumption was that you know there are these linear Factor models generating the time series evolution of the unit that we want to understand the impact of the treatment on as well as all these other similar units uh and when we say similar units in the economic situ what we meant was that it's the same linear Factor model or at least so the same family of linear Factor models that are influencing both the treated unit and these similar units that we're going to use to build this the synthetic control and so forth and we have to have some commitment that that underlying linear Factor model is the same before the treatment as after the treatment you know apart from the introduction of the treatment uh kind of impact itself um and so to me this seemed like a very kind of stringent set of assumptions and it didn't kind of lend itself at least in my mind very cleanly to doing things like sensitivity analysis what happens if that assumption breaks slightly or is slightly violated um because it's relying so stringently on the semi parametric kind of form it's hard to know what happens when you go outside that and so one of the first things we did when we started thinking about them in a kind of deeper way after drawing the dag was trying to figure out okay what set of assumptions will enable us to kind of show that you can identify this this synthetic control this counterfactual that'll help us figure out what this causal effect is um after the point at which it's been administered and you know we settled on a few assumptions that was nonparametric and then prove some general theorem that kind of allowed us to to show you can get these kind of um nice ident IFI ability uh results from these more general principles uh it's all about using ideas from kind of proximal causal inference so here instead of there being an underlying latent factor model you just assume there are these underlying latents driving the evolution of all these units the treated unit and these you know donor units that will hopefully build the synthetic control but instead of assuming further that you know there's this specific parameterization of this that they're linear factors uh of of of these kind of underlying drivers what you do is you just say well these drivers are proxies for these underlying latents we don't say specifically how they're functionally related we just say that they're proxies then you can use tools from proximal causal inference again here you have to make some assumptions about what it means for one variable to be aoxy of another right to tell you a bit of information about it even though it's not precisely what that variable is um but once you make those assumptions you can then dve these General identifiability results you don't have to rely on linearity and so forth but the cool thing about this is now that we have a really clear set of nonparametric assumptions we can check what happens when violated right we can build some synthetic or some sensitivity analysis around figuring out okay well if this assumption slightly doesn't adhere in the general that data generation process we're looking at here how wrong would we be right how much should we have confidence in the causal estimates that come out of this if let's say some of the assumptions are misspecified and some to some degree at least and so we can use these tools and to gain more confidence and so it's this marage of this kind of co uh sem peran approach with this econometrics idea uh to allow us to do kind of General sensitivity analysis and gain more confidence for these synthetic control estimates what are some of the ways that you that you build trust in your causal models it's a really good question because you know the main thing let's say uh deep learning practitioners think when they first are introduced let's say the causal methods is they're like wow there's so many assumptions here right like how can I really trust these results if all I have to make if I have to commit myself to these assumptions um and and you know forgetting that when they do calculations themselves there are these inherent assumptions going on that allow them to kind of be certain that their predictions will make sense and not kind of you know undergo domain shifts and very sort of things they just aren't generally used to making these these assumptions and so forth and so they don't think about them too much in my view having to make these assumptions upfront and think strongly about them is actually a bonus right it makes you really think deeply about does the data generation process in this specific problem does it actually seem reasonable that these assumptions are kind of uh you know uh satisfied in this case or should we really you know change up the methodology that we're using to try and extract insights from this and so generally there could be many ways in which these assumptions could be violated like for instance usually you have to control for confounders and you're obviously limited then you have to measure all re relevant confounders and you know there's no way that you can precisely know that you've captured all confounders but there are various kind of ways in which you can gain confidence in that fact right you might have some domain knowledge that'll tell you okay well I I presumably have missed some confounders here but from this domain I really know this confounder this is probably the most important confounder right like it would seem very strange to me as an expert to think that there's another confounder out there we haven't measured that's more important than this one so I can use how strongly that influences you know my my kind of methodology my end result to say okay well if I've missed something it'll be less important than this one still be important in principle but it's going to be less important than this then from that I can set bound on how much my effect estimate might change if I had actually measured that quantity and put it into my analysis and so forth and then you can still make kind of claims right maybe you won't be able to point identify the cause and effect right now exactly what it is but you can set at some upper and lower bounds and perhaps if those don't intersect zero you can say well there is a causal effect here right it's non zero and so that's maybe enough in some cases for certain business applications this new feature has a causal impact it's not close to zero and so forth so you can kind of by understanding these assumptions and then figuring out ways in which how the violations of them lead to changes in your causal effect estimation you can put bounds you can get more certain about these types of things um and to my mind that's that's like a feature not a bug of causal inference I haven't made this assumption forces you to think deeply but then also forces you to say okay well if they're violated I can still get some confidence in what's going on I'm not shooting on the do that's that's very interesting I think in deep learning we often love to forget that there is a lot of assumptions and those models as well right the main of the main one and probably the the most heavy one is is the IID assumption that Bernal shop called the biggest lie of machine learning I want to move a little bit towards something something more practical more applied what are the main challenges in causal machine learning engineering versus traditional machine learning engineering so I guess it's you know a lot of additional work needs to be done to make sure that any misspecification of some of the variables don't lead to you know big changes in the outcomes that we want to predict and so forth and sometimes one might naively want to add all the potential confounding variables one can think of right it could be in you know applications of Spotify there could be thousands of potential confounders hundreds potential confounders and you might naively think okay I should just condition on everything I should control for as many possible things as possible um but before you go to that engineering step right plugging things in to different estimators and you know all this kind of stuff you really have to kind of think okay are these things actual confounders there are a lot of results in in the literature that kind of show us that you know naively controlling for lots of things actually doesn't end up identifying the correct causal effect it actually leads to worse estimates right it's because some of those things may not be confounders they might be you know colliders between the treatment and the outcome and so forth and like you have to have this prior step before you go about and do all this engineering you really think deeply about okay what's the dag here what are Founders should that thing be in my adjustment set and so forth and then once you understand that you can kind of think further okay how noisy is my data what does it kind of look like what are the variances and so forth and that might guide you to specific methodology maybe you want to do like double machine learning or you know various other approaches here things like standard uh bread and butter like inverse propensity waiting and so forth there's many situations where given the type of data you're looking at that might not be the right thing right at the action space you're looking at at the confounder set have very large variance in their values some are very small some are very big can be difficult to kind of get reasonable control on the variance of some of your caal effect estimates and so forth so you have to think a bit more deeply than just plugging everything into a black box and then trusting what the outcome is you to think before you even do that and then when you look at the data you think about okay what methodology should I be using here to really get confidence in the out in in the outcome but also get as much out of the specific data I have as as possible so it's more about the conceptual framework that goes on before and even after the the kind of application of these methodologies of this engineering Feast before you moved to Spotify you worked at a startup in in healthcare what were some of the the results that you were able to get there using that was that was a really cool uh role that I was involved in there with a lot of kind of great scientists at that specific startup so I I moved to that startup directly from being in Academia and I you know I really I was working on causal inference at the time but applying it to a different domain and I really thought the more I learned about causal inference the more I thought oh this is really really kind of powerful right it feels like this could be really practical and could help you know make better decisions in various kind of uh fields and so forth and so I was you know found this job at this Healthcare startup we're doing research around trying to help kind of automate the kind of medical triage process right so H help patients when they come in they'll interact with some form of chatbot that will extract their symptoms risk factors and so forth and then we'll try and treiz and or figure out what disease is underlying their symptoms and then say okay maybe you need to go through GP Maybe maybe just go to a pharmacist or maybe you need to go to the emergency room right away and so in this kind of situation it's really critical to you know have really trustworthy methods making these recommendations right because you don't want to say the wrong thing to to a kind of patient um the way in which you know the the startup was working on this problem at the time was they were using what's called a uh disease model so you can think of it as like a big probabalistic graphical model has three different types of nodes so one is like your risk factors the next is the diseases and then the last one is the symptoms that patient is displaying and so forth and they had this that was constructed by you know medical professionals epidemiologists that input the direction of the arrows and all this kind of stuff uh but also we had you know conditional distributions between all these links in this big problemistic graphical model so we knew you know conditioned on this disease you know how likely certain symptoms were and so forth you know the the way to do diagnosis using such a disease model standard approach goes back to the mid 80s and the basic idea was to say okay given I've observed certain symptoms I want to figure out disease has the highest likelihood under this evidence or the highest posterior under this evidence which is which is to say you know what disease is most likely given given the evidence and so for anyone who's ever heard of the adage correlation not causation you might start to get a little bit worried now because you know if you're looking at diseases that are correlated with symptoms maybe that's not the right thing doctors really try and find the disease that's causing symptoms that way in which if they treat the disease then they'll know they'll reduce the symptoms or ateas that's the Hope um and we have we we kind of started looking into this a little bit you know Guided by this intuition and we found certain situations where this correlation approach was the complete wrong thing to do so one kind of clear example we found was if a patient came in with with tightness in their chest and kind of chest pain um then the the kind of disease model was outputting the highest likely disease being type two diabetes and this is strange right because if you ask a medical professional they'd say type two diabetes does not cause chest pain when you actually even looked at the graphical structure of of the model underlying that there was no a link between type two diabetes and chest pain so it was it was the wrong thing to do from a doctor's point of view but yet the model was outputting this and so what was going on under the hood was that you know if you had if you had chest pain with some probability you belong to the part of the population uh that's overweight and again if you belong to that population with some probability you you know have some chance of developing type two diabetes so there's this association between Type 2 diabetes and chest pain via this uh kind of confounder of being overweight and so forth so there it's this kind of classic case where there's a strong correlation but there's no cause of link and so what we ended up doing was reframing this diagnosis problem as a counterfactual reasoning task uh so this is a real kind of pean approach where we kind of asked okay um given given the symptoms are present so I've there it's factual evidence that I've observed I want to ask counter to that fact what would happen to those symptoms if I cured a specific disease if I intervened on a disease and was able to turn turn it off in this model and and it turned out that that was a much better thing to do when we compared the outcomes that came out of this approach to the kind of standard basian inference approach based on correlations and compared it to 44 doctors we found that the counterfactual approach was as good as the top 25% of of doctors whereas the correlation approach is only as good as the top 50% of doctors we doubled the accy by just going down this causal inference point of view and what's important to note here is like the disease model itself didn't change it was the exact same underlying probabilistic graphical model the same parameters we were just asking that model a different question and so to me that really illustrated The Power of cause and inference and that it kind of showed that using the standard correlational approach it's not the right thing to do but you got a big Improvement by using this kind of causal approach which was kind of cool and it was nice that it was in this critical area like healthcare where you could show that caus inference was you know quite important for this and important in the sense of making a prediction rather than just that say okay have have my data set I want to figure out how to quantify the effect of a given Tre M and so forth of what the what's the impact of a policy causal inference can help you do more it can help you predict or kind of infer what the impact might be in the future as well so I thought that was kind of cool coming from Academia into this kind of industrial world what is the most surprising thing you learned from applying causal modeling in Industry so there's a few interesting things I I I guess the first is when you first hear about there can be confounding bias and you to control for it to kind of reduce you know raw correlations between variables to check okay if I after I control the is how much correlation is left over right and that's meant to be the causal effect if I've controlled foren Founders given various additional assumptions and so forth but if you had a range of treatments or a range of actions let's say that you could take um and you first looked at the correlation between these treatments or these actions on the outcome you want to move right perhaps it's a it's a marketing campaign and a big kind of company perhaps it's a specific drug in a medical context or things like this and you have many options you might think because I'm controlling for the same confounders in all cases that even though the correlations aren't the right way to think about the impact the relative orderings between all these different actions all these different treatments might persist even after we control for confounding so you might think okay well the one that has the highest correlation as long as there's still some Association after I've controlled for things that's the one that's going to have the highest causal impact even though I can't know what that causal impact would be just looking at correlations turns out that in many cases this is completely wrong the the orderings of things can absolutely flip things that have reasonably small correlations can have bigger causal effects than uh treatments that have big correlations and so forth and so you really have to you know adjust your intuition thinking about these problems in a statistical way to really think about when this caruse away and you know controlling for confounders can be very different for different treatments and that's a kind of big thing uh so that was kind of a surprising thing to me because at priori wasn't absolutely clear that that would have been the case perhaps it's good enough to select the best treatment by just looking at the correlations and so forth because you'd think the relative ordings would be preserved under controlling for confounding but but it turns out in practice this is completely wrong that's a very interesting point um especially that the strength of correlation and it's persistent over time are two criteria that are part of the Bradford Hill criteria for discovering cation right so if we take them in isolation it's so easy to fall for this trap this reminds me about this website from Tyler vgan or Vian I don't know uh who finds surprising correlations between different typ serious like the number of drownings and movies with Nicholas Cage and so on and so on so sometimes I use one of those examples about non-commercial space launchers and phds in sociology a it in the in the US and I show people that correlation there is pretty strong and it's consistent over over a period of 12 Years although it seems intuitively um well not connected those two those two different events this consistency over time makes some people think if maybe they are they are related when you start to think about it a bit deeper realize in that specific example you know there's probably only like 12 data points right one per year yeah right so if we want to think about what a correlation is we probably need more than 12 data points to be certain uh kind of statistical Association persists you know um so you can get tricked in this way by looking at these things I I remember looking at that website a while ago one of my favorite ones was um there's a strong correlation between the height of tides in Venice and the price of bread in London so it feels you TR like like the there's no connection there should be no connection between these two things but when you kind of think about it right the whole of science is kind of based on this idea that there should be some underlying explanation to a correlation right as long as it persists in a certain level over time and so forth it's not just a like a fluctuation and so forth um and so there was this guy called Reichenbach who was this philosopher uh who kind of formalized this kind of principle of two things are correlated then there should be an explanation for that fact right um so either there should be exist a common cause and their Mutual past that explains this Association so in the case of you know tides and uh in Venice and the price of bread London it could be that actually the hide of Tides tells tells us when shipments from other company other countries come in to England uh you know high tides mean the the ships come in and then bread is delivered so Supply is high and demand is maybe low at that point and so that sets the price and then that also is correlated with the hide of tides in in Venice right because they could be you know geographically reasonably close and so forth um so that could be one explanation or it could be the fact that similar to that example you gave right that actually the data points we have to witness this specific Association are actually reasonably small and so it could just be a random statistical fluctuation and we just so happen to look at it at that point um and in in that case you know like naively you might think well how how can I represent that as a dag right what as a common cause I can understand right there's a thing in the past that has two arrows into these two outcomes and by conditioning on that I explain away the correlations between these two outcomes whereas in this case of having a small number of of data points it feels more difficult but if you think about it a bit more you can kind of think that okay well the way it's the way in which I'm observing these two variables at that specific point in time and so the data points that I'm getting to to kind of you know uh witness this this correlation are both you know uh it's almost like a collider between these two things both are telling us at this point in time what that data set is and so conditioning on that specific data set induces this correlation can induce this correlation between these two things but in that sense the specific data set itself is the explanation right it's the fact that it's only over a small time period and had I looked at a longer time period maybe it would vanish maybe if I zoomed in a bit and looked at you know minute by- minute correlations or minute-by-minute data points maybe would go away and so forth um so it's you know it's really tricky to see correlations where intuitively as humans the kind of designed almost to try and look for an explanation I think that website is there to show us that that's the wrong thing to do but I think it's it just shows us how hard it is to do that uh but the whole you know Enterprise of science is founded on that idea that if there's correlation we need to explain it somehow or show that it's not a correlation by looking you know over longer periods of time yeah that's that's very interesting what you said that maybe if we change the time scale we would not see the correlation there right or at least not not as strong so this reminds me of of my conversation with naftali Weinberger who devoted a significant amount of his time to stud add uh scale specific causal effects uh showing that the level of abstraction that we pick for our problem or causal variables can matter very very significantly you also mentioned the the riken Box principle and I'm really glad you you you brought this up because in one of your papers earlier papers you worked at the intersection of quantum physics and causality and your work was related to to the the reen backs principle can you tell us a little bit more about this work yeah I mean it was it was a lot of fun doing this project back in the day it was it was one of the first projects that I did in kind of causal inference in a way uh so it kind of got me uh got me into the kind of swing of things it's where I got the bug for you know thinking about things in this causal way but the kind of basic idea behind that the inspiration for that paper kind of came from two areas one is of which is you know in some of Pearl's early work uh you know he used this causal modeling framework dags and so forth to you know explain parent statistical paradoxes in a more kind of intuitive way so you know Simpson's Paradox Lord's Paradox and so forth so in those situations it turned out once you drew the dag and reasoned correctly using the dag rather than just looking at statistical associations things that were seeming paradoxes at the time right you know things can be associated in one way whereas when I condition on certain subsets today that Association can completely flip which one is the right one and so forth um but when you think about it from a causal point of view this Paradox is is resolved in a kind of clean way and we can understand what's actually going on um and you know in quantum physics there's a lot of chat about things that are parent physical paradoxes like you know schro dinger's Cat Spooky action out of distance all these things that you read a popular science book and they seem fanciful and crazy and they don't mesh with our everyday understanding of the world we kind of wondered whether you know by placing some of these phenomena on firm causal footing the way Pearl did you know with Simpsons Paradox and so forth we could understand them at a deeper level and perhaps these some of these paradoxes would be resolved a little bit um one of the kind of biggest ones that we kind of had in mind when we started out this work was this thing called Bell's theorem so John Bell was his Irish uh physicist uh he did a lot of work in the foundations of quantum mechanics as well as you know high energy physics and so forth um but one of his most kind of you know highly cited in red papers uh is is kind of a commentary on an earlier paper by Einstein and his collaborators podowski and Rosen where they kind of introduced this kind of notion of spooky action at a distance where you can have two physical systems uh that are very very far apart and when you kind of measure or intervene or do something to one of them all of a sudden the other one can respond or can you can learn information about this other one even though it's very very very far away so this seemed kind of counter to you know basic principles of physics right information can't travel faster than the speed of light but all of a sudden I can learn something about this this this this physical system that's very very far away from me just by looking at this one here so it seems paradoxical uh but Belle came along and Belle said well you know maybe it's not too paradoxical when you when when you kind of zoom out like here's a simple example that you can have the exact same phenomena happen I don't even have to talk about Quantum kind of physics to kind of get to there imagine having like two boxes I take a pair of gloves a left-handed and right-handed in one of the Box i b the left-handed one and one of the Box put the right-handed one I give them to my two friends who are going on airplanes to different parts of the world uh when one of them opens the box and you find it's the right-handed glove they know instantly that the other friend has the left-handed glove so I can learn something about that other box or the contents of that box even though it could be on the other side of the world um and I haven't done any kind of physical interaction with it I just given this one friend this one box and so forth and so maybe this kind of epor Ein Ros and Paradox is just exactly that right the the reason these two things have this property is because I prepared them together I I'm the common cause the way in which I you know put the gloves into the boxes and so forth and so by you know explaining that Association I can do it by just saying well I constructed it precisely in the way to have these associations or have these connections but show that actually you can't do that for the case of quantum correlations actually going down this causal explanatory route this you know idea based on Ren back principle these correlations have have an explanation turned out if if that explanation was was a classical object right was the descriptions of how these systems were prepared let's say um then that it's not enough to explain it you can show that the quantum correlations actually when you stipulate that that's the dag the correlations between them can violate uh you know um constraints on what that dag said about that joint distribution and so forth so you just can't explain it that way so it seems like a paradox and so we hope that you know understanding things from a causal point of view could help with this because the main Assumption of bell serum was that that common cause had to be a classical object classical random variable but you know if you said oh it's just a Quantum variable it's a Quantum system that's the common cause and if if I do that it seems intuitive that that would explain what's going on I prepare these two systems together in the same lab I send them both to different parts of the world the reason they're Associated is because the way I prepared them in this quantum kind of way and so forth but we didn't know how to use the language of causality in this kind of quantum setup right we didn't know how to say well what does it mean for two variables to be Associated via a Quantum variable and so forth um and so that was the starting point for the paper and we did a lot of work around how do you formalize the idea of a Quantum causal model how do you replace objects like the conditional distributions and standard causal models and the you know deterministic functions underlying them with you know relevant Quantum objects and how do you justify that that Association is the right way to do it and so forth and then once we have that you can start to kind of play with things like how do I use this formalism to do things like you know if I have a big Network what happens of I intervene here and what are the influences and all this kind of stuff so yeah it was it was a fun project to kind of get into the uh the the the frame of this CLE inference framework in this paper we also talk about Quantum CLE models if I'm not mistaken what's the different difference between Quantum and structural Cal models and is there a smooth transition between those two formalisms so when we think about Quantum effects they are specific to the quantum level and we don't observe them in the macro scale so I was wondering if based on your work you could tell us if there is a we know how to make a transition from the quantum level from Quantum causal model to a structural causal model yeah it's a it's it's a good question it kind of comes down to you know what are the actual mathematical objects in the quantum case that are analoges of you know these objects in in the standard sem case with classical random variabl so in the SC case you know the SC is is defined by both the structure of the graph as well as the the kind of deterministic functions underlying that and there's some variables that are observed and some variables that are hidden and so forth um and you know the deterministic functions plus our hidden variables or variables that I'm I'm uncertain about and have a prior over them are what generate the conditional distributions between different nodes and so for right just because I lack knowledge about some of these hidden variables I don't know exactly what this uh deterministic function is but I know there is some deterministic function mapping variable to another that's because I don't know this other variable and this is what kind of leads to this this kind of lack of knowledge and so forth and so in the quantum case we need to find analoges of both the deterministic functions and these conditional distributions that you arise from them by just you know not being aware of certain parts of the system and so forth and so quantumly you know like even though we we hear in the popular media that you know this this inherent Randomness in quantum physics and so forth there is an analog of deterministic operations it's called a unitary map um but the reason why it kind of gives rise to this stochastic evolution of quantum systems is in a lot of cases you know we don't know about the environment we don't know what's going on like we could have a very um delicate physical Mo molecule that we're trying to put into a super position and it can stay that way until something in the environment bounces off it or it hits it or whatever or information is lost from the system to the environment but if we just knew how to describe the entire environment that would become deterministic again right it wouldn't be this inherent uncertainty um and so you can show you know not by just saying okay well a unitary map is the direct analog of a deterministic map that's how I'm going to Define quantum caal models we didn't go that route in the paper we more so started from a more fundamental idea about you know what does it mean for one variable to be a common cause of two other variables or you know variables to be related in a kind of causal structure um and then showed from that basic more fundamental definition of what this this this this kind of what it means for you know variables to be related in the causal way that you can show that from that principle in the classical SCM case you get the terministic functions and conditional distributions and the quantum case you get these unitary maps and uh what are called Channel operators um what's interesting is in the in the channel operators it's a big Matrix you can kind of think of it um and on the diagonal of it are just conditional distributions the off diagonal points are these kind of variables that tell us about um the super position of the coherence between certain different you know States in a given physical system uh and so you know when we go from the micro to to to the macro realm usually this is described by a process called decoherence it's about losing information to the environment as you kind of go up to different kind of length scales of different physical scales and so forth um and you can show that as this process happens what that means mathematically is that the off diagonal terms in these operators go to zero and you just maintain these diagonal terms which turns out are exactly the conditional distributions that we see in standard SCS unitary Maps become deterministic Maps when we apply these decoherent channels and so so forth and you get this nice kind of transition between the these kind of two formalisms in in this specific way so yeah it was it was a lot of fun to to kind of work on this problem and try and figure out things in a causal way in the quantum realm recently after spending a couple of years in Industry you in a sense got back to physics but now not to the micro Quantum level but rather to uh the macro macro level the level of stars and galaxies and and and so on can you tell us a little bit uh more about the your recent projects your comeback to physics and how it relates to causal modeling when I left Academia I kind of maintained like an honorary position at University College London where I was doing a research fellowship before I joined industry um and over time I kind of buil so I'm now this honorary associate professor and what that comes with is interacting with students in you know various doctoral programs in UCL um giving some guest lectures taking some you know students into the lab for internships and so forth um and one student that I've been interacting with quite a lot you know saw some of the the kind of lectures I gave on causal inference and thought oh maybe those things would be really important for you know the the topic of my doct thesis which is all about astronomy and properties of galaxies and how galaxies evolve and all this kind of stuff because here you know usually when we think about physics we think about you know areas where we don't need causal inference because we have controlled experiments right if we can do controlled experiments we don't need to do causal physics um or causal inference but in cases like astronomy when we're looking at at the night sky we can't do these controlled experiments right if we want to understand uh why certain galaxies are the way they are we can't do this uh random intervention and so forth and figure what the consequences are uh so causal inference is a great toolkit to try and tease apart these processes and figure out what's causing what and so forth um so I've been working with the student whose name is seil mukes and his supervisors um at UCL so offer laav and will Harley um on a project that apparently is a kind of long expanding project in astronomy it's all about you know what's important for the evolution of of galaxies is is nature or nurture more important so nature is more like the environment that galaxies find themselves in and nurture is more like the internal processes of these galaxies and so forth and obviously you know as as in man cases like in biology and so forth these things are entangled together in you know difficult ways um uh and it turns out you can use caus inference to try and disentangle these types of things over time and so forth so one of the kind of main questions we we tried to address um uh in service of answering at least part of this this kind of question was you know do certain um does the environment that a Galaxy find itself in does that influence the star formation rate in that Galaxy so General background is there's two generally distinct classes of of galaxies one big red massive galaxies and one kind of you know younger blue kind of galaxies in the blue galaxies stars form and they're kind of made and so forth whereas in the red ones Stars generally don't form um and another interesting fact about these is that usually the red galaxies appear together in in kind of clusters so the environment of a red Galaxy is different to the environment of blue Galaxy which is usually on its own and so forth and so we wanted to understand does that clustering Behavior does that explain is that a causal effect uh for the star formation rate or is it that this just an association right has it got nothing to do causally it's just common cause that explains both kind of phenomena and so forth um so so NE and will spent uh many many long hours going through the astronomy literature uh and trying to figure out what's the D in this case right all these different processes what's causing what how can we be certain about the causal arrows they use various kind of techniques to do this plus lots of domain Knowledge from kind of astrophysics and in the end they had this beautiful tag that they had drawn and then we kind of took a couple discs with with data simulations and so forth and then tried to see okay could we figure out looking at uh the environment of the kind of galaxies and the star formation right what are the confounders between these these two objects um and uh they they found various candidates that when you when you control on them they what's called desparate the the kind of Association um so there're suff a sufficient adjustment set once you control for them you can be sure that whatever is left after the after the adjustment is you know causal effect assuming our diet is correct um and from that they found some interesting stuff which was yeah it it it it is the case that actually Galaxy suppresses star formation rate again assuming the diet is correct um and so you know the the more dense one's environment the less likely it is that they'll kind of form uh stars in in in in this kind of way which which was kind of cool but what was really cool is that actually you can you know unwind these processes back through time um and you can find out okay generally it's the case that um these uh the environment suppresses star formation right but in the early Universe you can it turns out actually that it enables star formation so it's really good for Star formation in the early universe but then over time it suppresses it and so forth and this kind of fin about the ear early Universe wasn't known before U so that that was kind of cool um papers uh we submitted to a journal a few weeks ago um so it should be on the archive soon um but yeah it was a lot of work kind of getting back to uh to physics and showing that actually causal inference is important for physic D this case is where we can't do controll experiments and here we can use these causal tools to try and answer fundamental questions about physical systems astronomical systems and and so forth what's the common denominator for all the activities you you've been doing uh in physics in science then going to Industry and we haven't mentioned it so far but you also write for new scientists so you also Popular popularize Science what is the what is the common the common cause of the common denominator behind all of this yeah I think I clearly have too much time on my hands doing all these these these different kinds of things um for me I mean there's there there's kind of two things so there one is that the thing that like interests me most in all these things is like the questions you can ask uh you know like interesting questions around why do we have this weird association between Quantum systems that are far apart how do we explain that like that's an interesting question to me uh the same with this astrophysics kind of stuff um and causal inference is like a really cool area where you get both these you know the ability to ask these deep philosophical questions like even going back to the ancient Greeks there's this philosopher called democratus he was one of the people him and his mentor uh you know physically or like um devis the idea of an atom before you could even do experiments right they said conceptually if I follow these principles atom must exist uh so you know they're really into this kind of foundational knowledge and so forth so democratus has this cool saying which is you know I I would give the kingdom of Persia if I could discover one true cause so you know it's all about understanding things cly is the most important thing in the world and you know from the point of view of philosophy that's all we should be doing at least that was his his view back back in the day um but also call it different spans you know way more practical things at the same time so it's this cool spectrum between foundational physical things um but also you know really useful tools that you can build when you understand what thing is a cause of what other thing and so forth um and for me this this kind of marriage is you know what really excites me um when I was five or six I remember going to Primary School um and we're talking about you know careers and what job you could have when you could grew up and all this kind of stuff and all I liked doing at the time was building Lego where I just would sit for hours and put the blocks together in various ways and so forth so remember asking my parents when I came home that day uh I was like what job could I get where I could just build Lego all day that's all I wanted to do and they were like oh if you could be an engineer that's kind of what you could do so over time I was really into this practical building things together and so forth but also as a grer I got more interested in these more foundational questions and drifted away from the Practical kind of aspect of these kind of things but still you know I really wanted to do something useful in addition to understanding things or you know answering these interesting fundamental questions or at least trying to um so cause of inference was this kind of perfect area where you could marry both these two things do something applied and practical while also still some of the time doing things that are kind of foundational and asking interesting questions about the world great um a few way few few weeks ago we both uh had an opportunity to speak at the RO Society in London during the C CI conference um and one thing that I noticed there was was that people got really interested in different types of methods that allow us to do causal inference when some of the assumptions are violated what materials would you recommend to practitioners today for for them to to get a chance to familiarize themselves with some of those methods that in your experience are useful in practice yeah it's a great question there there are a lot of kind of really good um resources out there both from you know academic papers to textbooks to notes that are online and so forth so one of the places that you know I first kind of got deep into this was I read a paper by um Victor V and his collaborator which had a great title which is sense and sensitivity analysis right play on the Jane Austin kind of stuff um and so there they had a really kind of clear way for introducing um you know methods to do sensitivity analysis why it's important but also you know how to illustrate that in a nice graphical way where you could explain the you know how certain you are about certain VI ation of certain assumptions in a way that's easily understandable by maybe a non-expert or someone who wants to understand what the causal effect is they don't really understand the mathematical details but you can show them a nice picture graph that really explains okay should I be confident the in these results or not so I think that paper is really good um and there's kind of lots of interesting other papers there's a guy called Carlos canelli and he has lots of nice papers and a nice package as well you can kind of use to to do these types of sensitivity analyses um and there's you know lots of other ones there's a great one called uh uh equality constraints and cause of inflence by Pearl and his collaborators it's all about figuring out okay where certain types of assumptions occur in many different causal inference uh um cases so you like even in difference and difference we have to make assumptions that you know the before and after is the is the kind of same or it's the same confounders that influencing in both cases um and so it's a kind of equ quality constraint that has to be the same or has to be equal and so forth there's lots of other areas where these equality constraints pop up and you can show when they're violated in certain ways you can get sensitivity bounds and all these kind of things and say okay well if that's violated by this much how much would my causal effect be violated by and you can understand then how to propagate these kind of uncertainties about the assumptions to uncertainties about the caal effect estimates so there where I would start um and I think there's you know a lot of cool uh a lot of cool other resources out they're just generally about causal techniques that kind of help in understanding these kind of slightly more advanced kind of things great before we conclude I wanted to go back back to your personal experiences what are two books that changed your life well one actually going back to the discussion on um kind of causal physics that kind of kicked us off earlier on um this this book by this physicist John Bell it's called speakable and unspeakable in quantum physics and it's all about you know it's a collection of his papers and stuff um and there you can kind of see you know how he derived his theorem and how he actually could see him even in the mid-60s thinking along these causal way like he drew something that looked kind of like a dag even though nobody was drawing dags then so like you explained that you know you could have these types of associations and they could be explained by a common Calla all that kind of stuff and the more I learned about this I was like this is wild right even before we get to applications and quantum physics that's interesting right this way of formalizing things so there's a great paper in there called um LEL Cuisine that really like spells itself for General audience it's really cool so that book was I think yeah transformative um what's what's interesting actually when when I think about it so when I did my masters um in in Canada in theoretical physics and I was thinking about Bell theum and I was working with someone there called um Rob speckin who's big into this kind of marriage between causal and quantum physics he I started a project with my Master's thesis and I just finished reading this book by John Bell uh and Rob took down a book uh from a shelf and handed it to me and said okay we're going to do something in this area read a few chapters from this and come back to me and we'll chat about specific problems and the book turned out to be causality by Pearl I was like what is this book like this is wild or whatever so you can flick to the indix of of causality and it's a great kind of um transcript of of one of Pearl's public lectures explaining all these phenomena like the do operator and all this kind of stuff so like once I read that and connected it back to this book by John Bell like you could draw these dags and all this kind of stuff I was kind of hooked on this kind of interplay between these two areas so for me reading those two books had a big effect both on my research in quantum physics but then also my decision to go and work more and they kind of cause a lot side of things um and it was just interesting that they happened so close together in time and so forth so yeah so for me it would be those two what would be your message to the coal Community when I first kind of left Academia and kind of you know took this plunge into industry I really felt that we could use these causal tools to do something useful and I couldn't really find a lot of examples apart from you know like understand the impact of various policies and so forth and kind of kind of econometrics even though at that point I hadn't been exposed to a lot of these papers um but like in big industrial companies I hadn't found places where we were using these tools in a really interesting way to actually both make decisions but also Drive decisions so not just do retrospective analyses to understand okay was this product launch did it have the impact we wanted it have but how to build a new product using CA inference right to me this seemed like a really cool thing to to kind of do and something that we should devote time to because it's more trustworthy and all these kind of things but no one really done it at that point at least I hadn't come across anyone who had done it um and so I like I really think we have a lot to offer um and we should go out and try and find some interesting problems where we can apply these these tools cuz I think there's a lot of areas that are kind of crying out for them Beyond you know quantifying the effects of interventions and certain situations I think we can do more um and yeah I I I really feel like we should try hard to find these these kind of problems and start kind of working on them to really show the usefulness of of these tools in a broad spectrum of kind of ways um but I think as well you know we have these these two camps the you know the potential outcomes framework the sem framework and stuff and you know they're more similar than they're not and I think I think both Frameworks have useful things to teach the other framework so I think we should all work together a little bit more and kind of use conceptual advances from both to you know push both forward so I think we should go ahead and find us some problems uh and kind of push the toolkits we have uh to make them better and make them more applicable to these real world problems what's next for you so at Spotify we've been having a lot of kind of success recently with like the types of projects we're working on and like the areas in which we're applying causal inference Beyond just you know as I said before what was the impact of that product launch or that new feature or whatever you know to really Drive actions and so forth so uh a lot of these are kind of at a late stage now so we're you know final testing and so forth and so I'm really hoping that they uh kind of see the light of day where I can talk about them quite a lot publicly um so I think in the next few months that'll happen and you know uh if you follow me on Twitter I'll be talking about those all the time so I apologize in advance if if they hopefully turn out to be successful um so it's really driving those but also you know really kind of figuring out the best way to use causal inference to you know address interesting kind of questions right like what I left this uh startup that was you know involved in kind of healthcare stuff because you know after the initial success we had with this causal approach the diagnosis we had lots of kind of models that were all about you know how to uh personalize treatments the given users and all this kind of stuff and you know rightly so we couldn't just launch these products in the same way a tech company would launch them right because there are kind of ethical repercussions to do these things you need a lot of you know like um certificates and to pass all these kind of things and you know recommend these types of things to to users and so you know part of the reason why it came to Spotify is that a lot of the problems that we were dealing with at Spotify at a conceptual level at least are very similar right recommendations are kind of like treatments on a user right you want to find a song that will cause a user to enjoy it right the same way you want to find the treatment to cause a user symptoms to decrease and so forth I hope is that if we could show we could use CA of inference in this really kind of Novel way in this you know slightly lower stake setup right if you choose a bad song it's not the end of oral if you choose a bad treatment maybe it is um so you really want to show that it's useful right that you can do these things in a Way Beyond just quantifying you know the impact of a policy and so forth um and we're like almost there at Spotify we're almost launching products that are powered by causal inference and hopefully that will expand in the future but I really think the next Horizon is like trying to use techniques from causal representation learning to start doing this like in almost all big tech companies you know we learn embeddings of our users of our products and all these kind of things that describe certain products being similar certain users being similar and so forth and the standard way that that's done is using co-occurrence data so that is to say just correlations between these things certain users uh did the same type of action so they're close together in this embedding space and this kind of word Tove you know sequential Transformer style way um but if we're learning embeddings based on correl and then using them as inputs to a recommendation engine which is all about finding a treatment to cause an outcome or finding a piece of content to recommend to cause and joyment or whatever um but we're using correlations to to power that it seems like the wrong thing to do right so it feels like we could do better by learning a causal representation of users that you know find the factors or the latent factors underlying why users are similar or why they enjoyed a certain piece of content um and that could help us improve things and you know if we could demonstrate that at you place like Spotify that we could use these things and actually works then perhaps we could use them another high stakes domain like medicine or you know various other areas so that's what I'm yeah hoping to push towards in the next few years that sounds really great where can people find you and connect with you so I'm I'm on X or or Twitter every now and again even though it's you changing quite rapidly over the last few years um think my handle uh started when I was in quantum physics so I'm as Quantum Kiron a hangover from a from a bygone age um on LinkedIn as well you can send me an email either to my Spotify account or my UCL account I kind of check both regularly there you know um uh you can find them on my website and so forth um so yeah so if anyone has any questions please send me an email I was happy to chat about all things CLE great Kanan thank you so much it was a pleasure thanks Alex great Shing to you