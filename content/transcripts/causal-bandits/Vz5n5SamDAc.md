the thing that struck me was that each of these papers really well grounded in social science theories really well kind of backed up by by data analysis coming to these beautiful conclusions and then the very last side would inevitably be but this is observational data correlation is not causation anything could be going on we don't know once you start using causal analysis approaches to gather Insight from data you realize how important it is to to be driving any decision-making process causally rather than through a handwavy guess based on uh correlational analysis what's next for for duai and Eon so with the duai well one of the projects I'm excited about is hey causal Bandits welcome to the causal Bandits podcast the best podcast on causality and machine learning on the internet today we're traveling to Vancouver to meet our guest computer science is his long-standing love he moved from low-level computation to social Computing and from there to causality he's one of the core developers of the Dy Library a passionate climber and a family man senior principal research manager at Microsoft research ladies and Gentlemen please welcome Dr Emer K let me pass it to your host Alex mola ladies and Gentlemen please welcome amra kijan thanks very much Alex I'm I'm happy to be here I'm very happy you found the find a while to uh to join us for today's episode Em are large language models coal parats and if they are does it matter I think the question of whether large language models will be able to reason causally at some point is up and there maybe someday they will I don't think that they really are right now however the power that they bring the with their embedded knowledge about the world if we treat them as a beginning of a of Common Sense database about how the world World works I'm very excited about how that information can be used to help augment the causal analysis process today not replacing you know statistical estimation methods and all the algorithms we've been developing but really augmenting and opening up an opportunity to provide support for people who need domain expertise at their fingertips some kind of some kind of help for setting up their causal assumptions what would be the scenarios where you find llms to be the most useful to day mhm in in the causal in the context of causality and causal inference or causal Discovery process you know for a long time we've talked about the importance of the assumptions you bring to a causal process right I think it's a refrain that everyone says you can't get causality just from the data you need to bring in your own knowledge about the data generating process and what might be plausible What mechanisms might be plausible what information might be unobserved and until now we've had to tell people that they have to go and figure that out entirely on their own our computers can't help and what I'm most excited about at the moment is large language models coming in and providing us some way to provide technological support to people at that stage of analysis you know they can now come with a open question some data set and say what are the plausible causal mechanisms here that I should be considering and the llm can give them responses or they can come in and say here's what I think might be happening is there anything I'm missing and the large language model can critique their assumptions and uh tell them where they might be going wrong and maybe where they need more more verification or validation this doesn't mean of course that the domain expert shouldn't have the final say but it does mean that the domain experts burden is greatly alleviated they're not starting from scratch any more mhm in our conversation with ishan scupa from from BMW uh group we discussed using llms for this process of constructing the knowledge graph with domain experts yeah within the organization and one thing that I really liked uh that he shared with me was that LMS were not only helping them speed up the process but we're also an element I was providing additional motivation for the domain domain experts to share their knowledge because they were like they were presented with something like the initial graph that was obtained using large language models and then they were inspired to motivated to to also criticize it and share their knowledge and show that their knowledge is valuable so it was not only making the process more efficient TimeWise but also it was inspiring people to engage more within the process yes I was really excited when you told me about that story and I'm looking forward to going back to your last podcast and listening to the the full description of it I find that really exciting and it I can understand why you know we engage differently when when we feel like what we're doing is is valued and so if you see that someone has taken the effort to already build a causal graph and you can start to see the connections about how that information is going to be used for you know the task that I can I can understand how that would be very engaging right and so that's interesting that the technology is changing but something about the human nature stays the same although the environment is different yes yeah what do you think are the most important challenges today when it comes to causality causal inference causal discovery in general working with caal caal models I mean from I guess it depends on whether we're think talking about this from an academic or practical standpoint I think from the Practical standpoint just getting causal methods deployed more widely in every place where it might be relevant for decision- making and understanding of the world um I think that uh education is still quite critical I think uh just understanding the basics of causal Concepts and how they and how to work I think other fields like you know basic statistics for example have a have a leg up on causality there so I think we need to make some more more progress but it's it's happening with you know books like yours for example on the academic front I think that there's wide open opportunity we've gone very deep on algorithms and processes for a set number of tasks but as computers are becoming more widely deployed um all around Industries and Society I think there's a lot more data about a much broader set of problems and so that means that you know simple effect inference under like binary treatment is that's already considered a rather simplistic case I think we're seeing that there's now a much broader set of tasks and so I think that there's a lot of opportunity for example I think more complex modeling of more complex physical processes where you have feedback loops over time I think that's that's something that's something that causality should be tackling and you know again like wide open opportunity to to find the right approaches for for modeling those systems you started working with causality relatively early uh before it it became popular recently not as literally as many people right I mean it's been going on for for decades yeah centuries yeah but of course we have those waves right so I'm referring to the maybe the most recent the most recent wave yeah and taking this as a as a point of of reference what was your journey to to calti what made you inspire to start asking those questions and dig deeper into this area of research yes I was at a point where I was working on a research topic related to computational social science and particular uh the analysis of large- scale social media data to gain insights about the world around us about how people behave in the world how do people make friends where do people want to go during the day what what drives Health decisions it's all sorts of really fascinating topics um but all coming from what people were just happening to to talk about on a public social media and what I found one day was one very specific day when I was at a conference and there was you know an academic conference and people were talking about these really exciting insights they were gaining and one of the things the the thing that struck me was that each of these papers really well grounded in social science theories really well kind of backed up by by data analysis coming to these beautiful conclusions and then the very last side would inevitably be but this is observational data correlation is not causation anything could be going on we don't know and that was so disappointing it's like you you've got this beautiful balloon at the the very end of your presentation you just pop it and you say uh we don't really know and that was and that uh I had heard about this thing called causal causal inference and that you could under certain conditions actually make causal claims based on observational data and so that was that was the day when I decided you know I need to go learn that and bring it back to this Pro this task here this problem MH MH how did you start learning about causality what was your your journey there my first step was to pick up Pearl's causality book that's courageous yes my second step was to put it down no I I I really tried hard but it was difficult for me to to to make progress with with that book immediately so I started looking at uh papers uh just any paper I could get my hands on about about causality and how people were applying it to uh real problems and in the end the one that really helped me click with just the the intuition behind why observational data might give you any hints about causality was the Rosen bal's paper on um the importance of propense two scores it's a classic paper from yeah the 70s yeah and that paper there was just it had just a very very clear description of how the propensity score acted as a balancing score to balance your control and treatment groups such that at least for the features that you were explicitly accounting for so the causal assumptions that you were basically simulating a randomized uh control trial right obviously you know not a real randomized control trial which would requires fewer assumptions but um still that intuition suddenly made things click for me and then from there I was able to better understand graphs and make my way back to Pearl's book yeah and the rest of the literature yeah P Cal is a book that might be very very challenging for anyone just starting with the topic because of the way it's constructed it's a great book it's amazing book I call it the talmood of causality uh because it not only contains the content itself but also commentary on this content and commentary on someone's commentary on this content and so on but nevertheless it can be very challenging for someone who is just just starting yeah today we are in a much better situation in terms of available resour ources M what resources would you recommend to people who are just starting with coal I think depending on where they're coming from uh there's different different resources I think there's quite a few new books out there I haven't read all of them or most of them even but I have most of them I think I just haven't read them um and I think that you know someone who's coming from like a data scientist or programming background is going to probably want a different path than someone who's coming from a a statistics background for example I do see most books seem to be organized by Method right so here's perens score based approaches here's double ml based approaches here's instrumental variable based approaches and I think that's that's great I do wish that there was something that uh a resource that approached it more from a high level Concepts first and then you know the methods happen to implement those Concepts right uh kind of providing a broader umbrella over the materi over the area you're one of the uh creators of duai and econom packages what was the main driver for you to engage in those projects it was really a desire to you know broaden the usage of these methods once you start using causal analysis approaches to gather Insight from data you realize how important it is to be uh you know driving any decision-making process causally rather than through a handwavy guess based on uh a correlational analysis it just makes your assumptions much clearer and it makes it much easier to recognize the limits of your analysis and the places where you can be highly confident about the the outcomes we uh with amid charma uh the two of us started giving a tutorial about causal approaches with the the purpose of you know educating more people about these these methods and we found that uh and we we started working on the Dy Library almost like a pedagogical example right just so we had some library that could you know we could use for coding examples and that was actually so that was one of the reasons why we've structured the DOI Library around these four stages of causal analysis you know coming up with your your models and your assumptions uh then uh analyzing those models to to identify a causal es demand and figure out an approach to answering a causal question a third stage then being actually doing the statistical estimation to calculate the your values from data and then at the very end validating your assumptions or uh refuting them trying to refute them and I guess this ties into what I was saying earlier about about that kind of highlevel process overview these are four steps that you have to do regardless of what uh causal estimation methods your your you're working with that was that pedagogical library then people found started finding useful and so we started thinking harder about you know how what we needed to do to make it more robust and more practically useful and it's it's grown quite a bit since then and we've you know joined we've broaden the initiative and a lot of people have joined in on the effort to make it a a robust library and we've also become part of a broader ecosystem of libraries that are working together for different aspects of of causal analysis DUI has been now moved to a new project recently uh called piy can you tell our audience a little bit more about this project and the motivation about organizing the structure around duai and other libraries in this in this way yeah the purpose of the duai library was always to broaden usage of these methods right that's the pedagogical interest and then the the kind of the more practical reason for making it a robust data science library and that was also what drove uh the creation of the the piwi organization so DUI was an open source project under Microsoft's GitHub organization and when others wanted to join in you know it didn't quite feel right for it to to be uh a Microsoft organization still so Amazon in particular uh wanted to join in with the significant contribution we said you know for the purposes of continuing to grow the and Foster the community around uh causal inference it was the right thing to do to make it an independent organization and since then then we've had great contributions from also from MIT and Colombia we have uh Carnegie melon as a key partner having contributed uh the causal learn package the python version of of the tetr algorithms and more as well as contributions from wise as well that's really great to see not only the growth of the package and the in the entire e ecosystem but also all those synergies that appear on the way and I think for many people it was really inspiring to see two major marketpl like Microsoft and Amazon contributing together to One open source tool it's one of those cases I think where we just see that empowering the community to make better uh decisions with uh CA analysis it's going to make data more valuable it's going to make Computing more valuable and that helps all of us beautiful I'm I'm a huge fan of this four-step process in DUI and I think it's it's really great every time I am teaching about causality I use this even if I don't talk about the software I'm using this as an example how you can structure your thinking about a causal yeah problem the the last step the reputation step is as I understand inspired by by the scientific method itself in a sense so a famous philosopher KL poer proposed in 1950s if I remember correctly that we can try to falsify theories we can never prove them but we can try to falsify them and so this idea of reputation seems to me very closely related to this uh idea coming from poer was that your inspiration or not not poer specifically but uh just generally the understanding that we can't that we can find in data signs of Contra things that contradict our assumptions but we can never know that we can never prove that the assumption is is completely correct if we could prove it it wouldn't be an assumption it also shows us that causal modeling is so close to the boundaries of human knowledge we just cannot prove stuff and that's just where we are as as as Humanity so in this sense for me this is the epome of of of scientific method of science itself yes I I think that causal Discovery and effect inference are really critical parts of of science it's the really core to what everyone does with experiments and with with what we're trying to do with understanding the world around us people use lots of different approaches and methods so I think what we tend to call you know causal effect inference and the specific approaches that we use aren't the only way that people get at that but conceptually yeah I agree with you entirely it's it's really at the core of science yeah mhm what's next for for DUI and econ so with the doy we are with well one of the projects I'm excited about is a piy llm right now it's an experimental Library starting up but uh the really what we're looking at is how we can incorporate llms into the analysis process with Dy so using piy llm to help people use llms to generate causal graphs and to refute to critique their assumptions so really plugging in certainly at the beginning and the end of this four-step analysis process and then experimenting with uh opportunities to do uh maybe like identification style analyses for example using domain knowledge to identify potential instrumental variables and also maybe even providing support to code up analyses as well so those are are a little bit uh tentative but we're relatively confident uh that will be able to use llms to in some way to bootstrap assumptions and critique assumptions causality recently is not always explicitly sometimes implicitly but at the Forefront of of of recent most hot discussions uh most engaged discussions about artificial intelligence it comes from the fact that the models like like like GPT then Sora and recently released large World model MH also works uh of yan leun JEA yes all of this stuff is going into the direction of modeling the world in some in some ways and if you want to model the world in in a way that is uh sound causality in in my opinion is is a is a necessary element of such a model what are your thoughts about all those generative and non-generative methods that we have today and do you think that those models can learn World models or causal worth models or approximately goal worth models I think it's it's plausible to think that they can I think with current like large language models I think there's you know you can imagine that the amount of data that they've seen has uh LED to observe for example many counterfactual scenarios and it's plausible that they could then that could lead them to actually Model A a true you know causal model if that was the most efficient representation for example however I don't think that we've necessarily done that on purpose and I certainly think that uh that even if uh this was true it you we would probably only have observed counterfactuals for certain you know you wouldn't have population support right at some point and once you start extrapolating not clear to me what would happen so do I believe that it's possible for these to possible for them to learn causal models I think it's possible do I think that they are no not now then there's a second kind of meta question especially on the language models which is they're not actually modeling the world they're modeling language and so now the question is if they are learning a causal model they're learning a causal model of language which is not the same thing as learning a causal model of of the world and so then I think we have to think about what would it mean for them to learn a model of language and then at what point would we think that that leads to something more something deeper that's a very squishy question I think very IL defined is probably the the formal way to say it as we move uh Foundation models to operate over different kinds of data not language but more direct observations of the world I think that'll give us an opportunity to think more clearly about what uh the models are actually capturing I think that's very interesting what you said about the support the population support for for those models so just for those people in our audience who are less familiar with the term support this means that observing the full scope of possible situations that rings a bell for me it's very close to my thinking about about these models as well especially when Sora was released mhm and open AI suggested uh that Sora is is a physics simulator I thought this is an overstatement and I think you can see this in the in the video so going back to the paparian logic right I would say that some of the videos and that that we've seen so far show falsify the claim that this is a physics simulator but they do not necessarily falsify the claim that this model learned to be an approximate physics simulator or or a local approximate physics simulator so it can simulate physics in certain areas but not necessarily in other areas and when we think about it from this point of view we can take broadly speaking perhaps two perspectives here one would be that the model only learns to predict something so it just learns certain shortcut that leads to a plausibly looking output or it really learns a function that is a correct or approximately correct function of how the world Works locally yeah what are your thoughts about this and which of those ways do you see as more plausible if any MH I think you're right that that if anything it's learning an approximate local simulation and I think that that's quite reasonable in some ways it ties into questions about whether these models whether it's okay for these models to be uh generating ungrounded responses or hallucinations if you're doing creative writing yes that's perfectly fine it's part of the the task if you're summarizing a conversation and you want to G make sure that summary is accurate no it's not okay similarly if you're write if you're asking something like Sora to generate a creative video it's fine if it skips Corners around physics and stuff to make the visual look look right like one of their example videos is two pirate ships battling in a coffee cup why do you need physics to to like it doesn't the the scenario doesn't make sense so why do you why do you care about whether you're violating physics or not and in that scenario the you know there's the waves of coffee in the coffee mug that look really really nice but if you think about it for a second why are there waves in a coffee cup that doesn't make sense right and so you you needed to to to violate physics in order to in order to satisfy the creative you know uh imperative and to make something look realistic right yes that's a paradox yeah I think it's fine that they that that they aren't following physics now the question is then when we do want them to correctly model uh the physics of the world are we going to have the right controls to allow us to do that you know like if I pick up a ball right here and drop it you know in a s a video and I say what's going to happen if I drop the ball it's probably going to say that it's going to drop but you know it's making an assumption about where we are my the ball is actually a helium balloon and it's going to go up instead those are all though that would be just as physically plausible and yet you know it's going to have to make an assumption about which one uh which approach to model and then how do we then change that assumption if we if we actually wanted something else that's a very interesting point in a sense I'm sometimes thinking about two axess there with those generative models one is like impressiveness and the second one is usefulness and sometimes something very impressive can be very useful for instance is in a example that you gave creative writing or creative video generation but sometimes impressive is negatively correlated with useful right in certain cases what do you think is the future of this generative Revolution that we are experiencing today oh it's so hard to tell I feel like we're we're at the beginning of the internet uh the commercial internet in the mid 90s right where we are going to we can start to see what's coming in the Horizon but it's going to take a while and we're there's a lot that's going to happen that we don't know like in the mid 90s I remember we could it was very clear that video was going to move over e-commerce was going to happen and yet you know taking e-commerce as an example it took at least 10 plus years for that to be plausible we needed to invent secure HTTP we needed to invent we need to engineer secure database backand so people couldn't hack the e-commerce databases we needed credit card companies to generate like fraud uh their fraud Pro policies to protect consumers before people felt comfortable all of this infrastructure and Engineering had to happen even though we could see that it was obviously going to happen and now I feel like we're in a similar spot we can and see that so much is possible but it's going to take more work and probably more work than we anticipate to make that happen I think we'll move faster than we did uh with the internet Revolution just uh pace of a change seems to be faster this time around but we'll we'll have to see and that leaves out analogously that leaves out um surprises like uber and Lyft style applications that were only plausible once you had smartphones and the internet together that something that was harder to see in the mid90s right and so what's the equivalent what's the complimentary technologies that are going to come along to make AI you know more even more impactful than we're imagining today I think that's that's a little bit harder for me to to figure out might what might happen in your journey with computer science you started with lowlevel computations how these experiences impact your understanding of of causality today for me personally I think that I tend to approach an analyses and understanding of analyses more mechanically so you know getting to the when I read the Rosen bound paper about propensity scoring I didn't just read the paper and I also you know implemented the analysis from scratch and like stepped through and figured out like looked at the data as it was being balanced and like measured and double checked that you know it my intuitions made sense you know and that that they were were correct and experimented with different setups right to push the boundaries of of what happened to really understand Its Behavior and I think that continues today so when I'm trying to figure out what you know uh how llms might behave causally it's I need to get my hands uh dirty to really give myself confidence about any intuition so I think that continues and I also try and think about how we might use these models it's not just on their own terms text in text out but also thinking about you know what we can be doing at different layers of the inference stack to you know control their behavior you know what are all the knobs that we might use to influence whether a foundation model is appropriate for a particular task or make it appropriate for a particular task and this is not necessarily different I think than how machine learning resarch researcher would think about these Models Behavior across different levels of of abstraction uh but it maybe is a slightly different set of knobs just because of the systems work that I bring and I probably miss things that the ml folks uh you know uh think are obvious as well in my recent conversation with Robert NES your colleague yes I remember Robert mentioning that one of the paths with generative models that he finds inspiring and potentially uh useful is to learning how to causally control the generation in a sense just you know creating a set of knobs for for ourselves where we can just modify just one or two aspects of the of the image without generating in it from from the scratch what do you think about this uh this path and thinking about causality in terms of causal impact on the output of a model rather than the model modeling causal reality outside of itself I think there's lots of ways to mechanically influence the behavior of a ative model right I mean there's even people going in and artificially reweighting activations you know based experimentally on what works or doesn't work and I think that's that's a a fine way to to approach the problem in a sense the one way to think about it is that we have the standard input output to the model but then we have all this other knowledge that we can bring to bear that describes what the generation should look like I mean the obvious kind of examples are like you know we're telling the model to generate at Json well we also know exactly what Json looks like right or python code or you know whatever structured information you might want to get out of a text based language model or you know maybe less structured but similar kind of knowledge about what we want to get out of out of an image what what parts to change or not change and it's difficult to express those in a text command but we have other knobs so trying to figure out how we can use other knobs to impose that other knowledge that we have that we can't otherwise Express I think is is is is a great way forward what what keeps you motivated in your work ah um I really I think what keeps me motivated is is really thinking about the the potential to you know impact real real problems that that's what brought me from lower level systems problems to higher level social science computational social science uh tasks that were maybe closer to people in society even today when I'm using causal analysis methods you know even though I'm you know thinking about the platform we're building horizontally I'm always looking for kind of end to end problems to validate that these approaches work or to push the boundaries of technology and the ones those ones that excite me the most are the ones that you know touch on some Society important problem so that's that's what continues to I think motivate me is is that is that um question of how is this going to make a difference in the world who would you like to thank oh so many people I think in this context uh I clearly have to thank thank my closest uh collaborators so Amit charma has been uh an incredible collaborator for so long and really I can't say enough good things about him my other uh recent collaborators in the causal realm of course would be Robert nest and Chen howan we wrote the uh paper on causality and large language models uh last April together and then all of the the people who uh are working together with us on you know in the piy environment so colleagues at MSR New England who develop eonl are collaborators at at Amazon and uh in and in the in Academia who are contributing to the library I think really it's great to see like everyone you has this sense of you know here's here's the direction we're all going and you know we're we're working on different pieces of Technology but we know we see how how it all connects together and how you know everything fits to push forward kind of clear more causal Clarity around uh important tasks and decision making what would be your message to the causal python Community I think it's actually pretty healthy right now I think that we have quite a few libraries so beyond piy we have others as well caal p and others and I think you have great resources around uh what that full uh ecosystem looks like and I think that a good advice that I'd have for people who are trying to continue pushing the causal python Community forward forward is to uh not lose sight of the end goal that is like what are the problems people are trying to solve with these methods and really looking very broadly at approaches that make it easier to solve those methods with causal analysis so that might be something very deep in an algorithm it might be something more you know software engineering related like how easy is it to ingest data into one of these algorithms or it might be uh even uh documentation there's just so many ways to push push this technology forward and ways that make it more useful and applicable to to real world tasks what question would you like to ask me I know you go around and and uh are working with many different groups of people on causal problems I'd love to you know chat with you about uh what you're learning about uh people's causal Journeys what trips them up and what you know we you know developing the causal open source Community can do to to help you know is it education is it uh better tooling or more easily accessible tooling or is it really making sure that these things scale to Industry problems what's what that would be I think something I'd love to learn from you that's a great question and it probably could cover an entire episode um but trying to be more compact with this I think one thing that could be very very useful for the community aside of Education which I think we still need more of it would be to make partial identification SL sensitivity analysis slash proximal learning stuff more accessible to people my belief based on my experiences with industry but also academ people I feel those free things which are somewhere at the core I feel very closely related are probably one of the most underutilized and under represented Concepts in causality that can really move many cases forward MH so many people don't realize that using sensitivity analysis might be just enough for them to make optimal decisions even if the model cannot be fully specified yeah the second Point here is that some people realize this or might realize it partially or I just heard about this but they don't know how to do it technically and so this stops them from moving this direction like many of those people are you know as as we are also busy and they don't have too much time to devote to studying in depth something from scratch and implementing something from scratch and so on and so on so I think that would be one thing that could have a very large impact on applied causal inference today and I know that DUI uses uh the the method from from cheling from caros cheling uh so you can you can use it it's a great method for uh for sensitivity analysis uh but there's much more than this and much more many methods that can go beyond the limitations of of the methods uh proposed by by chinel right so yeah so I think that would be one one thing that could really move the needle the needle forward yeah partial identification that's I know that we're starting to in design um so Adam from Columbia one of our contributors for in the context of um causal discover and the pi ecosystem um has been working on graph representations for partial graphs and I think that that'll lead to more of these broader set of identification algorithms yeah but it is still pretty pretty early yeah um and of course sensitivity analysis then comes after right yeah yeah it's very interesting yeah that's something that uh we'll have to keep in mind Emer what's next for you yeah so the the the major uh effort that I'm excited about in the context of of causality is I think there's two two directions so one is continuing to push on uh making it more practical to use large language models to support people in the standard causal analysis process so how can we how can we use uh large language models to suggest uh causal graphs suggest uh potential missing missing data and missing confounders um and critique the analysis process as people put them together MH um the second direction that I think might be starting up is looking at how Foundation models might help us um better model more complex physics style uh systems I think that's very early going but it's something I'm starting to to look at to see if it's plausible uh as a contribution but if it is I think that would open up um models to be applied in a in a really broad set of very exciting uh applications mhm before we conclude I would like to ask you one more technical SL opinion uh question some time ago I remember Yan Lun tweeted that predicting pixels or training him all to predict pixels and he was referring to I think Sora uh back then is a wasteful way to learn something about the world World M and he proposes architectures yeah that are more predictive than generative M at its core yeah what are your thoughts about those two approaches to learning something about the world yeah I think there's maybe two two ways to take that that statement one is like are pixels the right representation and I think pretty clearly no like there's some latent representation that you know that we have about the world and that we would expect a model would develop as well right and when we think about the physics of the world we think about the physics in that latent representation not in you know pixels and so I think that's that's right um that we don't want to be learning just based on pixels but you know what view do we have of the world opportunistically we have pixels and so maybe pixels are the best way to get to that latent uh representation whether you very quickly switch from pixels to latent representations or whether it's not implicitly as part of a larger process I'm not sure and that's where I think the second aspect of his statement you know saying that it's wasteful is is more of a veillance of like you know if you have the gpus to spare right who knows maybe maybe maybe you're not going to see it as as as wasteful now um but regardless I think going for latent representation of the world that's learned for um variety of signals and then learning then implicitly or explicitly learning physics over that uh does make a lot more sense to me where can people find out more about you and your works I have a mostly upto-date webbsite at k.org so kic an.org yeah most of my papers are there uh if they're not there they're on Google Scholar mhh what can people best connect with you so probably email is the the best uh best way and that's on the on my website great cool thank you so much it was a pleasure thank you Alex it was great thank you