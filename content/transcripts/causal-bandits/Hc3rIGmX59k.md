and um maybe to put it in there it's not like assumptions are are binary it's not like it's true or false in my PhD work led by Ricardo Silva I was put on this path on partial identification in that field he actually learned quite fast intuitively that assumptions are almost like a range it's like a slider you pull up and down is the future caal it's the future caal I think hey caal Bandits welcome to the caal bandits podcast the best podcast on causality and machine learning on the internet today we're traveling to Oxford to meet our guest he learned programming at 9 convincing his dad to buy him a book on PHP he started thinking about causality at 12 frustrated by the fact that the only thing he could learn at school was the old Mantra that correlation is not causation he used to play piano but now he prefers Counterstrike workouts and family time ladies and Gentlemen please welcome Mr Jacob Sidler let me pass it to to your host Alex moak ladies and Gentlemen please welcome Jacob zeitler thank you very much Alex it's great to be here and talk about my favorite subject which is causality amazing thank you for thank you for joining us uh Jacob where are we well we're here in the uh send all Church in Oxford in the United Kingdom and um I chose this place because today I want to really talk about the assumptions of course inference and assumptions in statistics or in science in general is something we believe in and we build faith in that they work and I think this church setting here kind of represents that in in the same way where people kind of like come to ask the question of like you know why am I alive why am I doing these things you know why do I believe certain things so you're questioning your beliefs and you question your assumptions and I think that's what're here to do as well like you know how do we make cost inference work and which assumptions are more reliable than other assumptions assumptions are are basic or fundamental in causal causal inference in some of your work you focus on on the cost of those assumptions can you tell us a little bit more about this yeah so it's um it's something that's emerged uh as an idea over the over time of my PhD is basically that not only do we have assumptions and we need assumptions for cost inference I think in your book I took a quick look as well but you know there are certain steps that help us to get to a point identification and cost inference and they're necessary these assumptions are necessary but I think the question we always kind of like ignore is like the cost of these assumptions um so most simply for example the best assumption we can have is randomization but it comes at a quite expensive cost for example for a clinical trial it cost you know millions billions for the farm industry to run those um and so that's great because then we have absolute you know the best kind of certainty about the cost effect of a drug whether it works or not but it's expensive whereas on the purely observational side we have assumptions that that are kind of coming for free right no unmeasured confounding is just something I say and then we assume it true and then we keep moving in the csal uh path towards estimation but then again the question is like can we spend money to reduce the risk that that assumption is wrong so I think assumptions are important and then the cost associated with that as well it sounds to me like uh the heavier the assumptions we we make the the larger the risk we take and the heavier the assumptions so maybe if we have a purely observ observational study and we assume that there's no hidden confounding for instance uh that might be a that might be a heavy assumption or or maybe less heavy depends on your context uh the price goes down by the but the risks but the risk of being wrong regarding this assumption goes goes up yeah I think something through my conversations with you actually I realized is that in this framework of the the cost of the assumptions of cost inference the the notion of risk is still missing so I haven't actually thought too much about risk in this framework but I think as you say like I think there's there's ways for us to buy um where you know can spend money to reduce the risk certainly so I think for example one practical way would be at Harvard at the public health school where they do you know a lot of fundamental research in cost inference they spend a lot of money to discuss these assumptions for observational studies you know they're empirically not verifiable but we can sit in a room and discuss them and I I think they set up a new lab as well where they even you know asked the public to send in you know questions and justifications for um the cost inflence analysis and So that obviously costs money you know people need to manage this people need to talk need to pay professors but it does of course reduce the risk that we are you know not um that the RIS reduce the risk that we're making wrong assumptions um so I think that's a definitely a good way to do it for um observational studies yeah it it reminds of the idea that we know so well from statistics and machine learning of no not having a free lunch MH absolutely yeah and um maybe to put it in there it's not like assumptions are are binary it's not like it's true or false um in my PhD work um led by by my supervisor Ricardo Silva I was put on this path on partial identification um in that field he actually learned quite fast intuitively that assumptions are almost like a range it's like a slider you pull up and down so um traditionally we look at like um you know we have data and then we're like oh let let me get the cause effect for aspirin you know does it work or not and then they're like I have to make assumption a b and c and only if I have a b and c I get a cost effect but that's not the whole story it's more like we have data and then we can make some assumptions to get some caal uh statement or some caal result and the point identification is actually only one way to look at caal effect analysis the other one is partial identification or causal bounce which is kind of in between between saying you know I can't do anything with this data because I don't like the assumptions and I'm making all these very strong assumptions to get to this one number with partial identification you kind of like can easily move in between and what you get is not a number but you get a lower and upper bound on the true effect and so as you add more assumptions those bounds get Tighter and Tighter and at some point they collapse so they're both on top of each other which is just the point identification um and so this is uh quite important I think to emphasize is that assumptions you know are range it's not binary it's not an all or nothing it's something we can discuss at very different levels I I love this perspective and I think this is something very very important I would love everyone to to hear that that uh thinking about causality in terms in in binary ter terms that we either can do it or we cannot do it might be very very limiting and we might be actually throwing away a potential gain gains that might be much cheaper than we than we initially assume when we think binary about this yeah I think it's it's just comes back to very basic you know your philosophy of science which is you know what's your scientific Paradigm and if your Paradigm means to you know question your hypothesis and and justify your answers then you would want to look at every possible perspective of the ca of question you're facing and so being like well it's All or Nothing is it's just two perspectives so if you're able to go in between we can much more easily always like with a different microscope you know we're looking at different Zoom levels at the at the ca of problem and that you know is is going to produce better papers so it's it's a very very early field I'm I'm not saying like you should have heard about partial identification before so it started in 1989 I think with her first kind of written paper um I think it was Robins who just as as a side note kind of introduced it Pearl also talked about it at the same time you know great minds think alike is quite common to have these um things happen at the same time and of course Pearl took a dag approach um and I personally find the dag approach actually much more intuitive to explain partial identification but with a student um Alexander Bal um they wrote A Few papers that introduced these causal bounds um and so then obviously we have the trough in between and then there was another guy from economics called um I think Charles mansky he wrote a whole book around it I think 2003 maybe and it wasn't picking up as much and so now we're actually kind of like getting into maybe let's say a third generation of partial identification and I think it's partially driven Again by the frustration that is like well there surely isn't just full C of effect estimation and no estimation there must be something in between so people people want more flexibility people want to talk about more assumptions different assumptions and more importantly weaker assumptions so strong assumptions are just inherently hard to justify so if if you're trying to you know if you're talking to the government about Co policy or a company about their policies and marketing strategies um you know you want to have a bit more than just a binary All or Nothing you want to be able to provide uh causal results with Weare assumptions because that's easier to justify at the end of the day one question that I often hear from from people who are practitioners in causality or are interested in causality and they hear about partial identification they also ask is this concept related to sensitivity analysis and if yes in what way is a good question I have I I actually um met with someone who wrote a paper on on balance and sensitivity analysis and in in the most uh kind of like um you know first step way yes it is in a way um can be seen as the certy analysis but I think strictly it's just a rephrasing of a cost model and then you can actually do sensitivity analysis on that in some way but um if it helps to understand the idea yes you could think of it as some kind of sensitivity analysis um sensitivity analysis strictly speaking means you you know introduce a uh subjective parameter which you dial up and down and then see how the results change and how they match you know with uh with what you see in the world and then you have to take that parameter and also calibrate it so G imens I think first described that in a paper and it's it's a very simple idea it's not complicated at all to be honest it's a paper that everyone can read and be like that makes sense you know just one more variable in there and I dial it up and down it's a subjective exercise though papage identification isn't subjective by default by Design the only subjective thing might be the ca of graph you assume but there is no subjective sensitivity analysis in there but you can add it and you can make it that way what do you feel contributes or contributed to the fact that uh I think it's safe to say that both areas uh partial identification and sensitivity analysis are not so well known in the community today uh and although they seem very powerful in a sense that they can really broaden the um let's say the the action space in causal analysis they are not that frequently applied you know it's the it's the age old question really you know this seems to make sense but why aren't we using it um there there are psychological reasons is also the fact like before something is being used it's not being used you know that's the stage before it is being used so are we at the beginning of of a change of people using these things and I think the answer is yes um I think we just at that point we are making this change sensitivity analysis has been around for some time I think it's just that basically people's bandwidth is lacking you know the Investments you need to make to get to already just a cause effect with a simple you know python Library I mean you wrote a whole book about it you know it's not it's not easy and then to ask them to also do a sensitivity analysis is this point maybe a bit still bit of a an ask there obviously more libraries coming out and simpler methods so I know the Tyler vender real for example came up with the E value um and it's a paper from 2017 I think he came also to give a talk here in 2019 actually very simple idea and he was like the medical clinical trial literature they need to do this they need to do sensitivity analysis on top of their cause analysis and here's a very simple way to do it and here's a python or our package just download and put in the thing and it's just one equation that the package just one equation in it you know it's trying to make as simple as possible still people are not using it it's just a question of resources you have and you have to choose to make trade-offs right so sensitivity analysis is absolutely important it should be all included it's just that people don't have the money to walk that far and I think the same with partial identification we're going to have to first create these tools and make them available and simplify them there is still a caveat with partial identification which is that these bounds that I'm talking about they can often be not particularly informative and that's just the nature of things doesn't mean we shouldn't report them you know as a scientist you should you know independently uh um you know go into your um inquiry of a cal question or a science question and you should PR report all the results you have it shouldn't be like I'm not going to report this or something like that you should try to provide the widest perspective of of you know the questions you're trying to answer and the results you've seen and partial identification should be part of that even if it is not as informative and so the thing is also partial identification on top of all the Cs of stuff is also another level of complexity and it's not just complexity to understand is also complexity to run these methods um so we have exact methods um that's something I've spent a lot of of time on and that's actually the kind of core part of my PhD and then we have approximate methods that probably have a better chance to actually work in in in real life and in practice um and so the the problem with the exact method is they don't scare well so you know if you go beyond five nodes in a graph if you go beyond the domain of three or four you know discrete states of a variable it it doesn't compute and so my PhD actually in one particular paper um has brought down as in my opinion has brought you know suggested one of the best ways to you know deal with this uh problem of scaling um but then the other paper um by curtain Pat um he um you know we collaborated all on this has shown a method that's much more applicable because it's um you know in the most simple case just the IV setting very classical you know many people understand that and then it allows for continuous rails and it allows uh for multiple treatments so I think we're going to end up with the more practical thing but if you still want to go to rots the exact methods is where it's at unfortunately no free lunch right so these methods are expensive to understand and to run we will link the paper uh and all the resources you mentioned in the in the show notes so everybody who's interested can um can dive deeper yeah and and read about those methods recently I had a conversation with with Andrew Lawrence H and he one of his Works was a about applying a a method AAR algorithm which comes from computer science it's like a path search algorithm to make some of causal uh Discovery methods more efficient uh do you also in your work have examples of taking some methodology or some idea from another context and applying it to causality in order to make it more usable uh more reliable I think it's actually it's actually the way science Works to be honest you know science isn't 100% Revolution science is 80% the old stuff and 20% something new and especially I I think people get stuck trying to be particularly original on the 20% don't be original just find something like the AA algorithm that fits the other 80% in a new way and that creates a new value so actually with the caal marginal poope it is taking ideas from something called belief propagation and it's applying that so basically let's say you have a graph X1 2 and three and yeah so X1 2 3 4 four nodes and they're fully connected now if you were going to do partial identification with that it would already get quite tricky computationally it would require a lot of ram a lot of you know arrays to allocate for the calculation but with Bel propagation what you take is you just take the marginal so you reduce this four um node graph into for example four graphs each with three notes so they're like subsets basically they're like let's just say the sub worlds it's like a course perspective on the caal world and with that method you can then actually overlap them for example to use the statistical information between those worlds and then also add expert knowledge and that way you can actually tackle you know csal bounding questions that are Beyond four or five or six RS so I think 10 also is possible obviously you know free lunch you still need to make a lot of expert decisions but it is very much a prime example just like the AAR approach um of using a different idea and applying it to a caal problem yeah it's it sounds like a beautiful application of the divide and conquer approach computer science that we know from sorting and and and yeah divide and conquer is the way to go absolutely yeah um you know there there's all kinds of people in the world and I think if you want to go far first of all you need a team and second of all you just got to be practical so um science is baby steps it isn't huge sleeps over 3 4 years where you have a a genius idea and then you know you wake up you do have these ideas personally I do have these ideas at night or like in the shower or whatever but they're not like huge ideas they're just like after grinding away and looking at the problem again and again you're like maybe this works in a different way um really just in a way banging your head against the wall um and there's nothing genius about banging your head against the wall Yeah you mentioned experiments in the beginning of our conversation and well designed and well conducted randomized trials are a great tool to talk about causality but they also have certain limitations so for instance one of the limitations would be uh when there is effect heterogenity right so all the different people different units in the experiment react differently uh some people in BIO statistics have ways to deal with this um another limitation of rcts that seems more fundamental is that even though they can inform us about average treatment effect in some cases conditional average treatment effect they cannot help us distinguish between different counterfactual scenarios or un answer more generally answer counterfactual laries yeah what are your thoughts about so in our research group we've actually um repeatedly had to clarify what we mean by you know conditional average treatment effect heterogeneous treatment effect individual treatment effect I mean maybe just give a background right so when we say cause or inference there's actually a whole zoo of different effects we can look at so the most common one is the average treatment effect but if you say conditional for example you might be you know conditioning an age and then you look for each age group what the cause effect is and and this can go as complicated as you want actually once again there is a really nice paper in partial uh identification the field it's by w at our 2019 and they're looking at bounding for fairness but it's a really nice paper where I think there's a table where they just list all the different effects and how they can be bounded and I think that's a really good overview of what kind of effects there are specifically now for the question with with heterogenity yes it's of course important I mean you know we we can make decisions based on average treatment effects but you know we probably want to drill deeper but it does get complicated and frankly I'm not the expert you know when we have these discussions about what what is the difference between Kate you know C being conditional average treatment effect and it and stuff like that frankly I I've never got past the stage of understanding it all I know is that people tend to practically revert to a because it is easy to refer to of course there's many people that spend a lot of time on looking at these questions and maybe I'm not I'm not the right person to comment on what the right henus treatment effect estimation methods are and I guess it's just important to like be careful um with these because there's a lot of confusion as far as I I see but it is important and I think I was just told by someone um that you know these methods tend to also have quite the danger of some something like pcking so you can easily create kind of like a subpopulation that supports a conclusion that you want to see um but that's you know I would need to look up the reference for that and how about counterfactuals this more fundamental distinction between Interventional and and counterfactual queries is one of my favorite topics actually um because um I I think I saw you as well um you know posted that you uh looked at the topology of course inference so it's a wonderful work um that Thomas ier I think wrote down and it's it's actually it seems to be based on some some previous work by Constantine ganning at at tubing and and Constantine was a PhD student with Kevin Kelly at CMU and CMU is one of the breeding grounds of caly but the causal hierarchy is incredibly incredibly important um and I think I saw it mentioned in your book as well um of course the cause a ladder as is called by Pearl for example um it's it's such an essential concept um because it really lays out the limitations of what we can do you know in science it isn't about like reaching for the stars I think at least I mean you can dream you can Envision But ultimately you need to come back to earth and you need to ask the question of like is this theoretically possible and so with the causal hierarchy we're able to inquire what is theoretical possible most importantly can I make statements about the Interventional world just from observation of data and the answer is no you cannot um so that is shown for example with topological arguments but then also in the paper I think it's called the causal hierarchy Maybe by alas B um they use I think measure Theory to show the same thing um that basically you can when you have observational data if you want to make statements about interventions you have to make assumptions maybe that's a better way to say it it's not like it's impossible to say things about Interventional states with just observational data it's just that you have to make assumptions that are probably pretty hard to defend and then when we go from level two to three so from Intervention to counterfactuals it's the same story just Interventional data like rcts interventions on the graph and so forth isn't going to get to your counterfactual conclusion but you can go and make the step of saying I talk to an expert or I'm willing to take I guess willing to take the risk to make the conclusion based on these additional strong assumptions um and I think once you realize you you have a much better realistic perspective on what can be done it's not it's not a statement of like oh well then we just go home and do nothing it's just like oh now I feel much more confident to be like okay well this this statement is possible this statement is impossible or more practical how much money do I have to spend you know to defend these uh you know assumptions so the cost of of caal assumptions and so you know those costs get quite a bit more expensive as you go up the ladder observational data is just freaking cheap it's the best we have the reason machine learning is so successful right and big data was a term is because observational data is cheap Interventional data is so much more expensive and counterfactual data basically doesn't exist except if you do something like a twin study which still requires you you know to find the Twins and pay them and you know make some assumptions that the twins are the same traditional associ associative machine learning rank one learning uh we we could say that it's crazy successful in certain areas H and this is the family of methods that brought uh topics that you and I and other people in this podcast are interested in into into the public awareness through especially recently through generative models yeah both in in graphics like mid journey and and in text like GPT Lama and all those all those large language models what is it uh about the place where we are today that it became that that the that the community became more receptive to hear about causality oh although those methods associative methods are so popular and and Powerful it's probably the same reason for most of us um um which is that you train a model and the world changes and you make predictions and they don't work and you wonder what happened well the world changed and I think we all with a good intuitive feeling that that's happening I mean if I trying to predict airplane ticket prices with data learned from 2018 in 2020 it's not going to work because there weren't planes in the sky right because it was the pandemic so the there was a systematic change there was a causal intervention on the world which was a a virus um and that changed the whole system so of course the ca the predictor I learned with machine learning or if it's just a linear regression doesn't matter uh it's not going to apply anymore because there isn't no causal system or thinking behind that model it's just correlation right it it learns that if these you know few data points observe then the ticket price is going to be this because I've seen it in the past but the past is not the present or the future usually so for me personally um it was also just the you know dissatisfaction taking courses in in statistics that would go on and on about well you you know make this you know you use this formula and then just apply this formula and you know then you get this number and then it's if it's about 0.05 you know it's it's not significant but there's one star two star like it's it's very applied and then even if he then do a theoretic C statistics he still will not hear about causality um at least you know five 10 years ago very few institutions would talk about that um it's changed obviously because um we have people that have invested the time and so you know I when I heard the first time about um you know that you can actually use mathematics to characterize cality I was very happy because I had I had all these thoughts and I was been kind of told and implied that no you cannot characterize it there's no maths to do that I mean math is the language the formal language to you know characterize things in in a very precise way and um I kind of had started to think or believe I made the Assumption it's not possible um and so machine learning models um don't have that caal adjustment in there there's no discussion of that traditionally um and so that's why they fail and that's why I was also unhappy when I would take courses in machine learning um and then Al usually at the end of the course I'd be like you know Professor but what if you know the world changes or something like that and they'll be like well yeah I guess it's probably some kind of causal reason or something like that and I'm not blaming the professor you know it's a structural problem in Academia um but these methods fail and of course that's why we have these huge training server Farms that retrain every day or every three months or something like that um and it is a practical approach but Surly there are applications where we can think causally about these problems to characterize them in a better way and maybe not you know uh blindly retrain every day you started asking causal questions very very early in your life at least compare to what people might imagine yeah is the is the moment when you start thinking about stuff like this uh can you tell me about the first time you remember you you started thinking about those questions yes I I think it was um when I was 12 and you know I mean I was young um I I guess it was somewhat Limited in my um perspective but um it was around that age that I I guess in school some some children were treated differently than others and I felt like you know that also the the differences in wealth created a lot of problems there you know kids couldn't go to school you know tours because they didn't have the money and other kids you know like had all the designer clothes and three game boys and um so I kind of like in a very natural youthful way I was like you know isn't there something you know a different weap where we can treat everyone the same and um you know long story short it's known as communism um and I was like well communism sounds very attractive and surely when they tried it so far it maybe it didn't work out but maybe we just haven't had a proper caal analysis you know like I mean maybe if we just do like some kind of experiment where we have one country and it's capitalist and another country that's communist you know maybe would see differences and obviously that's that's an RCT right so that's the ca of thinking there and um it was kind of motivated by the question of like what kind of political system is has the better cause effect on on welfare or Economic Development um and I was just thinking about that you know um didn't have the math skill or the reach to ask the right questions I mean when I was 12 what year was it 2008 I mean Juda Pearl hadn't published this book how would they have known how would they have found it so I was left with that and very frustrated but it it never left me it was always a question and annoyingly so I mean you know teachers hated me in school because I would always you know post calls or questions I'd be like yeah but how do you know this is what it does and some teachers were B more honest and they were like well I don't you know this is we learned these caal paradigms whereas others would be like oh you know why you asking this question you know there is no way to do this and it is frustrating you know when you're like I I feel like there's a way to do caal inference and causal understanding of the world maybe mathematically precise and then some person of authority tells you know because correlation doesn't impation and move on with your life we always going to just have these correlational studies and unless it's an RCT you're not going to have answer and sometimes the funny thing is sometimes they wouldn't even like say oh maybe just run an experiment they just would be like no you can't get the cause effect just like but actually I mean just run the experiment at least so when you mentioned this idea of taking two countries and randomizing a treatment between them it immediately brings to my mind the uh memory of a paper by Alberto about the influence of of a conflict on economy there was another paper also about German unification and both of those papers used this synthetic controls method this is the method that you also used during your internship at at Spotify can you tell us a little bit more about this project and what you learned yeah I I'd love to talk about that um because it has a really good lesson for PhD students in there especially if you're just beginning or just research in general so like when I started my PhD you know every PhD is different I like to say and uh when you start your PhD there's the you know pressure to publish there's only so many years you can do your PhD 3 or 4 and you want to show something for the work you're doing and and I've been working on that P identification uh thing for some time and there was a stretch you know arguably also with covid things were slowing down massively and at at some points there was weeks without you know progress because of all kinds of covid pandemic problems but um after two years I still really like didn't have something um that was you know publishable um and so uh the the C causal marginal Polito was coming around finally and we submitted it and um it went through a bunch of reviews and then I went into this internship and I was like well you know three months good luck doing anything here and it is absolutely true that three months isn't a lot to you know produce research novel original and publish um but it turns out that in this one with just maybe two and a half months of work uh got a whole publication out of it and that was such a surprise to me um because you know I had been working for two years in the same way same Pace same environment and I go to Spotify nothing Chang changes it you know just get paid much more and um I was like well what's the what's the factor here and the the truth is there is no factor which is that the only thing that matters is that research is random and so some projects how great they are just might not make it out there because of all reasons but specifically with Spotify now coming back to synthetic control um it's just that in a way some kind of you know Stars aligned you could say in terms of the research constellation which was that um Kieran um who who gave me that opportunity basically basically at Spotify and who's running the advanced costal inference lab there now um he was like you know there's there's this a problem we have with Spotify you know we want to um estimate the cause effect on these kind of Time series data so let's say you know that Justin Bieber um wants to promote a song on Spotify or something like that he wants to know the cost of impact so that's a caal question right it's not just he wants to know the impact he wants to know the caal impact right a go caal inance and so synthetic control the same way Abid would use it for answering political or economic question can be also very effectively used in marketing or any kind of like you know web platform analysis or time series analysis and so Google had done some work there before in 2014 they brought out a paper and a package called caal impact and that one had a basing approach but that's not important for the method but specifically at Spotify um we kind of like um asked the question of okay we want to use this but like what are the assumptions that go into this and so that comes really really back to my my core question here of like the cost of CA assumptions and so the assumptions that go into synthetic control there once again a few that are testable but a lot of them are untestable and so um we first of all wanted to actually properly characterize them so it wasn't until then with this paper that people really um this assumption three double Prime you know you can look it up in a paper it no one ever really went and did that in a nonparametic way and before we could do that we did something else that seems you know no one had done before which was to characterize synthetic control of Dax so Abid of course econometric would use the potential outcomes framework in some way to you know characterize this caal system and we were like well how would you describe it index because well if we know of swix so single World intervention graphs then presumably there's a way to translate abid's potential outcomes synthetic control into J pearls graphical models synthetic control and so as a first step we characterize synthetic control with DXs and that already makes the whole problem much more easy to look at and then we use um proofs from previous papers um to then provide that non parametric identification result so identification does come in different forms in your book you talk obviously about the different step that leads you to get the estimate in this case there's another step um that's actually being used it's a theorem that comes from proximal learning so proximal learning is another emerging trend um or topic and cause the inference we can talk about that later which you know as you know I'm I'm very passionate about proximal learning as a as a deeper causal concept but um coming to the paper with Spotify we then also on top of the Dack and identification provides sensitivity analysis and we already talked about that before but we basically introduce an additional parameter into our Cal model and that one is subjective we also have two more parameters but it you know seems like we're lucky that we can actually estimate them from the data we have and then we're only left with one parameter and so we have to assume linearity for this very simple synthetic uh control sensitivity analysis to work but then you just have this parameter and you can dial it up and down and it will give you different results based on your assumptions and I think that is something people haven't um looked at enough so synthetic control is very powerful it's a method where I personally think like we have the Cal hierarchy which can be very tressing when we learn that going from round one to two and three is very hard or hard to justify but then we have practical methods like synthetic control where it's like wow like yeah it does have strong assumptions but this thing does go a long way and so that was the The Internship you know personally I felt like it was two and a half months of work of course there was some submission and some final experience we did um it was a great time anyway because Spotify is a great company with a lot of opportunities um and and a lot of freedom at least in the position I was given um and then we submitted it and it was accepted at clear and then I presented it in April and as a whole incredibly smooth and Incredibly unlikely experience for someone to go through but I was you know given that chance to experienced that and it was a wonderful experience and it's still one of the projects I'm most proud of in the research I've done great congrats on the project thank you this very smooth Journey as well it's Kieran who's the Visionary here you know I'm just the one that like kept bringing up ideas that didn't work but the the parametric ident non-parametric identification is down to him the Dax is something you know we challenge together and then implementing the whole thing came down to me but yeah it's teamwork yeah I I think teamwork is is very powerful and often and underappreciated perhaps yeah um especially in those maybe more competitive contexts where where people might feel a little bit um uncertain if they give a credit to another person maybe maybe their credit will will hurt somehow yeah um synthetic control is is a very interesting method uh but it's a less known fact in the community that's at least my impression that this method does not come with guarantees of identification in other words is it might be uh susceptible to confounding you mentioned that you also use dags was that something that helped you frame the problem from the identification point of view uh is are you asking like whether using that Dex helped us produce that identification result um my my question was even a little bit more basic so I intended to ask you about if the fact that you use Dax although you are using synthetic control which is usually or typically used without Dax because it's it's somehow binded to this idea of potential outcomes was the fact that you use dags in um with wh synthetic control was helpful for you uh to think about identification clear more CLE in more clear terms I I think so absolutely um I have these potential outcomes and I think I'm going to say but like I think a castal inference researcher that always chooses one over the other you know um it seem seems a bit one-sided I think both both work fine and you can actually mix and match so there are papers out there that use potential outcomes in the same sentence as Dax and they are mathematically basically interchangeable you know keyword single World intervention graphs I personally just do prefer more the dags after all um I do find potential outcomes clunky but they can be more expressive at times um so when I when I want to express a much more complicated C the system I would use both together but if it can be done with a dck then I will use a dck and so in this case using a dag really um I I think helped just talk about it better on a whiteboard as well you know it's also you take a picture and you send it you know to to your research collaborator and it just you know it you get your you wrap your head around it better as far as I can see yeah so so Dax was definitely the way to do to go there um again you can make all the same arguments with uh potential outcomes it just can't draw the nice pictures for it I want to Circle back a little bit now to uh one of the one of the things we discussed briefly before so you mentioned this paper about the ological view yeah on on causal inference and causal hierarchy um when you look at uh those limitations that appear on the lower rank on on the rank that is minus one right compared to the rank where you are yeah we can observe the Symmetry uh that uh rank one can produce many potential rank two systems as as its basis MH and rank two one system on rank at at level two can produce many different systems on on the third rank contactual right yeah that would lead to the same Interventional distribution yeah from topological point of view it seems that we could try to extrapolate this the Symmetry maybe quote unquote symmetry I don't want to be yeah yeah yeah yeah know um very precise about this we could extrapolate this this this symmetry uh to even a higher level so this gives us a potential to think about at least theoretically about the another rank that is beyond factual what are your thoughts on this side I yeah I think I mean I probably ask J Pearl first what he thinks about that and then probably ask I mean who's a good potential outcome person um you know there many of them I guess um and what what did they thought about about it and I'm sure they did um I have a slight inkling maybe that I've read as well the argument of like of course in a symmetrical way let's say you can go beyond counterfactuals um what does it philosophically mean though I mean I don't know like when we do science or when we do data science or when we do statistics uh there's always a philosophical underpinning right um and so especially the great thing about causality as well is actually that um it makes us all thank you so much it makes us all um uh you know think more about you know I guess what life is and where cause and effect comes from you know um and I I think the question like that of like what the what what is what is a higher hierarchy and counterfactuals is incredibly philosophical question and which I don't have an answer to now I think uh with tools like measure Theory and topology we can maybe extend that so once you have phrased causal inference or causality with topology I presume that would be an operator something like that that could extend this infinitely I just don't know how that you know what interpretation is so with maths we can do a lot of things but how to actually interpret them in terms of the real world is is the harder question to be honest at the end of the day I think it's an academic exercise you know I already find contal themselves quite hard to understand at times I'm a very practical person that respect I know some other people are like oh it's just mathematical just write it down and then it exists but I'm like yeah but like parallel worlds you know like crossworld intervention they do make logical reasonable sense you know do we live in multiple universes and now we're already in a philosophical discussion right so I think there's much more behind this but I think practically also um we need to be extremely clear about how we going to use counterfactuals interventions that's fine I get it uh counterfactuals making the step you have to be much more careful it just gets so much more complex out there talking about philosophy I I had a conversation with naali vineberg from from LMU he's a philosopher of science specialized in the in the intersection of causality and complex or dynamical systems and one of uh things that I really loved that he shared with me one of his ideas is that causality is a concept that is scale specific so you could you could look at causality the causal system at one spatial or temporal scale and then moving to another scale there would be another caal system or another SCM that could represent properties of the system I was very curious what I have thoughts about this well it sounds interesting but do you mean specifically if we were looking at causal systems at different points in time uh no ra rather at different time scales so maybe like it's like a nano Nan scale versus uh I a millennium scale okay well I'm going to take the conversation in this direction now which is cyclical systems right so I think when when um classically or most simply if you look at the dag we kind of assume it's an equilibrium so that things have settled and these are the probabilities on the notes and these are the structural equations now someone who spend a lot of time on these questions of I guess different time scales is is yoris mui from University of Amsterdam and I had a chance actually early this year in March to go to a a workshop and um talk and discuss this at a table and it was actually fascinating story almost for like a book or maybe there will be a movie on C INF sometime and I'll provide some you know movie you know Direction details but it was uh it was a table you know uh dinner table dinner was done and there was this exact discussion actually um so one one person we said like we we don't need you know cyclical Dax system introducing cyclicality in Dax is is is quite hard and in fact again introduces many more limits to cause inference so yours muid has you know spent a lot of time on it and has a paper that discusses all of this in extent but that person was like we don't actually need that because we can just represent causal um steps in in you know in in different chunks of time slices and so this is what what what I would respond to like it's different time scales Well yeah if you have the time scale of of months so you have patients coming in every month then yeah you have chunks of different months and every month they get a different treatment which was you know dependent on the previous results and so forth and then you can also say well what what if we do it every second and of course you can also take it to n seconds and you can take it to you know hundreds of years so frankly I don't know where this conversation ended it was probably two or 3 hours and it went into very very uh very big details um and I think the conclusion was that we don't actually need you know I don't I don't want to be the person but from my perspective I think cyclicality is ultimately uh uh very instructive but it's not particularly practical it's practical in some ways but for like practical applications such as health and epidemiology those chunk time slices are just fine and you can put them on different time scales now philosophically I don't know what I guess naali uh bgo would want to imply with this statement but this is what I would imagine he would be talking about at that point um he might have meant something very different but I think this is just as as a whole already something very important to to mention I guess for the audience um is that you know DXs are called directed as but that means the directed so if you go with cylic graphs things get much more complicated again you mentioned a couple of times you refer to your work on on on the polytop paper so a polytop uh is a structure that might be less familiar for some people in in our audience could you provide us with a little bit of an intuition what a polop is in the causal in the causal sense of the caal interpretation and how is it useful I would actually love to do that because I think it's uh uh one of the good ways to visualize um these caal bounds here we go so um there is a paper 2012 by ramahi he actually did his PhD here at Oxford University in the stats Department um and he has um a a graph in there that actually shows bounding problem when a three-dimensional graph so you can actually see the bounds on on on a graph you can visualize it and so as I said before four bounds are basically a lower and an upper bound on a c effect and imagine to you have a box let's just say it's a cube a cube um and this Cube actually represents your caal problem with caal assumptions we slicing through the cube in with slicing off parts and so with a cost assumption let's say I can slice off the top now it's like half is high that is equivalent to making an assumption that slices off the top and then lowers the upper bound further down because the upper and lower bound are the maximum and the minimum point on a polytope and a polytope for example a cube is a polytop but more complex you know High dimensional um objects can also be polytopes and so that that is the polytope in in csal maral polytope is that we actually put different boxes together but these boxes are still ultimately are convex so convexity is a very important concept for optimization and convexity basically means that you can find the global maximum and Optimum that is also why I say I work on exact methods because they're called exact because at any point in time when I calculate the minimum and maximum or the low and upper bound those numbers are the true low and upper bounds there's nothing lower or higher than that and so that's that's the poope there and you can really imagine it like a cube that you're then slicing down with assumptions and so let's come back to it cost of course assumptions if you want to slice the cube you have to pay but it's money or sitting down to talk with your colleagues about the assumptions but you can slice down a cube and at some point you will have sliced it down so much that the lowest point in the poope and the highest point are together and this is your Cal identification because a hyper yeah in yeah basically that's the other word there yeah in the beginning of our conversation we talked about experiments and in a sense we could see experiments as a special case of of causal inference so we could think about doing Cal inference using do Operator just on the data and doing causal inference by intervening in the real world and this gives us or can give us some additional information about the system uh this is related to something that you're also working on which is optimal experimentation yeah could you give us a little bit of a perspective on this absolutely yeah become very passionate about optimal experimentation um as as I said because of course inference and it really is a motivation um that has grown out of that and I think the the realization that we can cut the the marginal polytope or we can cut the the Cal space with experimental data um is just quite powerful because the only question then left is which experiment should I run next um and so there are statistical answers to this so we have um actually there's a nice story to this the story goes like this when people were mining uh for gold let's say or oil they had a three-dimensional space let's say you have a kilometer by kilometer and you want to figure out where is the gold pocket right what what uh what methods can you make well we you can just randomly drill down and then when you find something you can be like oh this looks good you know I'll keep drilling more or you can make a grid so you drill every 10 met but that's quite expensive right the question then becomes can we be smart about the drilling and so that is something called is cing um and that's been used to explore basically you know min areas or or oil areas as far as I understand and so the same way you know if you have a statistical parameter space uh and you want to learn the data points about it you can just creck the space or you can use something called nowadays Basin optimization so Basin optimization is a method which basically takes a just any predictor with uncertainty on it doesn't have to be a GS in process which is commonly used but it is used 99% of the time and then it uses that uncertainty to make a decision where the next state point should be acquired and I find that just a really inspiring method and really effective method to not do random you know experimentation like okay now we need to be careful to not randomly select points where we do experiments um or measure data uh and to not go with a Brute Force approach but to be smart about which you know the data points be measure next and so um that is true for just correlational data analysis as well as cost analysis so both of these can be phrased is B B and optimization problems what are the main challenges in in this work or this area I think right now the main challeng is about the integration of expert knowledge um so we have something called vanilla V it's just a boilerplate method it only takes data um but then these uh surrogate models so those models you used to make predictions and you used to figure out the next best experiment they do have a lot of parameters that you can tune um and then those tune hopefully can be linked to expert knowledge and that will help you find you know the gold pocket faster um because you're not like just having somewhat of a good idea you have a very precise idea of where gold pockets are for example they might be you know at the bottom of a hill so maybe with expert knowledge you can steer your surrogate model to be looking more in the hill areas and then that expert knowledge can be also very concretely physics knowledge so physics presumably is true so if you ask a physicist about certain formulas they'll be like yes we derived them this way you know 10 20 30 50 60 years ago um and so maybe we can integrate those and basically kind of like exclude in the parameter space certain things that we know are physically uh inconclusive or like nonsensical um and so these are the main challenges right now and specifically for me working on applying these methods to Material Science it would be obviously the knowledge of a material scientist that goes into the model and that I think is quite important because materials are everywhere we all use materials whether it's the glass here or these microphones or the high-tech recording device um the reason we spend billions on optimizing you know microcomputer chips is because we are really highly dependent on them and if we can make them cheaper we can do more you know technology and in healthcare that can go a long way it just goes a long way everywhere um and so experimentation is incredibly important for them in in my conversations with with Juan Ordu and from Walt and and Andrew uh Lawrence from from coand yeah I heard uh something that that I think also goes well with this perspective that you that you just presented so both of them although they work in different contexts and with maybe different types of clients different types of business problems they both emphasize the importance of getting or incorporating expert knowledge in the in the Model H in in case of Hanan this these are often structural basion models M uh where incorporating expert knowledge can help you with building a graph but also limiting the search space for the parameters in the model yeah in case of Andress work that would be uh causal Discovery we know that this problem is uh the search space grows super exponentially with the number of nodes so even if we can exclude one Edge or 10 edges yeah this can reduce the sege space significantly mhm uh from what you're saying I I hear that uh expert knowledge can also help us with with optimal experimentation by Contracting this search space yeah it's the same thing I mean expert knowledge as a term or I think it's also called preference I mean getting the expert knowledge into your model is called preference elicitation um but using that knowledge that you have uh makes sense because it's there so if you don't use it presumably you're not being smart as smart as you can be and actually outside of optimal experiments or outside of cost inference this is also a term so expert knowledge and statistics um presumably every statistical Modge model is based on on Expert knowledge right I mean you assume a distribution that your experts said yep that checks out you know uh floods behave like a poon distribution or something like that but uh yeah an optimal experience absolutely it's very important and I think to bring it back to you know a cost INF as well I mean there's a cost of expert knowledge right so if you get a good ex good good good expert that that that might be quite expensive if you get a not so good expert or you ask your mom who's probably a cheap expert she might give you an opinion on why there shouldn't be an edge in this marketing model might just be wrong so like how much you spend on that crying that expert knowledge and integrating it efficiently determines how good your results are going to be um and I think we we are already you know confidently moving away from Big Data and building models that just are supposed to explain and predict everything to to a world where we like we have these expert they know these things better than a machine better than J GPT which hallucinates and we're going to bring those into those models and that's true for for C infin in the Cal marginal poope in fact you know half of the contribution is um integrating that expert knowledge about edges whether they're directed or bidirected so you can read it the you know the graphs half of the diagrams um half of the the graph show the impact of expert knowledge actually and in the continuous impact actually so it's not just like expert knowledge for this but like you can see how varying the expert knowledge and what they know has an impact on this bounds so expert knowledge slices the polto makes the space smaller constrains the bounds further closer to the true cause effect but obviously at a cost of that expert knowledge and expert knowledge can be wrong so um that's something we also need to talk about so how do we have methods that you know um recover from that so if you take a basin approach you're in luck because as you collect more true data it will kind of overrule the wrong expert knowledge but you will have to collect the true data which comes at a cost so everything costs something but you want to be smart how he spends your money uh Jacob who would you like to thank I did think a little bit about that I think um I'm going to you know thank first of all my my family who are incredibly supportive and also my father who supported me through all of this um I think education does pay the in best interest um whether it's an actual real money or your experience or life quality let's say and him being Visionary to you know support me and uh get me a computer early on um really helped me actually learn programming very early on access to that is worth you know Millions for me personally or even you know there's nothing that could pay for that experience um I guess I'm also really grateful for for the church here hting us today um so for me the the the cost of cal um you know assumptions is a very important topic and I think the church reflects it quite as well that we should question every assumption we have questioning those is pretty cheap and so when we then go invest in verifying those you know that's where we put down our money and so in the same way I guess people have been Gathering here for hundreds and thousands of years they're also questioning the assumptions of life so um I think that was a nice topic uh to bring around here and I guess finally I'm thanking my wife who you know um helped me with all of these things and so this just R supportive what question would you like to ask me that's a good question I was thinking you wouldn't ask that um I guess I I don't want to ask a question um that other people might have asked like what's your your your story in cost inference um and where you come from but I guess I I probably would ask maybe a person question like um you know um you have studied philosophy I think you studied also psychology you you've been a music producer so you've had a whole bunch of wide experiences there like what's a common learning like what's what's one wisdom you would want to pass on having been through all of these different stages in life I mean that's that's a wide variety of experiences you've seen basically the world so what is it that you think C inference can learn from your experience in music production in philosophy in Psychology what is it that we should emphasize in the next 5 10 years uh that is a beautiful question I think the unifying uh thread be that goes through all of those experiences is looking at at the information flow so this might sound a little bit abstract so I I'll unpack it little yeah go for it when um when I started studying philosophy I I came there with with a lot of questions uh and I thought that I will find answers to those questions but I think I ended up with something much more valuable which was that I started asking questions about the assumptions that I didn't know I had yeah and this was one of the probably first moments when I realized that by living in certain environment you learn certain things and not necessarily always in a conscious way so then when I went to music uh and I started started playing music first I started playing music because I was very passionate about it and I just loved it and I was like so curious how to I had some jazz concert you know like what do they do to get this sound what is the harmony there like ah how does he do his fingers so fast on a piano yeah and then I then I at some point I became a music producer and then I realized that the way you that you can take essentially the same composition and you can frame it completely differently uh using the ideas that you have about how human will react to to certain things that you can change I don't know in instrumentation like the the ARR the the arrangement the how somebody sings and so on and so on and then I started realizing that it's all about information flow and there are many channels of information flow yeah um and this goes for C culture in general uh it goes uh it works for art whatever art form that is yeah and then when I got very interested in statistics and and data science and machine learning uh I think that was one of the things that made this transition for me much easier because I came there and like okay this a certain problem those people have a question and they have some data what's what how how should we Channel this information so we either answer this question or we learn something about the question itself yeah all the system all the data so we can take another step that can lead us in the direction of solving this problem I think this is a very in a sense fundamental or like first principles based perspective uh and I think it's also very important causality uh and I find dags as a device that can help us understand information flow in a very clear very clear manner yeah that's great I think actually to mention there as well have you read the book um goodle eer and B no I heard about this I think at least 10 people in my life told me like hey this book is great you need to read it absolutely so I think I think there's a strong first of all I think we will look back at this book and we will find connections to Cal research there as well at some point it's it's obviously a long read but I do recommend it to the listeners as well because GLE was a mathematician aser was a artist painter and B was a musician and there is an underlying you know there's an underlying unifying concept here for all of them and it's it's quite the same actually um you know and it's expressed in different ways music or mathematics you know I mean b if you look at it actually what he um what he composed very maem exactly yeah yeah and so um I think it's the same of course inference we we need to go deeper you know as isn't it in the movie Inception where it's like we need to go deeper you know we can know deeper in those levels and proxim learning for example I think is also going to be really interesting in the future um so I'm really interesting to see what we're going to be you know in 5 years looking back at this episode and seeing what's developed out of all of these very you know uh early initiatives and what people would do with it yeah definitely I'm I'm also very curious about this and you know recording a podcast like this gives us a a POS a possibility to look back yeah and hear what we F back then exactly yeah yeah yeah is the future causal is the future causal I think life's always been causal I think life was caal yesterday today and tomorrow unfortunately some people thought that cality can be talked about for the last 100 years so let's just ignore that little blip there and move on to accept that the future is caal because it's always been causal and we should be just more explicit about it the causality isn't going to go away language might change um but uh the fact that there's a cause and an effect is is hard to deny um unless you want to go really philosophical so the feature is absolutely Cal and will always be some people start just starting with causality or maybe starting with machine learning uh might feel a little bit unsure if they will be able to learn all the tooling that they need in order to make this work what would be your advice to them it entirely depends on your entry point if you're a math PhD you're going to have an easy time you're just going to pick up a bit of stats you're going to read a book and if you are going to know practical you know they can read your book and see probably how to you know use the Mathis and packages if you at the very other end and you don't know mathematics of course it's going to be hard um I think if you want to get quick results uh obviously read pearls caal primer to get a bit of an understanding and and just see if he can learn from examples and uh emphasize quality over quantity you know if if he starts without much knowledge and uh you make it as your goal to understand for example the instrumental variable model which is very established and there's a lot you can read and that's a good goal and that should you good for go for and that's a c of method you can rely on and that's something that's going to give you a a good stepping stone um don't go too broad and frankly with all the most recent research that's out there in published you know sometimes the code isn't good sometimes um the method isn't even properly verified so do always go deeper and find the ground roofs and the fact is causality at its heart isn't actually that hard it's just we've been not teaching it right uh for the last 20 30 years um so erase your brain about all you flirt about stats you know find good resources um and then put quality before quantity you know if you have to read that chapter 10 10 times over 10 months then that's worth it um and so that that's what I would say this advice is on fire Co I love it Jacob uh if I ask you to build a causal model of of your of your life oh well what would be the main uh things uh resources your internal resources or external resources that you feel helps you moving in your career I think the external one was um obviously incredible uh support from my family to just explore these you know things um and you know always be tolerant of all the questions I asked and you know having access to education having living in the time with internet and meeting the right people at the right time which requires yourself to be put out there so I guess internally guess I'm I'm grateful that I was given you know some gifts to understand mathematics a bit more and Gifts of curiosity and and yeah so I I guess internally they I also feel like they give me a responsibility to share that as well I mean I'm just grateful to be here today to uh share my experience you know with PhD students about research and with with practitioners about you know how how to address this and make sure that you really question your assumptions you know one wrong assumption can create a lot of damage but you know 10 good assumptions really well Justified can go a very long way um and so this is what what I guess personally internally drives me um is the responsibility to share the learnings I have um with other people um because I guess I expect it from them as well because I would want to be treated that way um and that's pretty much it yeah what resources would you recommend to people just starting with kazal caral primer Juda Pearl um that's a good book easy to read um and what else we got it's quite funny because of course once you've done your PhD you forget where you started I I mean a practical work like that so I'm it depends what learner you are I think the course of primer is good for someone who's a bit more theoretical abstract I think a book like yours would be good for someone who just learns by practice I'm actually also more of a learn by practice person so um I would recommend practical stuff to start first and get a get a feeling for it um depends where you are for for sure um yeah I that that's pretty much it I have I have a web page this it's conveniently called cal- inf.

org I haven't updated much but I actually have a listed as beginner intermediate and advanced great so you can go on the web page um and um learn some things there as well yeah you mentioned your web page what are other places where people can learn more about you uh your team your research yeah so there's my my personal website which is Jacob D.D um and then um there's also a block on my my company web page um where we and then we actually have a seminar series as well on on Bas in optimization and experimentation um and are they online or uh they can be online yeah so it's on request so it is is online some people join virtually um and you know if someone has a a real thing they want to contribute then yeah would we happily talk and chat and otherwise I'm LinkedIn just like you you know I I do think to that LinkedIn is uh at the current stage doing exceptionally well and connecting people um and so people can just add me on LinkedIn and shoot me a question uh was a minim Jacob what's your message to the caal python Community the causal python Community my message is very simple think about the cost of your Cal assumptions number one the step first is to question your assumptions and then think about what's the price what's the dollar tag on this and because they don't come for free some are cheaper some are more expensive uh and do just really consider when experimentation is a good choice um I think that's that is the most you know realistic perspective of cost inference you're going to get um because we want to avoid a world where we just walking around with purely observational uh you know data sets um I'm okay with people doing observational studies to inform trials but I find it really hard to just do an observational study and never even think about how you would run an experiment for uh for that to actually verify the results and so um the cost of these assumptions to slice the the polytope to get to something more justifiable it it's just going to make your life easier as well H focus on that um and you will be just fine so follow the truth question your assumptions uh and you will you will get to a good place thank you so much for your time I love this conversation and I hope that you will also love it thanks for having me it was a pleasure congrats on reaching the end of this episode of the CAO Bandits podcast stay tuned for the next one if you like this episode click the like button to help others find it and maybe subscribe to this channel as well you [Music] know [Music] all [Music]