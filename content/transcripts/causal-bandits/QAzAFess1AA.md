so I would say that it's great to be wrong and that's how we learn hey causal Bandits welcome to the causal Bandits podcast the best podcast on causality and machine learning on the internet today we're traveling to Berlin to meet our guest he started learning programming as a child by modifying code examples from a book that he got from his uncle he played guitar in a metal band and studied bioinformatics just to fall in love with basson modeling which inspired him to grow and develop one of the most recognizable Python probabilistic Programming Frameworks ladies and gentlemen Dr Thomas Vicki let me pass it to your host Alex molak thank welcome to the podcast Thomas yeah thank you so much I'm excited to be here how are you today very good yeah I'm relaxed I had the pleasure of seeing you set up this amazing setup and uh excited for this discussion so yesterday we we had a dinner together and you told me a little bit about your story about how you got fascinating U fascinated by programming by computers by this idea of creating something out of nothing by the idea of controlling the system then you got fascinated by by Neuroscience and bioinformatics and then Bas and modeling came tell me about the day when you felt that you don't you cannot imagine yourself anymore as a p person in the future that is not doing be modeling I don't know there was like a particular day but I mean it definitely became more and more certain as time went on and I found that these tools and Bas in modeling specifically I could not just use in my PhD research but also then at the job I was after um a fintech startup called quantopian based in Boston mhm and that was focused on building a crowdsourced hch fund so Quant Finance something completely different and nonetheless the type of problems related to portfolio construction and evaluating algorithms that really was well solved also by Basin modeling so just the same tools as I was using there I could use just as well to solve these completely orthogonal problems and that's when I definitely realized is like okay well this tool is not just useful for academic but also for industry problems and pretty much any data science problem well not any but a lot of data science problems where you need to really build a deep understanding and want to incorporate that understanding into the model and what was the bridge from this first day that you that you saw a computer in your life and maybe you realized what set of possibilities what what set of possibilities it offers you and between this day that you find uh yourself falling in love with with Basin modeling or probabilistic modeling yeah I mean I always just thought it was so fascinating to be be able to really create something and do so creatively right so when it's programming there's a lot of creativity involved in terms of having ideas and then bringing those to life and certainly in the development of PC that was really alive and but also when building models but really I think these days the thing that I enjoy the most is the community aspect behind that so I mean I love just being in front of a computer and doing some modeling but much more fun is it to do that with other people so that is very strongly expressed of course in the open source Arena where you just put some stuff online and then random people from across the world show up and they're like hey I thought I might just make this really really significant contribution in my free time and then you get to know these people and realize how talented they are and friendships for and the sense of community is built around that and that's really what I feel about PC and also PC Labs where uh it's just amazing to be able to work with driven talented people solving extremely Advanced problems and pushing the boundary of what's possible so something that wasn't possible yesterday today we maybe have made possible and just opening up these things to things that before you couldn't really even imagine maybe so yeah those things I just find endlessly motivating and fascinating it it sounds like this element of discovery of pushing the boundary of of seeing a possibility in something that today we see as impossible is is something important to you yeah definitely um I that image of being like an Explorer in the modern sense I I find very appealing and uh and yeah being able to do something at that that no one has done before and and not only for myself but once we've done it and that's the amazing thing about technology and software right like the day after something new is merged then already the next day the whole world has access to it so that sense of pushing the boundary and then that level of impact to enable Humanity to do things that weren't possible before and solve potentially massive problems right that's the other thing where there are so many important problems right um from climate change to um what have you and then yeah uh I think that these tools definitely can make a lasting impact to that and it is being used in P C is for example in all these different like I just looked the other day over 2,000 citations um of that original publication from like astrophysics so people are using it to solve actual applied problems so that I think is just immensely cool it sounds like something really really rewarding yeah to have this feeling of of such an impact okay so uh you just added something something new to to to PMC and this is a caal do operator can you tell us a little bit more about this yeah and we're very excited about that so me personally I don't consider myself a causal expert so I have that Basin background and I feel like I'm just starting to learn through these these topics in uh through that Basin lens and I feel like that is actually really helpful because to my understanding these two Fields have mostly developed independently uh but nonetheless there are all these really interesting cross connections like also between basian uh statistics and machine learning right so and I think it's very instructive to learn about that so that's how I've been approaching it and really the main driving force behind that is Ben Vincent who has gone through like a lot of the causal Theory and then really did the hard work of mapping that into a language that I as a basin could understand and I think then other people who come from a from that background can understand better and very naturally then as we are starting to understand these Concepts and reformulate them in our own language then we want to start and apply them and and take the best ideas and incorporate them into that framework into that Bas modeling framework and the DU operator was one of them where it was actually um it actually fit really well into the framework from the software side it was still I guess a little bit challenging because it requires some graph manipulation and we had to add some functionality to that um and actually it was Ricardo VI who who did that implementation of the Dual operator and everything that has to happen under the hood and yeah so now we have it and that adds I think one of the um critical missing pieces to really make PC be uh framework in which you can answer structural causal problems and build these types of models that I think are really really exciting and now you have more of that Machinery from directly the causal inference domain you mentioned the structural aspect um and when you look at the way PMC and other probabilistic uh programming languages frame the problem of modeling there is a structural aspect uh in this and and it's and it's a very fundamental aspect uh structural thinking is also fundamental for for causality and what was the first time when you heard about causality and was it something natural for you to build this association between those structural aspects in both in both uh worlds so yeah I remember when I first uh saw causal inference before I just heard about it and that was at a talk at odsc London a couple of years ago and I remember sitting there and seeing that well they were creating these structural causal models to answer interesting data science questions in that example around price elasticity and and I remember thinking like well that is what we doing with Basin modeling as well right we don't call it I guess structural costal modeling we call it the data generative process but nonetheless um so at the end of the talk I asked what is the differen between the type of models we're building in a basing framework and they were like that's a great question I don't know and on many subsequent talks about caal modeling I kept asking that question everyone was like hm I don't know I mean yeah sounds kind of similar but no one really seemed to know so yeah um this basically is then so now I I think we have the answer and the answer is yes those two things are the same just to a different lens through a different framework and that's what I think is exciting about it so I think there's a lot to learn uh in both domains like one is qual inference I think is has very powerful idea and really puts causal obviously front and center and estimating treatment effects and how to think about the world uh but a lot of it as I see it is expressed in a frequentist framework now the um create the many of the people behind that like Pearl they don't say that it has to be frequentist but in reality that's what I observe so I think there's a lot of value in expressing these ideas in a basin framework and on the Basin side I think there's a lot that we can learn in adopting that language and that framework because what really is the benefit of of basin modeling well there's many things you could say and I have always tried and refin that obviously with PC and PC Labs it's our mission to try and make these methods more widely available and more widely used so we really have to figure out how to explain this to people who haven't heard about it and once you start talking about priors and uncertainty like people don't really get that and then I guess you can talk about transparency and that's a bit better but talking about causality I think that really resonates with a lot of people and I think that's also why causal modeling is quite popular these days uh because it it makes sense right just intuitively like yeah if you want to act on the the world you have to understand what causes what to take the most effective action so that is I think an amazing motivation for building these structural models and we can just as well do that in a basing framework in and now with the do operate in PMC so that's what I think is really cool about this and yeah there are these parallels starting with the structural approach MH you said you said so many interesting things here uh that I have already a list of questions in my in my head to to learn more about your perspective here let me start with one one particular question so you said something about the communication how you communicate with business stakeholders and how you um what choices you make uh regarding putting your focus where to put your focus in order to show them the value of of B and framework and it sounds to me like you just said that talking about causality uh seems like a powerful tool to convey this value to people who are not necessarily in deep into modeling deep into statistics and so on is is that correct yeah absolutely so um after really having tried this literally for 10 years to try and explain why Basin modeling is a good choice for a certain type of problem it um and and many Mis starts in that uh that idea of really so the way that I'm phrasing it now is well what is the purpose of data science right why are we even doing this um and I mean a lot of people like me do that and I mean I guess that's also what we talked about just I think it's cool and it's fun and right and we're pushing the boundaries and that's a valid point is it a really good point well maybe not right um so or maybe it's to make better forecasts right that we can predict what's going to happen and that sounds useful but really I think ultimately the best answer that I can come up with is that the purpose of data science is to make better actions right make better decisions and how we do we do that well if we want to make better actions that lead to desirable outcomes we really need to understand how actions affect outcomes right and that is at the core a causal question because if we mess that up right then we might be able to forecast what's going to happen but we're not able to affect what's going to happen so that type of logic and and communication style I find pretty compelling at least to me I don't know what you I'm curious if you agree um but yeah so that's um that's that's how I think we can really start conveying these methods better so but yeah what what do you think well it sounds to me like like in a sense going back to basics and asking a very fundamental question why actually we doing all this stuff and I and my view is very similar in the sense that I think we built a culture in data science that we just take some tools and we use them and we try to apply those tools to any problem that we that that we are encountering and the fundamental myth that is beyond this uh this culture is that prediction and decision- making is the same thing exactly but it is not but it is not um a couple of weeks ago I got I got a message message from my friend so he texted me on Whatsapp and and he and he added a a picture so he show a picture of a of a whiteboard with like structural some some structural modeling and he tell and he captioned this by saying I'm trying to understand how our marketing works we have a set of machine learning models we use them for over three years and our marketing is pure losses for all the fre years D and this is using uh machine learning predictive predictive modeling or predictive approach for decision- making right it's not a tool that can provide you with this information I had this metaphor with a with a map if if you just use Google Maps the the the most default view in Google Maps it's very useful to help you get from point A to point B but if you're a climber and you want to find another month to climb and so on you w't find this information in in the default mode of Google Maps it's just not the right tool to get the answer that you are seeking for yeah yeah I completely agree um and I think it's very easy for us as data scientists to not really think hard enough about really how do we have this business impact right so and I mean there's all kinds of reasons for that some of them are structural that often these are different organizations right and the data scientists are doing their thing and they're deploying models and then how critically are those evaluated at the end of the day right and maybe 3 years later you take a look and you look oh actually this isn't working at all like yes it's doing very good predictions and it's super fancy but does it really solve the underlying business problem and that is something that I think we need to think much more carefully about and I think for most of those problems then the that causal approach is very powerful uh not for all of them right I think there's like legit forecasting prediction problems where just blackbox ml algorithm will do the job just fine but in my personal experience also with um seeing this through primy Labs is uh there aren't they are way fewer than I think are getting applied to um way fewer problems where machine learning is getting applied to where it's actually the right fit so I think with a little bit more careful thought and understanding the problem and building a model that is mapping that causal structure we can solve these problems and it might be harder we might have to learn new tools and develop new tools but uh I mean that's G to be what is determining the future of data science right like whether we're still gonna be relevant or not will depend on whether we can solve actual business problems or not some time ago a couple of weeks ago I had a conversation with with Robert NES from from Microsoft research and it turned out that we share a common experience we both work with cality and we had this experience of hearing from people uh that they are really really concerned and really really afraid that if they need to explicitly Define this structure the data generating process or the structural causal model they are just afraid that it will be wrong and as a beijan modeler you are experienced with this right so you making choices like what makes sense and what doesn't make sense and which direction should be should the influence flow and so on and so on what would be your advice to people who are just starting thinking structurally to overcome those fears and what would be the what do you see as an opportunity cost in this case so I would say that it's great to be wrong um we're wrong all the time time and that's how we learn right so we build a model and we start with something very simple and that oftentimes we might think like oh yeah this is like a good first cut um but oftentimes it's not and then there's all these tools right to find out how whether you're wrong and how wrong you are like posterior predictive checks and simulations right to see like can I reproduce the data um and then you find like oh actually know like it's doing a terrible job at that and then it's like then you can ask full-on questions like well why uh does it have that behavior and start fixing things and then you actually learn something about your data rather than just like throwing more um machine learning at it and of course the other path that opens up is communication with those domain experts right so usually as consultants we don't come in with um The Domain knowledge and we build these models from our best understanding and then we present them to the client and they're like oh well actually that's not how these things really fit together and then we learn something and we improve the model so yeah we're we're so long uh we're wrong as long as we until we get right and then you have actually learned something about the problem you have model that works and that the domain experts agree on and that model the data well and then you really cooking and what's the alternative actually not of not doing this yeah exactly um I I don't know I mean I guess um you could just yeah train a whole bunch of classifiers uh that learn whatever they learn um and it might be nonsensical but even if it is you don't learn anything uh in that approach which which I think is problematic and you can't really communicate Your solution either um to other people which is also then a question of trust right like would you really have your marketing budget be determined by a blackbox algorithm that might work completely counter to your own intuition um and often times these people have done this for decades right and really have a really good idea of how these things fit together and then in the best case scenario you ring that together you bring the domain expertise and what the data says together and get the best of both worlds rather than doing things in a completely qualitative way using just only the domain expert and Excel spreadsheets or doing a 100% datadriven approach where you only have the data and you fit a model and and have the predictions do so I think yeah having both of these work in Tandem and support each other helps with the solution but also with the trust in terms of using them mhm I always say to people that just selecting features using their I don't know Intuition or just putting everything into the model is also building a structural model right yeah and every feature you put in those in this model every every decision about putting or not putting a a a feature in the model it has a chance to impact the uh conditional probability landscape of this model yeah um so that is often times what uh Basin like to say when people criticize priers for being subjective and uh and the response to that as well all modeling is subjective and and that's true and like you do actually I think it's really a great idea to extend that argument further right because even in a machine learning framework you make all kinds of decisions right uh starting with the data processing and by now there's a lot of research also on the uncertainty that is introduced through that process and it turns out that that matters a lot right like how do you remove outliers um do you normalize your data what type of machine learning algorithm do you fit like all of those things matter a lot to the end result so yeah these are all choices and you can either be very conscious about them and transparent or not you also have extensive knowled in Neuroscience is there any any connection between uh between learning how we as humans and maybe all the non-human animals how we function cognitively and how we function in the environment we how we react to environment and your approach to Basin modeling H so um there's definitely a very interesting research Direction in cognitive Neuroscience that is furthering the hypothesis that the human brain works using Basin updating essentially and whether that is true unlike um every level um is is a science question right and there's good data for it um but I think just that general idea is so compelling right that like we start with some idea about how the world works and then we go out and we apply that and we learn something and then we update those beliefs so that's how we all operate and I guess what is interesting in the context of this conversation is that there is this uh obviously causal model that we're all building in our head of how the world works and and and that is as much a part of it as updating our beliefs so I think there's some really interesting parallels there and also just really helpful intuitions that well yeah that is how we learn about the world and that's probably how our computers should learn about the world as well mhm when humans uh learn about the world we build those causal models but perhaps and I say perhaps because I don't know the answer ER we we do not build one huge causal model of everything that we experience maybe we we have just like local causal models and when I think about uh marketing and and and you uh with the PMC team also invest in this direction by by building PMC marketing and Publishing marketing mixed modeling blogs and and all this kind of stuff uh marketing is is a set of actions is a very complex environment and we could think about two essential two fundamental ways to to to model this this complex environment so one would be to try build as huge model as possible and as accurate as possible so let's call it a global way and and another one would be just focusing on what's important for us for a given given problem that is maybe a little bit more narrowly defined and then maybe build a series of those smaller models from your experience which approach makes more sense in practice it's it's a great question so I think in practice what we're mostly doing is always building the more localized specialized models because really that's the only way you can start um I in the past I've definitely tried and build like overly ambitious model that then just crumble and always had to go back to basics so these days we're always starting that way but I think there's a huge appeal to these Global models and one of those comes from the fact that probably many different things influence each other so in that blog post that you mentioned before where we introduced the do operator uh we talk about the marketing funnel and how different aspects affect purchasing Behavior at the at the bottom of what we're interested in so certainly marketing does that right so and there's different types of marketing there's brand marketing that is more driving awareness of the product and maybe then through Downstream effects and Cascades has that effect on sales versus more direct um Performance Based Market marketing and then there's other and that's usually well that is already pretty Advanced for like a media mix approach where usually you just have those you don't separate those out um so you can start doing that and then you can think of okay well I'm not the only one doing marketing there's also competitors who are doing marketing and that Al also works for increasing awareness of my products right because it grows the general pie so why don't I also include that but then there's other things that we know affect things like for example uh the price right like how how what's the price elasticity of my product and where is do I set the current price point and also the price of the competition so like all those things interact and I think it's uh it will be very interesting and I think it'll be the best model to really include that and probably we will start with individual pieces and then start connecting them but whenever we did that in the past um especially connecting these different data sets like you have your marketing spend and your purchasing Behavior but maybe also you ran lift tests um so there's something we did with uh in the hellofresh project where they had these lift tests where you test specifically how good is that channel um using much more accurate measurements than what an mmm could provide and you can just add that as another data source another view into a latent process and then that turned out to make the fit significantly better so yeah like linking thep data sets and connecting them in sensible ways uh is usually what I think we should all be thriving for mhm to what extent you feel like just putting some of the some of the existing processes as uh we sometimes call it exogenous variables which means that just distributions like some noise distributions that are impacting how the model works but we don't Define them so we move them outside of our scope of the variables that we can intervene on we just say like hey we know that all this stuff impacts this variable jointly we assume that the distribution should be more or less like this maybe it's normal probably it's not in in real world and we just we just put it aside in a sense to to what extent or where where's the where's this boundary where you feel that this approach just putting things like hey this is the external no noise to our system uh is is useful versus saying hey let's analyze what are actually what is this noise what constitutes it and and so on and so on where is where would you set the boundary in practice in Practical terms yeah um so it depends um and I think there is it's always going to come down to like the specific problem and data set and whether that actually matters or not so this is definitely something that in the model creation process we would test and say okay um are those noise terms can of just like summarize them and and be done with it and simplify the model that way and if that works then great um and if it doesn't well then we add more structure to it MH and see how big the benefit is but of course even if there is a benefit it might not warrant the additional complexity I would say though in practice we tend to ER on the side of including more than less so and and I think for good reason so um we do add um most of the things we care about because even with that usually I would say that we're always a bit under um underutilized in terms of what the data can provide so um there's always a little bit more that we would like to be able to model than than what we have data for in terms of like structure like for example we might only have aggregate purchase Behavior where really we want individual purchase behavior of individual customers but we only have the aggregate so we can only do that and then the assumptions that come with that so there's um yeah a lot of assumptions that we then have to build into the model that we'd rather not directly have so these are like approximations that we're we off uh and probably it's going to be fine but if we had this additional information we would love to include that and build a better model when we work with with Cal models using frequentist approach to to inference to to estimating the parameters uh we are often faced with the decision which variables should be included in the model in order to reflect the structural properties of this of this model beian perspective in terms of probabilistic programming languages and Frameworks like PMC uh seems to be fundamentally different what are your thoughts on this yeah so I think that's one of the areas where Basin modeling can really provide a big benefit for causal inference the way that I understand what mostly is being done today with causal inference where you you build the structural causal graph and then you input that into like an analysis framework that does back door path front door path and figures these things out and then says okay these are the variables you should include and these are the ones you shouldn't include if you for the subsequent estimation of that model but often times it's not fitting that complete structural model it's still then doing say a linear regression um and then of course you want to be very it's very important to solve that variable selection problem because if you include to the the wrong ones then you're getting biases if you like a collider for exactly yeah if you include the collider you get uh the wrong answer if you don't include confounders in in the right way you get wrong answers so that is very critical to that um I guess frequentist path of doing things although I think these two things are largely orthogonal however in the basian framework what we're doing is we're just like building that model the same structural model and then we're just estimating that directly we're not sort of we don't really need this type of logic to say okay these variables I have to include these I don't have to include we just include it all and for example a collider well we just include that structure in the model and then we run our inference and that will incorporate that already in the right way and there's actually a related point that is really critical here which is I think there's going to be uh I mean people are definitely working on that right and the ability to have this Calla a graph and then directly estimating the strength of those connections um but if you still do that in a uh for example with a point estimate um or frequentist way that is often times going to give very um biased or noisy estimates so that's something that we that as a basin we often see is that if we want to do Point estimates which Basin can do that that these Point estimates are often times just not at all what you want them to be so for example in hierachical model which are very common right but in a basian framework you just estimate them and things just work out but if you estimate them with Point estimates and you just look for the the mode the the most likely value in a maximum likelihood framework it will just often times uh collapse everything together to a single point um and there's like theoretical reasons for that where weird things happen in this parameter space if you're trying to estimate um things in a certain way and you're just looking for the maximum in that parameter space that is often not the point that you really that's going to be most representative and most useful so what you really want is the mean um and and and for that you have to run something like Mar of Chen Moto so if that was too technical doing Point estimates is very limited when you're trying to build more complex structural causal models and that's really where you need to integrate and that's where you need often times Markov J M Caro because that is one of the most flexible and general purpose algorithms for solving that problem is all of this that you mentioned also related to the fact that bean modeling in this version that we are discussing here and that PMC offers is generative versus what we have in traditionally in in frequen in inference a non-generative approach I think that definitely helps and it's um a very powerful tool in building these models and really understanding the type of problem that we're trying to solve so one step in that Basin workflow which is essentially how we build models is first before you even fit the model to data you just build the causal structure that you think is going to underly um the problem and once you have that in this framework that can actually Express this graph and then generate data you can exactly see what type of data is generated by this and usually humans don't think in paraba spaces they think in terms of like oh well this is the data that I have and this is what I want to uh this is what I expect to see so once you do that you really immediately see what uh whether it's doing the right thing or not and then often times from there you can really Intuit it okay well that's not um probably this assumption that like this thing influences the other thing might be wrong what happens to the pattern of data that are generated when I change that and maybe then all of a sudden like oh okay well this actually makes more sense now so there's a lot of structural Discovery um which is a very caal term um that can can be done just by going through different hypotheses and and seeing the implications of the hypothesis that we put into the model this workflow reminds me very much of of what we do when we when we usea causal Discovery in in real world settings which means that this is almost always an iter iterative process um so we do something very similar we learn a structure uh very often we also want to include as some sort of a prior not necessarily in Bean sense sometimes yes sometimes not uh the expert knowledge that we have available and then we compare what what this model looks like uh comparing to the data that we have from The Real World or some insights that we have maybe from an experiment and so on and so on so this seems very very related on a conceptual level yeah and uh sometimes now that I'm talking talking more about Basin causal inference I do get that question of like well how do we even come up with that graph which is the question for structural Discovery where there are um quite a few causal inference tools that like just try a lot of different combinations and there's some work in the Basin domain for that but most of the time we're still mainly just building these things in this um iterative simulator approach and that actually um I find so far hasn't really produced many issues in terms of like oh well the space is so large and we have no idea about the problem we just need to iterate everything through usually that search space is pretty constrained and with some guidance you can make a lot of progress so so far we've fed fairly well with that approach mhm over the last year or so there like many new developments in in the PMC ecosystem that are causal so we had a do operator that we the do operator that we discussed before but we also had I think last year a new package in the in the family called Cole p is the future of PMC going to be even more Cole um that's a good question so I think there's a lot of premise there so uh causal Pie has been really the first I guess piece of causal inference that um we started to attack and a great package developed by also Ben Vincent and that is focus on quasa experimentation which I think is a pretty nicely constrained set of models or problem domain and that's I think where we first understood like okay well this is how causal analysis would approach this type of problem well really what it's doing is just fitting data on an in uh sample period and then predicting the outo sample period and then comparing to what actually happened and there's various combinations of that but well once we're fitting something and predicting something we can do that with machine learning or we can do that in a basin model Basin framework and that's what causal P does so it allows you to either use um a psyched learn model or a basin model and if you use a basin model you get uner C and in the other casee you don't and so yeah that that was um that insight and from there I guess we really learned that there's a lot of misunderstanding is too strong of a word but nonetheless I think there is um a lot of historical reasons and and and maybe even baggage where I I have heard that like well you can't really do causal analysis in based in uh fr framework or sometimes you will say with Basin networks that's not supported and for example one is well in Basin we're looking at conditional probabilities and that doesn't cover the case of interventions which is the do operator and well okay traditionally that's true but there's really nothing stopping us from adding the DU operator right and then like well is it strictly technically still a Bas a network who cares right I mean these are all just tools and we want to build the best tools so and it's all at the end of the day probability so um yeah I think there's a lot we can do if we're trying to come at this with fresh eyes and really seeing okay well what is still requir today and maybe what are things we can now do better with the better tools we have and just being free with the exploration of these methods and allowing ourselves to do that so to bring that back to your question um yeah I think that's really powerful direction for PC in adding these tools and also in communication as I said earlier well it's a very powerful way of thinking about the world and data science problems and solving them and I'm um I'd be delighted if PC is uh is going to be helpful in that endeavor you mentioned the the topic of uncertainty and uncertainty estimation a couple of times today um and and you emphasize that be framework allows to do it in a very natural very organic way over the last a year maybe last year or maybe two last years there's also another way uh of estimating uncertainty that became very uh popular and prominent which is called conformal prediction that comes from more from the frequenti uh from from the frequentist tradition what are your thoughts uh on strong and weak sides of both approaches to uncertainty modeling yeah so I think like those are really interesting directions the way that I started to think about it is that really there's two orthogonal things going on and I think that is what at least for me was a big point of confusion where uh like I said earlier I just kept asking people like well in Basin framewor we also doing that is that the same or different and no one really knew the answer so the way that I'm starting to think about is that there's two axes and one is along the axis of uncertainty quantification and the other one is I have to find a better term for it is maybe actionability or understandability where for example blackbox machine learning models I would say are rank very low in terms of the understandability that just fit some function then we can move up that scale and look at correlational models and um that certainly gives us more insight right we can really understand how things relate to each other and then of course the ca of people are saying well that's not enough because uh if we don't understand the directionality then uh we can't really take action so that I would put at the top there that causal understanding that we get through caal models but these models how we then estimate them is a completely orthogonal question so we could just do Point estimates that's fine uh we can do frequentist that's fine or we can do um Basin model um and conform prediction fits in that model as well so um and and yeah so different tools can be placed on that map as well so yeah that's how I think about it and like I think there's all kinds of different ways of doing that and on that two-dimensional space you want to be on different points at different times for different problems and then it's just about like okay well what what tooling do I require to solve that particular problem mhm I I also found one uh another one another one di menion that um I think is significant here and I would be very curious to hear your your thoughts on this so in Bean framework we often can pretty easily split the um estimates of aloric and epistemic uncertainty while conformal prediction just gives us total uncertainty for for a given model in in more like a blackbox manner right because it looks at the outputs and then the does a little bit of calibration that's a simplification but let it be um do you find the this ability to split aloric and epistemic uncertainty quantification as as something useful in practice it depends on how much you trust um that split and a lot of it will depend on on your prior and how precise you choose those so I think more of uncertainty in terms of not absolute but relative terms so given that was my starting belief about the world um now I'm thinking about it this way and but nonetheless like even that uncertainty estimate I think needs to be validated and and and tested on on reality whether those uncertainty estimates are correct so for example for a while there was the very top U popular topic of basing deep learning and I also got really interested in that because I thought like oh well there's a lot of um interesting things that we can do here and maybe having things in a basin framework will be really helpful but the more I worked on this and started thinking about it and of course other research has come out as well because one of the biggest selling points there is well we get uncertainty in our predictions and that sounds cool but then the question is well what type of uncertainty is it and how does it behave and then when you look at it it actually is not really the type of uncertainty you want because um what it does is it estimates a hyperplane right that's uh if you have a classification problem and then the uncertainty just keeps decreasing the further away from that hyper plane sorry the uncertainty keeps um yeah keeps decreasing the further from the hyperplane you go but maybe very far away from the hyperplane you also don't have any data so it doesn't behave in the way where like oh this is the the type of example I've seen before so I have very high certainty about it and this is something I've never seen before right like some let's say I have an image model and it just give it um a white noise thing and then you would expect that it has very high uncertainty about that but that's not necessarily the case because maybe it ends up somewhere in the parameter space which is very far away from your hyperplane and then the uncertainty will be very low so it has these weird properties and then when we start thinking about the parameter space itself and then the uncertainty in that space what does that even mean in a way so the uncertainty I think is very model specific and then the type of answers um that we're getting and then whether it's um how we divide that between uncertainty from the data or the model I um yeah I I think that that is um I would need to do a lot of validation in order to really believe uh those numbers mhm and and when you use uncertainty in uh uncertainty estimates in in PMC in practice so we M we discussed a couple of examples with related to marketing um what's your approach there so yeah um I think the that type of uncertainty is very interesting and becomes even more interesting when it becomes actionable and the way that we always love to do it is again coming back to that concept of actionability right rather than just providing posterior estimates and cool like we can estimate how strongly these two things are correlated or maybe Cal and now in addition we get uncertainty bounds around that and that's useful and we need to make sure that they're somewhat calibrated and meaningful again they are I would say it's more about um comparing this to let's say I have that same model and I fit it on a different data set like a smaller data set and then you can see like oh the uncertainty is much wider here than there or I compare different marketing channels right M so that I feel much more comfortable with and but what you can do then which is really cool is take those uncertainty estimates and put them into an Optimizer and Define a loss function that tells you okay this is an outcome that is preferable in this case it's I want more sales right so and because at the end of the day what do we want to do with that marketing mix model yeah analyzing it and seeing how effective certain channels are is is interesting right and people can take that information in and then maybe do something with that and but what are they going to do they're going to adjust how much they're going to allocate to different marketing channels and that's cool but we can do one better where we just treat that as the optimization problem and say okay well we want the to allocate the budget most effectively to maximize the sales that's going to be my loss function my objective function and I'm going to find that best setting and there the uncertainty plays a big role because if you just treat Point estimates a marketing channel for example that maybe was on for like two months right and looks really really good we get very high Effectiveness estimate if you only look at the point estimate and a marketing channel that has been where we have data for 3 years and it's been solid but not amazing you would give that a smaller allocation well the optimizer would in practice most people would say well I don't trust that small window right they have only very little data for that channel I will probably like stay on the safe side mhm but once we include the uncertainty in that the optimizer does exactly what the person would do which is okay I'm going to go with a safe choice where I have a lot of data very little uncertainty that things will go wrong and the new one I'm going to like keep in there but not like um double down on in a sense we're coming back to this uh to this area of connection between human decision making and human psychology and and modeling again yeah uh exactly so I think a lot of that is how humans make decisions how we think about the world and we are risk averse right there's a lot of research on that and if you don't have a measure of risk which is just another word for uncertainty in your model those answers can't possibly take that into account that we like to have solutions that take that risk into account um and of course we're also coming back to that concept of actionability and what the purpose of data science is right it's about making better decisions and for that just giving someone a POS distribution or an estimate with arrow bars is not as actionable as just saying okay well given everything and you understand the model right and all the connections this is the best put this is the best budget allocation of our marketing spent that we can have and then of course we can inquire that and play around with knobs and do different simulations right and see what happens if I diverge from that and so it opens up that discussion and provides really interesting uh solutions to to problems much more directly than only the modeling does you mentioned U risk aversion that we as humans experience or display in certain decision- making scenarios when we talked before and and you told me about your story I had a feeling there's a lot of exploration there and that Discovery is something that's important to you and Discovery is in itself an act of going outside of what is is known it's it's a risky Endeavor and by by its nature in a sense what would be what would be your advice to people who are starting with something new maybe they want to go into machine learning or Bean modeling or maybe causal inference or causal modeling in Broad temps and they just feel that there's so much going on there they feel a little bit overwhelmed or maybe they feel a little bit not sure about themselves if they can grasp those those Concepts what would you say to them yeah no I mean I've definitely had a lot of doubts uh along the way I remember just starting uh considering studying bioinformatics computer science and knowing that that was uh there a lot of math required and I wasn't sure whether I would uh be good enough at math uh to do that and then nonetheless I gave it a try and it didn't come easy but nonetheless I really spent a lot of time just banging my head against the wall and like reading these weird proofs and then finally like oh okay actually it's not that complicated it's fairly obvious once you really understand it and then there's a for me there always was like a really deep level of satisfaction in understanding these Concepts and Building Bridges to different things but in terms of the risk well okay so two things one is I for the most part followed whatever was fun for me like I never felt like I really did something that I really hated doing and just only did it because like oh I want to be a data scientist or I want to be um a machine learning person so I have to do this what I hate like it was always fun for me and that is really what kept me going so it never felt like work um and nonetheless I did certainly take risks but through me they always felt like um risks where I really thought carefully about like the up and the downside and and protecting the downside so I wouldn't say that I'm not risk ofus I think I'm definitely am and that was one of the reasons also why I didn't stay in Academia so when I did my PhD there was also a very calculated risk in terms of like okay well what are the probabilities that I will have a career there and be become a professor and what would that look like and I didn't think that the chances were very favorable and nonetheless I thought it made a lot of sense to still do the PHD because I could learn a lot of things and then that would help me for an industry career if I would choose it but maybe I loved Academia so much that I would stay there and even then throughout the whole time I was very conscious of the fact that well if if I want to move to Industry I should probably have some skills as well so all this programming which I enjoyed anyway but I just realized that that was really going to be very beneficial for that and also going to P dat conferences and reaching out and doing internships at quantopian this is how I got my first uh job then after I finished my PhD in Industry so that um that was the other key aspect I guess is um following the passion and taking calculated risks and also just reaching out to people so many people in the past that I just sent a random email to and was like hey um that sounds pretty cool what you're doing like can I learn more about that and maybe do like an internship there and what I found is like people are often extremely open and helpful and eager to work with you if you if if it comes from a good place so yeah I think those are some of the things that that worked for me and then of course also with uh starting my own company with py Labs which has been like an incredible Adventure but also there like for example we didn't take on any uh VC funding or I didn't take on loans at the bank so it's it's totally bootstrapped so really what is the worst that can happen like it it may not work and then I'll do something else that's cool um that's not that bad right so just give it a try um so yeah I think trying things and but also maybe not overc committing right like I think it's easy to just have this like very uh just follow your dreams and like if you work hard at it it'll definitely work out I don't think there's any guarantees uh that that's going to happen uh so I think yeah it is important to be a realistic and if things are not working out well maybe then time to try something else at a certain point rather than just like doubling down on something that might not be might not be the thing that's actually working out because the other thing I learned is often times also then talking to many other people who for example stayed longer in Academia than I did they did a postto and then switch to Industry and that shows a different type of commitment I guess right because those were people who were like oh yeah know I love this research and the the work I'm doing so much I will fight for it I had that dream of becoming a professor and then that didn't work out and then they switched industry and 100% of them two or three months after I talked to them whether they like missed those research questions that were like their life uh they're all like what no like who cares like this stuff I'm doing now is like super cool and they're really excited about that so um most humans uh I think just fall in love with whatever they're doing so I think that can be factored in as well that like the thing that someone might think is like the only thing that will be amazing for them uh maybe they'll like something else just as much or maybe even more um just haven't haven't tried it yet it sounds to me like there are there are three main lessons uh that that you talked about so one was uh give yourself the last one was give yourself a chance to explore stuff outside of your what you're doing currently because maybe there is something that you would actually like more the other one was to take risks but in a calculated way so to think about the consequences and the worst case scenarios and the best case scenarios and the thir one was to follow your passion and do what's passionate for you yeah I think that's well summarized is there anyone who you would like to thank well I definitely had um quite a few mentors along the way that were really helpful um so my PhD adviser Michael uh was Michael Frank was amazing um I learned a lot at my time at quantopian um I seeo there F and uh just steth who was my manager they really taught me a lot in terms of like the type of company culture that was even possible like before I had this abstract view of like well it's just um you need to have this like hierarchy right and can't be fun and like to have project management and maybe it's agile or whatever and the the possibility to just break those rules and just like well no um maybe you can just have a group of people and be very transparent about what you're doing and everyone can contribute and there's no red tape and there's like very little hierarchy um or like self um like fluid hierarchies that just like assemble themselves and just trust a lot more in in the people to do the right thing when they have the whole picture and they have the sense that they can actually contribute where can people find more resources to to learn more about PMC the the whole open ecosystem and in particular for our audience about Bean modeling as as you see it and you see the PMC and and causality so I would start with um the PC website pc.

that has uh a really great examples Gallery where you can just like browse through and like see all different notebooks on all kinds of problems and that is I think a great way to get started because again it's that playful self-guided exploration principle uh I really love the blog post that we put out on the py labs website so pabs doio and then go to blogs and that has like for example also that post on the DU operator so that's where we output I would say most of the current thinking of like what we're excited about and and where we see things going and where these ideas like we talked about today are expressed um and then of course social media so um I guess LinkedIn is mostly where we post stuff um yeah I think those are some good good starting points mhm is there any question that you would like to ask me hm so what is the what is your motivation for well not just the podcast but everything you do right so what is that what is that driver and what is that um what does success look like uh in in this endeavor great question one more of the one of the main motivators for me doing the work for for for for the community is that in some of the darkest moments in my life I had this possibility to go to the internet and learn from other people experiences only because they just decided to put it out there for free and when I think about it even you know it gives me just Goosebumps all over my body I feel super super grateful for this I I have a ton of gratitude in myself for this and and I want to pay back to the community so this is behind my my blogging this is behind behind this podcast as well um and and and all my activities and of course there's also a let's say uh there are more business oriented aspects of my of my actions but they also make it possible for me to give more to the community yeah and I mean those two things don't need to be they can all fit the same thing I mean I think that the work we're doing with py Labs is as much part of the community building and because our customers are part of that Community too right and like the people who are watching this and and learning from your resources and and your customers um are yeah all all part of that so I think it's it's really great to be able to think about this holistically and and really yeah build these communities and that has been for me one of the most rewarding aspects of this whole Endeavor what is the best way for for people to connect with you so um you can connect with me on LinkedIn that would be uh the first line of business I still have a Twitter T Wei uh that you can check out and that's that's pretty much it happy to hear from anyone also feel free to drop an email um happy to hear from anyone great thank you so much Thomas it was a pleasure I hope that you all also enjoyed this this discussion and see you in the next episode thank you very much for having me this great thank you for staying with us till the end and see you in the next episode of the caal bandits podcast who should we interview next let us know in the comments below or email us at hello caop python.

stay caal