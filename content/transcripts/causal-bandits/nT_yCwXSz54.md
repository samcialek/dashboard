there will be two men falling ill for every woman who falls ill so how are you going to recruit them into the clinical trial there are many deep wonderful and complex theories of optimal experimental design that we medical statisticians ought to know better and wait till we needs probability hey causal Bandits welcome to the causal Bandits podcast the best podcast on causality and machine learning on the internet today we're traveling to Edinburgh Scotland to meet our gu he loves hiking and occasionally posts a picture of a beer on his Twitter he's passionate about the history of statistics and knows a lot about randomization the author of statistical issues in drug development and dicing with death ladies and Gentlemen please welcome Dr Steven send let me pass it to your host Alex mola welcome to the podcast stepen thank you before we start I wanted to I wanted to thank you uh because uh your tweets and then your book were very helpful for me when I was writing my book oh okay I'm surprised because I know nothing about python at all and not very much about causal inference either but there we are I would not agree with the second one but I understand your perspective on this in your book uh there's actually a quote that is both in this book ah okay and in this book I see and the reason is the causal relationship is that this SCH was in this book and then I cited you per okay good um so in one of the pages here you write that it's pointless to beat around the bush that randomization is not a controversial idea and that it's still controversial among statisticians and scientists even today what are the most controversial ideas about randomization that you think or you expect most people are not aware of so I think that the criticism comes from a misunderstanding the misunderstanding is that what the goal is is perfect estimation but AR officia who proposed randomization realized that perfect estimation was impossible but that maybe one could estimate how imperfect any estimate was and to be able to estimate how imp perfect any estimate was use randomization so the critics start from the point following position well hundreds and hundreds of things which could affect an outcome in a clinical trial and once you randomize it's obvious that they're not all going to be perfectly balanced and since they're not all perfectly balanced there will be some bias in the particular estimate that you produce but what they don't understand is that this is accepted it's known that this is the case but what happens is that these factors come contribute also to our estimate of error and I often put it like this if we knew that all of the particular factors in a clinical trial were perfectly balanced then in that case the standard analysis would be wrong because the standard analysis allows for the fact that they will not be perfectly balanced and it's failure to understand this which leads to endless tedious conversations in which people don't really know what's going on some people um say or expect that randomization will balance the the the groups so if we have a binary treatment for instance that by randomizing uh the treatment assignment we will get we will achieve groups that are somehow comparable um but this is not necessarily true no it's certainly not true in fact they won't be comparable in in that sense they won't be perfectly balanced it's obvious that they won't be but I think um to give another analogy which is perhaps helpful here is I sort of imagine the conversation between a mathematician and an engineer and the mathematician says to the engineer well actually the problem with the bridge that you've built is that in the hot weather the bridge will expand and then in that case you're going to have trouble because you've calculated the bridge in such a way that it fits over the river but uh thermal expansion will lead to lead to problems and the engineer says yes I know that that's why we have Expansion Joints and the ma policians say yes but you're ignoring the fact that the bridge expands he's not listening to what the engineer says what I've already told the philosophical critics is I've already allowed for the fact that the factors will not be perfectly balanced and I can demonstrate this by showing you how narrow the confidence interval would be for a crossover trial compared to how broad it will be for a Parallel Group trial in a crossover trial in fact I have some data in which some of the data from the same trial can be analyze as if they were in a crossover trial because the same patients have been treated more than once and some of the data as if they're in Parallel Group trial because different patients were also treated in different ways as regards other treatments and you can look at both of the analyses and you can see that the confidence interval is much much wider for The Parallel Group than the crossover trial in the crossover trial we're balancing for 20,000 genes all life history to date because each subject is their own control and this leads to much narrower confidence intervals in the parallel grp trial we aren't doing that but you can't tell me that my estimate is wrong because that's not the game I'm in I know my estimate is wrong the question is how wrong can it be and I've told you how wrong it can be probabilistically can you quickly Define for those people in our audience who are not experts in um experimental design what are the differences between crossover trials and and parallel groups trials so Parallel Group trial is probably the most common one and that's where you have uh patients say for example that you would randomize to receive either the new treatment or a standard treatment and so every patient gets one or the other and these are usually relatively easy to implement but it would be nice if we could actually have each patient to be their own control and for certain diseases only diseases which are chronic where the treatments are essentially reversible then in that case we can do this so for example in asthma which is a long-term chronic condition we could compare two beter agonists to drugs designed to help your lungs to expand and breathe more easily we could compare them by treating the patients for a period with one beter Agonist and then for another period with another beter Agonist and here we would randomize the order in which they're treated but in a Parallel Group trial instead which we might do for example in a in a trial in stroke prevention then in that case uh half of the subjects will be uh randomized to receive the new treatment to reduce the risk of getting a stroke and half would get the standard treatment that's a Parallel Group trial some a couple of years ago You released this presentation called seven myths of of randomization and you discuss a couple I think five questions different questions uh that we either can answer with uh with randomized trials or sometimes we maybe hope to answer with with those trials can you tell us a little bit more about this the idea behind this presentation and what motivated you to uh to prepare this material yeah I think I think the um the first um statement of that was a little bit before the the the random seven myths of randomization it was actually um in a paper called added values and the the five questions are as follows I'll give you the questions first and then give you the motivation question number one is um was there a difference between treatments in the trial so in other words was there an effect of treatment to use the language that statisticians will use second question is what was the average effect for the patients that were actually treated what difference did it make to them if they were given treatment B rather than treatment a the third question would be was the effect the same for all the patients in the trial and the fourth question then would be which would follow if the answer to three was no no we have evidence that it's not the same perhaps we would then try and say well is it different for particular subgroups can we say for example it's different for men than for women or for the elderly than for the young or whatever and the fifth question which is the most ambitious is what will it be like in future patients not in the trial can we say anything about patients outside the trial so these are the five levels of question and they gradually get more difficult uh my motivation was partly because I think that statisticians were not being always honest with their clients they were selling what they did as being being more capable of answering all the questions than it was strictly speaking I think most of what we do is stuck in question one and question two occasionally we're able to answer question three whether the treatment is the same for all patients and sometimes we have enough power in the trial to say something meaningful about subgroups but not very often but the fifth one is one which really involves an degree of uncertainty which is not captured in the formal statistical analysis we could always be prove wrong about this we can't know what the future will hold a good example is um the first clinical trial or the first one that's really cited as being Pioneer trial which is the streptomycin trial of tuberculosis by Bradford Hill that trial showed I think beyond the shadow of a doubt that the patients given streptomycin were better off at the time the trial reported than those who were not on average is pretty convincing but if you were to say say is streptomycin still effective for tuberculosis and the answer is no why well because tuberculosis has mutated as a disease we now have resistant forms of tuberculosis you can now no longer have the terrific treatment for tuberculosis that we thought we had then so so the fifth question is is essentially a counterfactual question that if we want to address uh we need to know more than than just the information we are able to obtain from a single I'm not so sure maybe but maybe not and my understanding of a counterfactual is that counterfactuals are also involved or could be involved depending on one's point of view in the ansers to the first two questions question one and question two because in a Parallel Group trial for example the the patients who are given the control treatment are somehow substituting for the fact that we cannot observe the counterfactual in the patients who are given the new treatment so each group acts as a sort of counterfactual group for the other if you like it's a wave estimating what the counterfactual might be you don't necess have to think of it that way but I'm not opposed to thinking of it that way myself no I think that the business about the um the future the question five is a different one is we don't know how the world will change now we might like to think of that as counterfactuals but it's not as if we're looking at um what might have happened differently or how we can estimate what happened differently this is just the fact that the future holds many surprises for us and we can't predict what they will be things may change just to make another point I think a lot of people are fixated on the idea the genetics is the only thing that matters and therefore if only we can find some some reasonable way whether it's classical genetics or whether it's even epigenetics more complicated some way of classifying patients we will then be able to say everything about future patients but I think that that's misleading there are lots of other things that change in the environment all the time that may be affecting humans for all we know so my thought here was that it's it's a counterfactual question in a sense that we need to understand the mechanisms of of of of change in order to say something about about a future so future about future outcomes maybe maybe that's so I don't know I mean um there are different views of causation um which are um possible uh which may may might succeed if I understood them thoroughly enough in convincing me that I have to think of counterfactual that way I would think of it more as being a sort of um prediction using Theory and obviously our theories are fallible even in physics then physicists have had to tear up theories that they had and replace them with new more sophisticated theories or alternative versions and the perhaps the old theories were then found to be approximations immedately to the new Theory and so forth and obviously there are many many things about the human organism we don't understand so bi biology is even more hypothetical if you like in that way we don't really know what's relevant always but nevertheless we're trying to make predictions with Theory but we just don't know what the future holds for us maybe one would be better thinking of it in terms of History we don't know what history holds for us because everything is terribly contingent we don't know how contingent our predictions are contingent contingent in the sense and depending upon things that we would like to know but we don't know we don't know what is the nub what is the essence of a thing uh this is also a problem in general when we have a look for effect modifiers as I often point out to people we assign patients their treatments but we don't assign them their covariates so we might think in a particular Tri clinical trial that really what's important is the sex of the patient but it's not the sex it's the weight we Overlook that the women are on average lighter than the men but actually once we condition on weight it explains everything between the two Sexes I'm not saying this is necessarily the case but it's a it's a possibility and so if we were um making a predictions based on sex these predictions uh fail when we move from a population in which the women are all very very slim to one in which there are many many obese women who are perhaps even heavier than some of the males that there were in the original clinical trial that we ran so we don't know this it's difficult to predict this and we have to have some ideas so we can't escape theories in a way and we can't sample from the future we can't know what the future population would be like yet it's obvious that populations change in time you only have to look at the life expectancy of different generations of Americans the children of a previous generation of Americans or British or swiss or whatever had a larger life expectancy than their parents and it wasn't the genes that were different what changed in practice how do you deal with this when you design clinical trials and you think about providing your sponsors um as you call them right in in in this field with information that will be helpful for developing a product and helping the patient yes I suppose the motto is that we we try and walk well before we learn how to run so um generally what we're trying to do is we're trying to answer question one and question two it's incredibly hard to produ to produce precise answers as to what actually happened on average to the patients in the clinical trial primarily because as I say either the counterfactual person is missing the the alternative reality that there would have been for this individual because it's a Parallel Group trial or even in a crossover trial because the circumstances will change from occasion to occasion we know that this is true by the way because there are some rare crossovers in which the patients have been randomized to receive a and b and then b and a and then A and B and we actually know that the difference from B to a changes from cycle to cycle it changes in a way which we suppose is random in some way some way that we can't see so there's always this missing element it's quite hard to establish that the treatment was effective but we're also working on the limits of what we think is possible in terms of resources both financially and ethically and I often put it like this supposing in a particular clinical trial in lung cancer we discovered a significant a really Clinic significant not just statistically significant benefit in terms of survival for patients but we then discovered well actually the problem with this trial is and it's not so surprising because lung cancer has been until recently anyway predominantly but not certainly not entirely predominantly a male disease or more males than females we discovered that although we can give a pretty firm answer looking at the males the proportion of females is just not large enough to say something separately for the females M now imagine that you are a female lung cancer sufferer what do you want do you want someone to come and say well you know actually we can't register this drug for women plausible it would work for women since it worked for men but we can't register for women because we haven't studied enough women so you're going to have to wait in the meantime male lung cancer patients yes certainly you can have the treatment but you female ones you can't have the treatment and in the end we can't escape making these of faith that we have to make and so I would say that whether we like it or not we frequently can't answer even question three or question four adequately never mind question five we cannot say anything meaningful about subgroups but we have to behave as if it doesn't matter because in any case any attempt to answer these questions competes with other projects and the other projects involve new molecules which might be even better than the current molecule Ule which is apparently the best around that we're raising question marks about so you simp you simply don't have the time to do all of these things I understand that what you're saying is that there's a number of practical considerations that we need to take into account when we think about human health and human life and we don't always have the luxury to collect enough data or to build Theory uh be congruent with the theory to the level that we may might uh might imagine or expect as as as researchers that do not have to deal with the Practical yeah stuff I think it's a mistake to imagine it's only a problem for clinical trials and I think that the the problem is that too many people have got sort of sociological investigations which might involve surveys possibly what do people think what do people believe about something which involv a sampling Paradigm and experimentation I think is not like that I think there are many cases where we cannot actually experiment on exactly the material we want it's no coincidence that one of in my opinion that one of the most important early books on Survival analysis was Jerry lawless's book and that he worked in uh essentially if I understand correctly he worked in um survival analysis applied to the automobile industry now what's the survival anal by to the automobile industry well the thing is you want to know how long a car will last before you need to replace XY Z pieace but supposing you want to have a warranty for a car for 10 years you design the car you build the car are you going to wait 10 years before you sell it is that what you're going to do would that be sensible because in 10 years there'll be new models on the market no so what you do is you have to do accelerated life testing you have to simulate that car being driven all the time by putting on a machine to drive it or something like that and you have to really put it under stress testing and you have to then extrapolate from the stress testing to to somewhere else that's what you have to do you have to do that in order to be able to use these things so it's not that unusual and you this is an example I've given you from the physical sciences and I think we've sort of lost the history of experimentation it's a long long history now 100 years at least of a formal theory of experimentation which was dealing with all of these sort of matters in a formal way but using highly abstract models which are experiments and this was a causal program in a way it may be a causal program that we've lost sight of what can uh the industrial Community learn from clinical trials oh um well I was thinking more the other way around let me go back and tell you a bit about the history of experimental design how it went Ed I think it really starts with ra Fisher arriving at rothamstead in 1919 and he soon started to work on on experiments and um these experiments were quite complex you had Fields where it was known that there were fertility gradients in the fields and it was also known that um there was some sort of a correlation structure that you know the closer two pieces of soil were to each other the more likely it was that the yield would be similar and what what you had to do was you had to try and compare treatments in this particular experiment and you could do complicated things like you could actually vary nitrogen and and phosphate at one level and then you could maybe vary the variety of wheat that you planted at another level so the actual experimental units blocks plots subplots they were different sizes and interesting enough Fisher's first analysis he got it wrong the Fisher McKenzie paper um which has many Innovations in many ways but his estimation of the V variance I think this sometime between let's say 1923 and 26 something like that he actually got it wrong but within a short amount of time he realized what you needed to do he realized you needed to really make sure that the contribution to your estimative error reflected the way in which this would also contribute to the differences between the treatments if you could match the two you could then get valid standard errors and out of this they developed a theory which one start to have a look at designs in which uh not all the same treatments could be compared in the same block so incomplete block designs were developed and then ultimately designs fractional factorial designs in which you wanted to compare lots and lots of combinations of treatments but you had more treatment combinations then you had experimental material how could you do this the answer was by deciding that higher order interactions were not important this was then developed further in Industry starting maybe around about uh the 1940s and you then had a a large impetus of development in industry and clinical trials came along relatively late to this and um now I understand there are also internet experiments which is perhaps the fourth age of experimental design with which I'm not particularly familiar but there's a long long history of this and one of the important things I think a key milestone for me was the development in 1965 by John nelder of a front-end machine a front-end way of thinking for linear models which would dictate that given the blocking structure given the way experimental variable variation could be seen before you started experimenting given the treatment structure and then given the design Matrix which match one to the other it would tell you precisely how you had to analyze the experiment in a way that made the standard errors correct and this unfortunately has not had as wide an appreciation as it should have this is a sort of thinking that that uh that should guide in my opinion the way we look at a lot of designed experiments you are not only a season statistician you are also interested in the history of of the field who would you say is the most underappreciated statistician of all time well that's if that's difficult to know I mean um Fisher as a scientist is underappreciated I think there's no question I would say his reputation among statisticians is pretty high um but occasionally his ability as a mathematician is underestimated but Jimmy Savage who was certainly a very good mathematician himself in his rereading ra Fisher piece confesses that he realized he completely underestimated Fisher as a mathematician and I think the reason was partly because fiser was a very good mathematician but using a form of mathematics that was slightly oldfashioned by the time that he was using it so he was not someone who cared about Le bag measure for example and so a certain formalism that uh that soon became established in uh in statistics largely I think due to the influence of Yi neon was not present in Fisher's work instead he used a lot of uh geometrical intuition but but uh and also some geometrical proofs which I think are actually fairly rigorous but people preferred algebraic proofs and so for some reason his mathematical influence was his mathematical ability was underestimated and this means in certain quarters as a statistician he's underestimated but his reputation in statistics is fairly High um otherwise I don't know really I think there are some some other important figures that maybe were eclipsed a bit by him um pitman's work is very profound but there aren't many papers partly because he was very busy both as a teacher and administrator then there are earlier forerunners of um of Fisher Edgeworth from the 19th century very important um and uh yeah it's difficult to difficult to know um maybe we will know in 20 years time or 25 years time or whatever you as a teenager uh was very were very interested in in mathematics yourself how does this interest influenced your choices in your career and also your view of of of the field of clinical trials where where you worked for most of your career so growing up back in Switzerland I didn't study enough mathematics really to and I wanted to study in uh as a university student in England I didn't study enough mathematics to really do an English mathematics degree so I chose um economics and statistics as a possibility which was a fairly quantitative subject that I felt I could manage but actually in retrospect I think that probably in a sense I'm making excuses for myself I think even though my formal education didn't include much mathematics I think maybe mathematics was not my thing anyway I mean I do use mathematics a lot and I like mathematics and I enjoy it to the extent that I'm able to do it but I often feel that in statistics that's not the way the where the action is for me and that often I can't proceed with a problem until I can see what the solution is and I see what the solution is by thinking about it and avoiding doing the mathematics until I feel it's time and I'm ready to do it and that's partly because I feel that unless I have some intuition to guide me with the mathematics I'm going to get it wrong I'm going to if I just follow it in the you know this logically follows from that which follows from this which follows from that and so forth then I'm not going to get it right and also I'm lazy I don't want to start doing heavy work if I don't have to and so I would tend to sort of try and think about it and then uh once I understand the problem I think I understand the problem then then proceed but I mean you know that I have said I have a paper in which I talk about the role of mathematics and statistics in which I freely confess that I wish I knew more I wish I was was better at mouth than I am I I at University I um had for my purposes a fairly thorough grounding in linear algebra as part of my economics course funly enough not as part of my stats course and of course you know the stats course covered probability Theory derivation of distributions properties of statistical estimators and all all this standard stuff but you were only ever using as much calculus and Analysis as you needed to for the purpose of understanding the statistics so you know I I don't have a background of of much much deeper mathematics that I can can call on for the purpose of of doing what I I've done but I know other people who also didn't study math at University who have have gone on to have a much deeper mathematical understanding than me so you know in a sense there's no excuse for me what made made you interested originally uh in in mathematics in looking at the world through through this formal lens well I mean I I think I I certainly as a as a school child I I loved mathematics I thought it was a you know terrific subject was my favorite subject and the subject I hated above all others was Art I just you know really loathed art and I've never been able to to draw to save my life I can hardly write my own name anything do to get my finger tracing on a piece of paper is completely hopeless and uh so from that point of view I I always lik math my mother was um was very interested in mathematics and uh so she was a big influence on me from that point of you although she was not a mathematician she was a radiographer by training and had then become a teacher but she was always interested in it but um but I think it was more what I discovered was statistics I discovered that statistics had a another dimension in it which also made the mathematics more enjoyable about me because enjoyable to me because what I particularly like was the fact that you could design things and you could Implement them and you could actually see the results so you know one of the biggest buzzers I had working in the pharmaceutical industry was designing an incomplete blocks crossover trial in comparing 7 treatments in five periods in 21 sequences and uh at the time that's fairly complex fairly complex yes I think I would claim it was possibly the most complex clinical trial that had ever been run at that particular stage crossover trial I've never come across one in patients before then that was as complex as that I was worried that we wouldn't be able to implement it um and I contacted trial Logistics which is something you should always do before you start thinking that you can run a particular trial go and see the people in charge of trial Logistics because they know what the limiting factor is I came across this recently was giving some advice from a particular uh company and they were proposing a particular randomization ratio which implies a very a very long block size if if for example if for example you choose a a 13 to5 randomization ratio you might think that's optimal for some particular reason you can't achieve that except by having a block size which is a multiple of 13 * 5 so what's that uh 65 is it I forget no yeah yes 65 yeah they say there are three kinds of statisticians those who can count and those who can't anyway so the the uh so 65 so that's rather a large block size so you know you have to think through these things anyway to go back to to my incomplete blocks design I said to them what's the maximum number of groups you can have for packaging because each of these 21 sequences would have to have their own package this is what you take take for the first day this is for day two this is for day three this is for day four this is for day five well wash out periods between the days but on these days we would have to take these these things um so I said what's the maximum number of packages you can have they said 26 I thought wow that's great because I've just done 21 I nearly broke the bank but I didn't get there I can have 26 and then I said uh why 26 they said there are 26 letters of the alphabet so so it it turned out it turned out was they had a labeling system which had to have a label a b CDE e FG for each of the packages in the list that they were doing or each of the lists that they were doing and no and nobody had ever thought that any would be crazy enough to have a um clinical trial which had more than 26 groups so I would need more than one letter so um I don't know whether they would have to do what the Excel solution is which is to go on from Ab through to zed and then you go a is it a a and then a I forget anyway but uh so that turned out to be uh to be manageable and so we did it and the particular trial which was to compare three doses of a new formulation to three doses of an existing formulation to Placebo that's the seven treatments it proved that the existing formulation the new formulation much to our surprise had one quarter the potency of the existing one so that project was killed dead so I killed a project Stone Dead with a design in which I had a major part and that gave me a great deal of satisfaction course my name was mud you know sen killed this project and I was no no no no the project killed itself it's just that I offered the Cuda grass at the time when it was necessary to put it out of its misery when we we found out early that we weren't going anywhere with this particular formulation and that was that was important being a part of of the process of Designing and and conducting clinical trials is connected to a I suppose or I imagine a huge dose of responsibility because the outcomes of of what you design and what you conduct can have very profound impact on people's lives what were some of the stories in your career where where you felt that this responsibility uh is something important something something um significant well I I think every time I've being on a data safety monitoring board um there is that possibility because you have to decide whether the trial will continue or not um and my experience in the field of cancer on data safety monitoring boards has been particularly marking from this point of view because typically uh an effective Dr drug will have toxicities so and typically you will see the toxicities before you see any efficacy so in other words well to put in another way if you don't want any toxicity take a placebo if you don't want any efficacy take a placebo so if you want some efficacy you're typically going to buy it at the expense of some toxicities expense of some unpleasantness at the very least for a number of patients also you will see the tox I ities before you see any benefit in survival so when you're looking at the two arms there what you see is on one of the arms you'll see the toxicities mounting and that could be an indication that there will be a benefit there as well would be a benefit from ex increased survival but it might not be you might simply be giving toxicities without any increase in survival so it's quite a difficult decision to make there as to whether one should continue or not and of course um on a day monitoring board I'm fortunate that I have a number of medical colleagues who are trained gifted for and able to make decisions based upon individual stories that they get from patients as well I always make it quite clear I can't do that all I can do is help them in comparing numbers averages totals these sort of things between the two groups so these are quite uh quite unpleasant things it's also happened to me once that I've stopped a trial early because of efficacy so then you feel rather better about that you know you can say well I was able to to we were able to see quite clearly early on in this particular trial that the new treatment was efficacious and that's happened to me once it's also happened to me that I've involved in a trial in which the particular treatment which was already on the market was proven to have um a toxicity in the trial H and so the trial was then stopped and this led to the treatment being withdrawn from the market so of course that's a shocking thing because you don't like to think that a that a trial has been started which had that particular outcome on the other hand of course you can always say that if the trial hadn't taken place then maybe the treatment would still be on the market you know um this particular treatment had been introduced in an earlier era in which there wasn't such rigorous rigorous testing so it's difficult to know you won't you won't discover anything without there being some risk that the treatment will that the result will not be positive if we knew it would be positive we wouldn't be doing a trial so it's inherent to the particular process you you've been working in both Academia and and Industry what are the main differences between those two worlds from your experience well I would say that um you can learn from both in very different ways so my first academic job was um lecturing at the dundy technology and for that particular job I had to teach a large variety of courses and I had to teach things that I had not myself studied at any stage um so for example I had to teach some operational research which I hadn't done and um in some cases I was only one week ahead of the students in what I was learning so it was high pressure and you were teaching a lot of stuff that you some of which you familiar with some of which you weren't familiar with and so of course one of the things that happens there is that you get a fairly broad but not necessarily deep knowledge of a number of topics and I'm glad I got that knowledge um I've never actually worked in applying multivariate methods but I've had to teach multivarious analysis I've done very little work in sampling Theory applying it but I've had to teach it and so I know something about these topics Simply Having to teach that and that's what what happens there but in Industry you also have a learning process and that's a very different sort of learning process you then actually learn by doing things and working on projects and it matters whether the projects succeed or fail and if they fail it matters that they should fail early and they shouldn't go on too long and these sort of things and it's a intense collaborative work and that's also very very useful and very interesting from that point of view and I'm also glad I had that actually before I started an academic I'd had three years working for the Health Service and there that at least taught me one thing and that was be very careful about data that are given to you because there my job involved looking using a lot of data that were collected for official purposes but when you looked at them closely you found that the data were not really quite so innocent as you thought one example is actually treated in my book dicing with death and that's um to do with the population figures that I put together for the health district I used to work for and I put them together and I noticed based upon other figures that have been given to me from official Publications and I noticed that the population of the district seemed to go up and then down and then go up again and then I realized that the going down occurred shortly after census had been taken and what was happening was a series was being recalibrated MH so you have a census and then what happens is you add the births you subtract the deaths and you make an allowance for migration which is always very very difficult and you do this annually and then 10 years later you get another census and you get a chance to correct and recalibrate the figures so this was a lesson to me that you know even be even though it's an official statistic and it's collected by people who are trained to collect such data doesn't mean that there isn't a story behind it that you have to understand stand if you want to use the use the data so that was also a valuable lesson so I think I think some practice is a very good thing but certainly the the time I had in the pharmaceutical industry was very very enjoyable from the point of view of professional challenges and having problems and solving problems and not always solving them but then trying to find another way of thinking about them so it's really good what was the challenge that you solved the one that you are the most proud of well I think that um what we did during the time I was working for cagi which is a forerunner company of nvar so during that particular time I think the the general approach that we managed to bring to designing and analyzing TRS in asthma um which also carried over to a certain extent of the other particular conditions we were dealing with I was um laterally there I was head of the group that dealt with um chronic diseases and uh we we instigated a number of things which I think are fairly obvious things to do but which are not standard we made sure we didn't dichotomize any data you'll still find that there are commonly lots and lots of dichotomies used for analyzing clinical trials which is very wasteful and misleading we use covariates um more than one covariant and we use analysis of covariant for doing that and we sort out useful Transformations so basically I think we were sorting out we were establishing the way in which trials in that particular area should be done in what was a relatively Cinderella area there have been some excellent papers on how you should analyze triing cancer some of that's been forgotten since unfortunately uh there were excellent papers on how you should uh uh analyze cardiovascular disease trials these are big big areas but something like asthma was less well established and so that was that was something I think as a whole I think wasn't just me it was my group as well as well you know I think that was something that we could regard as being an achievement but crossover trials were a particular field where I also worked a lot on the theory and so I have a book on crossover trials which is now rather elderly second edition 20 years ago so you mentioned working with additional covariates does we can imagine that there's always a trade of if we have a description of a given unit a patient or whatever our unit is um that is a multi-dimensional description and then maybe we have an experimental study or maybe a mixed study with observational and and experimental data and there's a tradeoff between including as much of this description as possible and the statistical power basically where would you put the boundary like in practice from your experience are there any hints or any um rules of famp you would say could work in in in cases like this when we need to make this Choice which coari to to to add to the model yeah I would say there are some rules of thumb for a typical phase three parel group trial will involve hundreds of patients and for a trial like that um then there's no reason why you shouldn't have half a dozen covariates you could probably have more you could probably have 15 it wouldn't be a problem you know it might not be worth it but you know you could have you could have that number it's not really a problem if it's a very small trial it begins to be a problem and so um there are three things you have to understand about what happens when you fit a covariant here I'm talking about the linear mod the um normal linear model case we can think about the nonlinear case in in a minute but for the normal linear model case then there are three things that happen the first one is that the mean square error to the extent that the coari you fit a predictive will go down mhm and this is advantageous because it means you're going to have uh smaller confidence intervals narrower confidence intervals other things being equal and greater power in the in the trial for a given signal that you're trying to detect to the extent that the covariants are not orthogonal not perfectly balanced there will be some inflation of the variance so this acts in the other direction but the is the consequence is small It's usually the order of loss of about one patient per coari so in a trial with hundreds of patients that's not important but in a trial with a dozen patients that will begin to be important you shouldn't fit five covariates if you've only got 12 patients the third thing is that the it's what I call second order Precision in addition to the variance going down because of the mean square error and the variance going up because of the nonorthogonality we're talking here about the true variance of the treatment effect but nobody will tell you what the true variance es you're going to have to estimate it and you have to estimate it by using the residuals and you will lose one degree of freedom for every particular covariant that you fit and one way to understand the effect of this is to have a look at the variance of the T distribution I think from memory the variance of the T distribution is new divided by new minus 2 where new is the degrees of freedom and so you can see that um the variance will be much larger than one if new is very small but rapidly you approach you approach one an interesting test for anybody who uses statistical tables but nobody does these days but I'm from a generation who did the question is what value of the T distribution the degrees of Feed the T distribution corresponds to an ordinate of sorry a critical value of two for 2.5% either side so in other words for a typical 5% two-sided test and the answer is 60 60 degrees of freedom you're at two at Infinity you're at 1.96 which is the value for the normal distribution that everybody knows but 60 degrees of freedom will give you two so this is the second order thing and that's usually not so important so these are the three things you have to consider um and I would say that um provided you stop consider them and think about it then usually you will have a pretty good feel for what's reasonable for a particular um particular clinical trial and we probably for most of the clinical trials we've run certainly in phase three we underuse the ability to fit covariants now the normal distribution is a two parameter model many of the other models that we use are one parameter models so for example logistic regression it's a probability and there's just one probability admittedly you've got lots of linear predictors but in the end the distribution itself the binomial distribution has this one parameter P that you don't know you know the end so that's a different because then um essentially what happens is that if you miss out covariates which are predictive your model is somehow misspecified uh and so you don't see the effect on the variance in the same way and what you tend to see is you tend to see that you're losing the signal itself directly so you see an attenuation of the estimate on the particular scale that you're using there and so things are a bit more complicated a lot of the considerations still carry over you still pay exactly the same penalty for loss of orthogonality doesn't make any difference whether you're using these squares with the normal model or logistic regression or survival analysis or whatever that thing which is a function of the imbalance of the X's that is paid for that penalty is paid in all of those cases you don't get the mean square error benefit that you would get at the normal case but the benefit is expressed in not attenuating the the treatment estimate for these things so it's a it's a field where I think a lot of work has been done um a lot of work has been forgotten uh people reinvent the wheel all the time I still see lots of papers about uh how covariant models predict using simulations where I say well you know that's obvious and that's not true and I know this you know simply from reasonable knowledge of the theory but it's it's not nothing that I've developed it's just should be out there people should know it and what happens in nonlinear cases that you mentioned before well as I said it's um basically the the models are in a sense inconsistent this is also related to something I think which some of the causal people complain about non- collapsibility of particular models um the odds ratio could be the same for two subgroups that you have the subgroups could be perfectly balanced it's not a question of confounding but the odds ratio for the two groups pulled together would not be the same this seems to be baffling that's simply because there is a scale effect if you look at it in prediction space then that's not true parameters are one thing I think it's Philip David I'm I think Philip himself couldn't find where he said this but I always a attribute this particular Mar to him he says a parameter is just a resting Stone on the road to prediction so a parameter is not in itself particularly important it's just a means of deciding what we're going to do in practice and so I I sometimes feel that well you know okay so collap non- collapsibility so what you does it really matter isn't it just a question as to whether the model predicts things reasonably or not but maybe I don't understand enough about it you know I know people that I respect highly who work in this field that know a lot more about causal infant than I do like sander Greenland for example quite worried about noncollapsibility so maybe I should be what do you think about the ideas um that could help us be more efficient with experimentation so there are a couple families of this ideas right one would be general optimal experimentation Theory another would be caal data Fusion combining data sets from observational and experimental Realms together in order to maximize the information G gain is this something that could be helpful for for us as a community when it comes to clinical trials and other areas where experimentation is is prevalent today yes I think there's a lot lot that we could do but I think there were two ideas that you picked that you mentioned there I'd like to pick up each in turn the first one is experimental design I think there it's very worrying in a way what happened there are many deep wonderful and complicated complex theories of optimal optimal experimental design that we medical statisticians ought to know better and don't so there's a lot of really deep Theory there but equally there's a lot of deep practice which some of the people who talk about optimal experimental design ought to know so optimal experimental design could almost be I think a branch of pure mathematics it's so it's so austere and beautiful and fantastic but as soon as you want to apply it to anything to any real experiment you enter into the world of the engineer and then things are somewhat different and I've come across cases where people have proposed optimal experimental designs but they don't know for example that patients are not treated simultaneously so they misunderstood what a period effect is so all sorts of things like this are just not known they don't know what the constraints are in practice on uh they don't know for example that uh certain types of optimality would require you to lengthen the time for which a clinical trial would would report suppose for example that what you have is you have a disease in which 30% of the patients are female and 70% are males but you decide you want to make an equally precise statement about the women and the men how are you going to do that because the patients will fall ill when they fall ill and they will fall ill at the rate that there will be two men falling ill more than two men falling ill for every woman who falls ill so how are you going to recruit them into the clinical trial it's going to be quite difficult to organize things so that you can actually get the same numbers and typically what will happen is if you define a stratum with the target you will find the rest of the trial is finished and the trial is continuing so I blame both sides I blame us medical statisticians for not knowing more about the theory I blame some of the optimal experimental design experts for not thinking enough about the theory and give one further example and that is you can have optimal dose finding designs which outperform regular ones that statisticians use in clinical trials but they only outperform them if you can guarantee you'll come to the end of the dose escalation but part of the point about a dose escalation is you might not get to the final dose that's why it's a dose escalation and if you don't get to the final dose and these designs are sometimes inferior than the back of the envelope rule of thumb designs that the statisticians use so that's yet another example so there is failure for the two communities to to to speak to each other there's also a second there are two two strands of optimal design there's the optimal design which is um Kea volovitz the sort of wonderful work that that they developed together starting in the late 50s and culminating around about the early 60s and there's a work which had already been done by begun by people like um fiser Frank Yates um finny and so forth um which was based upon randomization and correct analysis of variance and there's still these two particular stands but both of them both of them have a lot to teach medical statistics no question about it and we need to find some way of Bridging the Gap now as regards your second thing Fusion there I feel that it's plausible that a way of getting putting observational data sets and clinical trial data sets together will yield more power I've made some tentative suggestions as to how it might be done I've seen some very interesting and intriguing proposals by other people but some of them don't work some some of them would have to rely upon a random sampling which doesn't take place but but that doesn't mean that they should be dismissed it maybe they could be fixable with further things done to them and so I think the honest is on both sides to uh try and talk to each other it sounds to me like we we need a lot of improvements when it comes to communication between those little different ghettos that we have here yeah there there's not just the ghettos between um statisticians and people who are working in other fields but there's a there's a ghettos within statistics that I've been talking about but in any case if I mean sometimes surprising things happen the very early paper on applying standard errors to um agriculture experiments predates Fisher and it's actually a collaboration um between an agricultural scientist and an astronomer um and they actually say in their paper people may think that Agriculture and astronomy have got nothing to do with each other but both of them are really badly affected by the weather so or strongly affected by the weather um but then the astronomers were used to calculating probable errors um nowadays we calculate standard were prob eras for their astronomical data and in this particular paper it's shown how you could apply this idea to actually to experiments on root crops so this dates from about 1910 from memory one of the persons was C Stratton and I think the other one was Whitaker I think it was Whitaker and Stratton but I'm not sure but anyway that's that's an example so and and Fisher himself um was obviously influenced by agriculture about which he knew nothing when he arrived at rothamstead uh and uh then Cochran who uh this is not the Cochran Archie Cochran of the Cochran collaboration but William Cochran Bill Cochran of U experimental design fa Fame he then later got involved in sampling methodology and so that was yet another field of application application to uh survey methodology and so forth for people familiar with uh pean or Ruben uh formalisms for causality what would be one book that you'd recommend for them to read in order to understand a perspective of a practitioner of of the limitations in the real world that could help them Broad than their Horizons well first of all I'm not the best person to ask about I mean Don ruin I know well uh judia Po's book I read um I mean the the big book on causality I read when it first came out and was very impressed and I follow him on Twitter and there's no question that um his do see distinction is very very important you know it's a sort of Mia he's obviously done a lot more than just that but I'm saying that itself is a sort of Columbus a type type thing it's in retrospect it seems obvious and simple but in fact it had eluded many people before so I mean this is all all very important but I'm not the person to talk about uh I'm more familiar with Don rubin's work but but um but they're both for me um very very important figures in The Wider world of inference of that there's no question but what people if I understand your question you're asking me what should I tell people who are only familiar with say pearl or ruin what should they know about statistics is that what you what you about statistics as uh you use them in experimentation in study design and I asked let me give you a little bit of motivation so you told me before today that you have a feeling that sometimes we might have people who have certain Theory but they are not familiar with what is going on on the Frontline so to say uh and this makes certain theoretical ideas allthough they might be valuable in themselves difficult to apply in practice so my question was motivated by by by this our ear conversation of ours and in particular this idea that maybe we could open more doors between our ghettos in order to make people more aware of the limitations and and challenges that the other side is facing so so my question was what would be one book that you would recommend to people who are maybe causality researchers and they understand the formalism but they not necessarily have a good perspective a good clear view on what are the limitations of applying their theories in practice Yeah I think I would tend to think that it probably has to be grounded in whichever particular application they're looking at I'm not sure there could ever be or there has been a book in general which would do this certainly if you wanted to have a look at say you know what's going on in economics there's no point in looking at my book for instance even though there is a chapter on health economics in it which is now uh particularly oldfashioned I think so let's stay in the in your area in your in my in my area well I think on modeling um I would recommend Frank Harold's book I think that's a good good book if you want to understand some of the practice and Theory merged together by somebody who actually is uh a real programming junkie I mean Frank is when I was in the pharmaceutical industry Frank was famous for the work that he'd done on SAS to make SAS usable because SAS was very powerful in many ways but you could only do survival analysis and you could only do logistic regression by using the routines which Frank himself had written for the Suki library and then he went onto s+ now he does r and so forth so that I think would be a good book to get a flavor of some of the Practical things that people think about if you want know about clinical trials um in the pharmaceutical industry then I would recommend my own book has lots of practical issues that you would have to to think about so I think that would I'd like to think that that would be a book that you could use and it was originally written in any case to try and make it easier for um life scientists this book yeah this book yes to try and make it easier for life scientists and statisticians to talk to each other and there are a number of issues mean that's the whole point the point is to raise issues which I consider to be still controversial in some cases unsolved I don't know what the answer is in some cases I think I know what the answer is but I know that some people would disagree with me and I think that if you have a look at those things it will give you an idea as to what sort of things that really are debated by the people in the particular field um I imagine that there are similar things in economics marketing would be another area I don't know you going to think of all sorts of application areas yeah but the but I think the application field is is certainly important because there are particular restrictions you have to know about even in survey work things about you know what in practice is possible for for people to do if they are um using a clipboard still these days to ask questions you know what sort of things can you do what are the practical constraints about how many questions you can ask you know what are effect on on uh quality of asking too many questions and you know what about embarrassing questions you all these sort of practical things are very very important if you want to get good answers in that particular field and certainly uh my book on designing clinical trials is not where you would find them and Industrial experimentation I would say that looking at um box Hunter and Hunter is probably the book which has both the theory George box was someone who certainly contributed to the theory of experimental design but also the practice he was someone who worked for ICI on the production side in fact and did uh did a lot of important work on experimentation there so that's the sort of book I would encourage people to have a look at so rub your noses in reality basically in your book you devote a significant part of of the text to uh how to communicate with with stakeholders what would be two or three main lessons from your career communicating with sponsors that you could share with the community I would say try and find simple stories that everybody can understand to communicate an idea and give you one example people often say it's very strange if you do an analysis of variance that you should be able to determine from the analysis of variance that there is a treatment effect which is to say at least two treatments let's say amongst the five tested are different but once you look at the pairwise comparisons you cannot actually say that any particular pair is definitely different yeah how can this be possible this is surely ridiculous and I say is it so imagine the following scenario a mother leaves her two children playing together in a room when she comes back she finds that they're fighting she knows that at least one of them has been guilty of aggressive behavior but she doesn't know who the aggressor is she doesn't know that from the answer so it's perfectly possible in everyday life to have results like this there's nothing particularly mysterious about it we can in fact find that the answer to a question is well at least some of the treatments are different but we don't know exactly or it's difficult for us to say exactly where the difference occurs but that's just just one example we try and find things again try and find simple graphical methods I have a meth way of teaching regression to the mean which just uses graphs and nothing else you don't need to know anything about the normal distribution you don't need to know anything about that it just shows you that just cutting the data the particular way you choose to cut them will cause regression to the mean to happen and people can then understand that by seeing the diagram if they don't believe you then you can give them the data set from which the diagram is constructed and say what try it out yourself and see what happened and so I think it's more important to teach these ideas to a certain extent except for people who want to see it um resorting to algebra is to admit defeat it's uh it's not what you you want to be doing if you can avoid it um and there are some some examples also I think but also the statisticians themselves I mean you know if you if you have for example you have a particular experimental design which has a number of um let's say cells in it um these cells are created by cross classifications um what you can say is that any linear solution will be a linear combination of the cells you can hide it behind the Matrix algebra you can say well the answer is Xpose x theus1 x transpose y that's what the solution will be like and the variance will be equal to X transpose X theus1 zma squ blah blah blah blah blah you can show all of this but it's a linear combination so the question is can you find the weights because if you can find the weights you can see exactly what they do in a crossover trial if you want to eliminate the patient effects the weights must add to zero over any patient if you want to eliminate the period effects they must add to one over any period if you want to estimate the treatment effect B minus a they must add to one over all cells labeled B they must add to minus one over all cells labeled a you can often solve for the weights with a little bit of extra minimization at the very very end just using these insights and I frequently find people looking at things like step wedge designs or you know complicated designs like that they failed even to grasp that in such a design the first period data contribute nothing at all to the estimate the weights for the first period are zero because it's the only way you can eliminate that period effect it's obvious in retrospect but until they understand that they don't understand the design if they just understand it in terms of this is the Matrix algebra and this is what it says the variances are they don't understand until they understand that all the algebra is doing is the solutions what you asked me what about mathematics earlier on when I was at University I had a friend who was very dismissive about statistics he said all you statisticians do is add things up and occasionally Square them which I found rather hurtful but as I grown older I come to the conclusion well actually he's right a lot of Statistics is basically adding things up and occasionally squaring them um it's adding linear com linear combinations is what a lot of it reduces to maybe through an iteratively reting process but eventually that's what it reduces to and understanding this is um important and I also say to every say to more statistic students you need to understand statistics at least two different ways you need to understand it from the mass certainly but you need to understand it in the sense of the intuition if you don't have the intuition that goes with the mass you don't understand it if you don't see why the m math in order to do what you needed to do delivers the the answer it does you don't understand it and you need to understand both ways and that's why it's such a difficult subject in my opinion but also such a beautiful one it's got this this two Dimensions to it but probably that's true of all Sciences I don't know in your career when you experienced difficult moments challenging moments what was the thing that was keeping you going I have a job where I get employed and I get to to solve difficult problems and that's a plus and a bonus and you know you have to be grateful really I mean I think I came across statistics by accident um and I feel uh which I know is a statistical fallacy I feel I was pre-ordained to be a statistician as I say I couldn't be a mathematician because I hadn't got the background I studied economics and statistics what then happened was I didn't like the the economics and I stopped and looked around for an MSC I wanted stay on a university cuz i' met my wife by then she was still uh in her second year when I I graduated so I did uh Computing and statistics I didn't like the Computing so by process elimination I was left with Statistics then I got my first job and I started really enjoying statistics but of course the statisticians we also know that most of anything that happens in life is luck it's not under your control however good you think you are at modeling and predicting and what whatever so you know uh I have to admit that I've been lucky so be lucky is my advice what be your advice to people who are just starting with with an advanced field like statistics or causality or machine learning or whatever they they've chosen and they maybe feel that there's so much to learn that they feel unsure if they will be able to master all the pieces all the elements that are needed to success in those in those fields well I think it's good to find concrete problems to work on so that you get the habit of solving something which is just yours you know it's something that you particularly own I mean I I used to my PhD was on regression to the mean and I mistakenly assumed at one particular life point point in my life that I was a world expert on regression to the mean I was not but I it was a field I worked in a lot and um but don't necessarily stick with that you know look look wider H have something concrete to be going on with at any particular time solving the concrete problems at least for me has been a good thing but also spend some time to look around see what else is happening and see where you can borrow stuff you know maybe interesting results that uh other people would use for example particular field I'm working on at the moment n of one trials which is particularly applicable to personalizing Medicine which is related in a sense to the crossover Tri that I did so it's a field that I have some background in but but um n of1 themselves were proposed in medicine um by people at McMaster University Gordon Gatt and colleagues of his who shared a coffee room with the psychiat psychologists and the psychologists were always talking about these n of1 studies and they could never understand what in Earth they were talking about but they essentially they were talking about testing and retesting individuals Maybe by giving them stimuli you know so they professional or I don't know what some sort of stuff that they might they might do and then suddenly it suddenly hit them that's what they meant they were randomizing in the same subject and they said oh we could do this in medicine and they then started I think doing um amitryptiline for fibromyalgia they actually started doing this a number of patients were randomized in different episodes to either get Placebo or um the active treatment and so that that was um just by looking a little wider there it was a chance essentially a chance encounter which which led to that so I think I think concrete problem plus plus looking around what would be the one idea that you think if we or one challenge that if we would able to solve would change the phase of how we approach clinical trials today well I think the the Practical thing that we could do quite easily um but it involves solving a problem of human psychology is to analyze clinical trials efficiently using what we already know how to do so if you have a look at a lot of clinical trials you'll find that the data are dichotomized and we have responders and non-responders and not only is such a classification misleading but it leads to a huge loss in uh in power we know that in the best of cases when you dichotomize the sample size will have to be um something like 60% great greater than it would be if you didn't dichotomize but if you choose a bad cut point if it's not near the median then in that case you will have a much bigger loss than that the second thing is to use covariant information so if we just had the covariates in then in that case we would get also much greater Precision greater understanding so there are simple modeling steps that we could do which from some quarters are resisted because they're described as being too complex but they're basically only using Theory which is 100 years old MH why are we not doing this stuff that's a good question I don't know we have uh we have a lot of talk about you know sequential trials flexible designs increasing efficiency but this would increase it very simply uh much more than those will do so it's it's a bit of a mystery as to why it's resisted but it is resisted I think slowly very very slowly there's an increasing realization that that this will help you still feel you still find very strange things where people try and balance as much as possible by hold of Co sort of covariates which you can only do dynamically using a method called minimization but they then don't fit the covariants in the model which is really strange because if they don't think they're predictive why balance by them what's the point but if they are predictive then why aren't you using them in the model so this is a sort of uh a sort of contradiction in thinking is it a cultural thing no I don't know whether it's cultural it might be a cultural thing a difference between statisticians and life scientists I don't know not really sure it's just ingrain habits you find sometimes also that what happens is that once once people have succeeded in publishing something a particular way uh you're then told that this is the way that it has to be done there a very nice paper from about 10 years ago I think in BIO statistics by Kristoff lamber who is a scientist there's also an actor called Christoph lomber um but it's not him so um and he says something like uh pay attention to experimental design or my heads will explode and he looks at some of the early gwa studies and he showed that the way in which they were carried out meant that extens extensive data curation was necessary in order to deal with all sorts of plate effects that there were and if you looked at the two largest principal components for the results they were actually plate effects and not Gene effects um and what everybody's copied or at least the time you wrote his article whatever you copied was they copied the curation the extensive curation rather than simply designing out the problem if you designed properly you wouldn't have had the problem in the first place being able to fit the plate effects very simply orthogonally to uh rather than having to deal with them in this particular way and yet you know it became a habit so who knows so this is a problem about understanding the structure of like what variables are linked to what other variables in the study as I understand yes partly but if you think about any observational study then people tend to make the assumption that the only difference is the difference between the experimental material which might be let's say something like cases and controls in a case control study but actually what you're doing is you're processing data if it's biological data you're processing data so the question is are you sending off all of the Control Data to one lab and all of the um case data to another lab um and if many labs are involved are you sure that that particular assignment is randomly orthogonal or is there in fact some correlation over time how do you know that there isn't a Time factor to do with measuring which is correlated to what form the cases and what come the controls unless you are obtaining them simultaneously in a double blind clinical trial there is no way that this sort of bias could occur it's simply impossible to send off all of the all of the cas all of the patients given treatment a and all the patients given treatment B to be processed in different Labs is simply impossible all of these things are Impossible by the nature of the design but they become possible in different types of observational studies and they're overlooked all the time the title of one of your papers suggests that people who think they are Bas and might be wrong why is that it's because I was much taken by um the beauty of the basian method and the Very in many ways convincing arguments by a number of leing basian deep thinkers but I was unconvinced by some of the examples that they then produced they had examples in which all sorts of errors are made um which are obvious I think to any frequentist U without having to be a basian and so in this particular paper I take some classical examples that these people have used and I've shown how they couldn't possibly believe in the posterior distribution that they calculate because they simply are using the wrong prior it's not a prior that they could own why do we need probability well that's a good question some people think we don't um I would say I mean I know that uh Nasim Talib thinks that um probability misleads a lot of people uh he refers to ludic fallacy I think using games as an analogy but games are a very well structured setup in which you could plausibly believe in the probabilities elsewhere you don't the probabilities and I think he probably thinks believes more in sort of trying to find options or or ways of not being hedged in by probalistic decision analysis I think in some cases we have no choice but never nevertheless to think probabilistically about things but who knows maybe others will eventually prove it was all a fiction that was unnecessary these cases are the cases where we don't have enough information about the system that generates the data the process well you could argue that I mean there's always an argument as to whether Bedrock probability exists or not you know some people are believe in Bedrock determinism um I always use perhaps the cheap and false argument that well it may be that you're right that Bedrock determinism exists but if that's the case it seems to have been determined that I don't believe you I have no choice but not to believe you if that's the case it seems on the other hand if you're not right then there's some value in my not believing you so what's the point you know really why are we discussing this you go ahead and believe that if you think in that particular way so but it's obviously a a mystery it's been a mystery in religion as well you know if God is Almighty then how can there be free will and if there isn't free will How can there be sin and then you know the calvinist come to the conclusion well some people were pre predestined to sin and some were predestined to be saved and that's the way it is because anything else would imply that God is Not Almighty you but it's actually actually mirrored exactly I think by people who are atheists as well thinking about you know how does the world work why does it matter if it just works the way it does and we can't do anything about it you know if everything is pre-ordained so who would you like to thank Steven who would like to thank I would like to thank a number of people who've helped me understand stuff in particular Gilbert Rutherford who was a colleague of mine when I was at um at uh the dundy K technology I learned a lot from him uh Andy grieve and Amy Rasin when I was at um when I was at cagi as it then was two basian statisticians have been very influential in the way I think um and uh I would also uh yeah like to thank a lot of people I work with from whom I learned during during the time I've been a statistician where can people learn more about you and and your work following my blogs is probably the best thing either follow me on Twitter you will find that there are a fair number of rather bad puns you have to put up with um and also that there are some photographs of my hiking trips you have to put up with and the occasional photo phra of beer um that you will find but otherwise I mainly mainly twe tweet about statistics I don't know what you say these days it's no longer Twitter it's called X you X I don't know what you do when you but anyway um and also uh my blog site so I have a a collection of a web page which links to the various blogs I've I've uh written on various subjects great we'll link to this in the in the show notes in the show description so people can find it okay thank you thank you so much Stephen it was pleasure yeah pleasure is mine thank you thank you congrats on reaching the end of this episode of the caal bandits podcast stay tuned for the next one if you like this episode click the like button to help others find it and maybe subscribe to this channel as well you know stay caal